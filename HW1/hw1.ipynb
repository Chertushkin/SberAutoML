{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:10:41,677] (WARNING): /Users/shinkovskiymichael/anaconda3/envs/ml/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "logging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Imports from our package\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 3600 # Time in seconds for automl run\n",
    "TARGET_NAME = 'final_price' # Target column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = [('mean', np.mean), ('min', np.nanmin), ('max', np.nanmax)]\n",
    "s2 = [('mean', np.mean), ('min', np.nanmin), ('max', np.nanmax), ('median', np.median)]\n",
    "s = [s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = {'use_algos': ['linear_l2', 'lgb', 'lgb_tuned']}\n",
    "g2 = {'use_algos':'auto'}\n",
    "g3 = {'use_algos': ['lgb', 'lgb_tuned', 'linear_l2', 'cb', 'cb_tuned']}\n",
    "g4 = {'use_algos': [['lgb', 'lgb_tuned', 'linear_l2', 'cb', 'cb_tuned'], ['lgb', 'linear_l2']]}\n",
    "g = [g1, g3, g4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = [5, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_prices = [1111111.0, 8388607.0, 111111.0, 6666666.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[~train_data[TARGET_NAME].isin(corrupted_prices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_prediction(general_params, statistics, freq):\n",
    "#     train_data = pd.read_csv('train_data.csv')\n",
    "#     # train_data = train_data[train_data[TARGET_NAME]>1000][~train_data[TARGET_NAME].isin(corrupted_prices)]\n",
    "#     test_data = pd.read_csv('test_data.csv')\n",
    "#     submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "#     def create_extra_features(data):\n",
    "#         data['NANs_cnt'] = data.isnull().sum(axis = 1) \n",
    "        \n",
    "#     def create_col_with_min_freq(data, col, min_freq = 10):\n",
    "#         # replace rare values (less than min_freq rows) in feature by RARE_VALUE\n",
    "#         data[col + '_fixed'] = data[col].astype(str)\n",
    "#         data.loc[data[col + '_fixed'].value_counts()[data[col + '_fixed']].values < min_freq, col + '_fixed'] = \"RARE_VALUE\"\n",
    "#         data.replace({'nan': np.nan}, inplace = True)\n",
    "\n",
    "#     def create_gr_feats(data):\n",
    "#         # create aggregation feats for numeric features based on categorical ones\n",
    "#         for cat_col in ['vehicle_manufacturer', 'vehicle_model', 'vehicle_category',\n",
    "#                     'vehicle_gearbox_type', 'doors_cnt', 'wheels', 'vehicle_color', \n",
    "#                     'vehicle_interior_color', 'deal_type']:\n",
    "#             create_col_with_min_freq(data, cat_col, freq)\n",
    "#             for num_col in ['current_mileage', 'vehicle_year', 'car_leather_interior']:\n",
    "#                 for n, f in statistics:\n",
    "#                     data['FIXED_' + n + '_' + num_col + '_by_' + cat_col] = data.groupby(cat_col + '_fixed')[num_col].transform(f)\n",
    "                    \n",
    "#         # create features with counts\n",
    "#         for col in ['vehicle_manufacturer', 'vehicle_model', 'vehicle_category',\n",
    "#                 'current_mileage', 'vehicle_year', 'vehicle_gearbox_type', 'doors_cnt',\n",
    "#                 'wheels', 'vehicle_color', 'vehicle_interior_color', 'car_vin', 'deal_type']:\n",
    "#             data[col + '_cnt'] = data[col].map(data[col].value_counts(dropna = False))\n",
    "        \n",
    "            \n",
    "\n",
    "#     create_extra_features(train_data)\n",
    "#     create_extra_features(test_data)\n",
    "\n",
    "#     all_df = pd.concat([train_data, test_data]).reset_index(drop = True)\n",
    "#     create_gr_feats(all_df)\n",
    "#     train_data, test_data = all_df[:len(train_data)], all_df[len(train_data):]\n",
    "#     print(train_data.shape, test_data.shape)\n",
    "\n",
    "#     train_data, val_data = train_test_split(train_data, test_size = 0.2, random_state = RANDOM_STATE)\n",
    "#     print(train_data.shape, val_data.shape)\n",
    "#     task = Task('reg', loss='mae', metric='mae')\n",
    "#     automl = TabularUtilizedAutoML(task = task, verbose=0,\n",
    "#                        timeout = TIMEOUT,\n",
    "#                        cpu_limit = N_THREADS,\n",
    "#                        general_params = general_params,\n",
    "#                        reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "#                       )\n",
    "\n",
    "#     roles = {'target': TARGET_NAME,\n",
    "#          'drop': ['row_ID'] # to drop or not to drop?\n",
    "#          }\n",
    "#     oof_pred = automl.fit_predict(train_data, roles = roles)\n",
    "#     logging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))\n",
    "\n",
    "#     val_pred = automl.predict(val_data)\n",
    "#     logging.info('Prediction for val data:\\n{}\\nShape = {}'.format(val_pred, val_data.shape))\n",
    "\n",
    "#     logging.info('Check scores...')\n",
    "#     val_mae = mean_absolute_error(val_data[TARGET_NAME].values, val_pred.data[:, 0])\n",
    "#     logging.info('MAE score for val_data: {}'.format(val_mae))\n",
    "#     return val_mae, val_data, automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_final_prediction(general_params, statistics, freq):\n",
    "    train_data = pd.read_csv('train_data.csv')\n",
    "    train_data = train_data[~train_data[TARGET_NAME].isin(corrupted_prices)]\n",
    "    test_data = pd.read_csv('test_data.csv')\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "    def create_extra_features(data):\n",
    "        data['NANs_cnt'] = data.isnull().sum(axis = 1) \n",
    "        \n",
    "    def create_col_with_min_freq(data, col, min_freq = 10):\n",
    "        # replace rare values (less than min_freq rows) in feature by RARE_VALUE\n",
    "        data[col + '_fixed'] = data[col].astype(str)\n",
    "        data.loc[data[col + '_fixed'].value_counts()[data[col + '_fixed']].values < min_freq, col + '_fixed'] = \"RARE_VALUE\"\n",
    "        data.replace({'nan': np.nan}, inplace = True)\n",
    "\n",
    "    def create_gr_feats(data):\n",
    "        # create aggregation feats for numeric features based on categorical ones\n",
    "        for cat_col in ['vehicle_manufacturer', 'vehicle_model', 'vehicle_category',\n",
    "                    'vehicle_gearbox_type', 'doors_cnt', 'wheels', 'vehicle_color', \n",
    "                    'vehicle_interior_color', 'deal_type']:\n",
    "            create_col_with_min_freq(data, cat_col, freq)\n",
    "            for num_col in ['current_mileage', 'vehicle_year', 'car_leather_interior']:\n",
    "                for n, f in statistics:\n",
    "                    data['FIXED_' + n + '_' + num_col + '_by_' + cat_col] = data.groupby(cat_col + '_fixed')[num_col].transform(f)\n",
    "                    \n",
    "        # create features with counts\n",
    "        for col in ['vehicle_manufacturer', 'vehicle_model', 'vehicle_category',\n",
    "                'current_mileage', 'vehicle_year', 'vehicle_gearbox_type', 'doors_cnt',\n",
    "                'wheels', 'vehicle_color', 'vehicle_interior_color', 'car_vin', 'deal_type']:\n",
    "            data[col + '_cnt'] = data[col].map(data[col].value_counts(dropna = False))\n",
    "        \n",
    "            \n",
    "\n",
    "    create_extra_features(train_data)\n",
    "    create_extra_features(test_data)\n",
    "\n",
    "    all_df = pd.concat([train_data, test_data]).reset_index(drop = True)\n",
    "    create_gr_feats(all_df)\n",
    "    train_data, test_data = all_df[:len(train_data)], all_df[len(train_data):]\n",
    "    print(train_data.shape, test_data.shape)\n",
    "\n",
    "    task = Task('reg', loss='mae', metric='mae')\n",
    "    automl = TabularUtilizedAutoML(\n",
    "        task = task,\n",
    "        timeout = TIMEOUT,\n",
    "        cpu_limit = N_THREADS,\n",
    "        general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "        # general_params = general_params,\n",
    "        reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "    )\n",
    "\n",
    "    roles = {'target': TARGET_NAME,\n",
    "         'drop': ['row_ID'] # to drop or not to drop?\n",
    "         }\n",
    "    oof_pred = automl.fit_predict(train_data, roles = roles)\n",
    "    logging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))\n",
    "\n",
    "    test_pred = automl.predict(test_data)\n",
    "    return test_pred, automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ls = []\n",
    "# for g_i in g:\n",
    "#     for s_i in s:\n",
    "#         start = time.time()\n",
    "#         val_mae, _, _ = make_prediction(g_i, s_i, 15)\n",
    "#         end = time.time()\n",
    "#         elapsed = end - start\n",
    "#         print(f'Training took: {elapsed} secods')\n",
    "#         ls.append((val_mae, str(g_i), str(s_i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sklearn doesn't support in general case mae and will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34994, 145) (10697, 145)\n",
      "Current random state: {'reader_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "Found reader_params in kwargs, need to combine\n",
      "Merged variant for reader_params = {'n_jobs': 8, 'cv': 5, 'random_state': 42}\n",
      "Found general_params in kwargs, need to combine\n",
      "Merged variant for general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']], 'return_all_predictions': False}\n",
      "Start automl preset with listed constraints:\n",
      "- time: 3599.9972202777863 seconds\n",
      "- cpus: 8 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (34994, 145)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 3592.852639436722 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3625.3401783053273\n",
      "Linear model: C = 5e-05 score = -3617.9109012294725\n",
      "Linear model: C = 0.0001 score = -3608.362453041562\n",
      "Linear model: C = 0.0005 score = -3537.3749882098114\n",
      "Linear model: C = 0.001 score = -3457.4608561197915\n",
      "Linear model: C = 0.005 score = -3029.9781333666083\n",
      "Linear model: C = 0.01 score = -2774.9060320809904\n",
      "Linear model: C = 0.05 score = -2419.652746733878\n",
      "Linear model: C = 0.1 score = -2313.907876415446\n",
      "Linear model: C = 0.5 score = -2161.575498879339\n",
      "Linear model: C = 1 score = -2161.5751933503752\n",
      "Linear model: C = 5 score = -2102.9507768186504\n",
      "Linear model: C = 10 score = -2102.950878182008\n",
      "Linear model: C = 50 score = -2102.9510355400416\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3735.8774905901737\n",
      "Linear model: C = 5e-05 score = -3728.4179507158947\n",
      "Linear model: C = 0.0001 score = -3718.9658891002287\n",
      "Linear model: C = 0.0005 score = -3647.2535158831283\n",
      "Linear model: C = 0.001 score = -3566.2293354268245\n",
      "Linear model: C = 0.005 score = -3141.5977064073554\n",
      "Linear model: C = 0.01 score = -2893.806788879048\n",
      "Linear model: C = 0.05 score = -2537.1695952313953\n",
      "Linear model: C = 0.1 score = -2424.0423776670464\n",
      "Linear model: C = 0.5 score = -2256.3689534710143\n",
      "Linear model: C = 1 score = -2220.6162179782573\n",
      "Linear model: C = 5 score = -2220.6160533418315\n",
      "Linear model: C = 10 score = -2174.881278169787\n",
      "Linear model: C = 50 score = -2174.8813233847686\n",
      "Linear model: C = 100 score = -2174.8811691535984\n",
      "Linear model: C = 500 score = -2174.881254418269\n",
      "Linear model: C = 1000 score = -2174.8813733415514\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3734.56467860364\n",
      "Linear model: C = 5e-05 score = -3727.1877250600533\n",
      "Linear model: C = 0.0001 score = -3717.8698763606853\n",
      "Linear model: C = 0.0005 score = -3647.136845721264\n",
      "Linear model: C = 0.001 score = -3568.275622173145\n",
      "Linear model: C = 0.005 score = -3142.7823791059704\n",
      "Linear model: C = 0.01 score = -2886.9585885779484\n",
      "Linear model: C = 0.05 score = -2524.5218637207267\n",
      "Linear model: C = 0.1 score = -2421.088807751475\n",
      "Linear model: C = 0.5 score = -2263.2761467231785\n",
      "Linear model: C = 1 score = -2263.2756437336247\n",
      "Linear model: C = 5 score = -2182.771268613237\n",
      "Linear model: C = 10 score = -2182.771268613237\n",
      "Linear model: C = 50 score = -2182.771268613237\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3852.004879254514\n",
      "Linear model: C = 5e-05 score = -3844.4482430944377\n",
      "Linear model: C = 0.0001 score = -3834.8881976164007\n",
      "Linear model: C = 0.0005 score = -3762.4471633852268\n",
      "Linear model: C = 0.001 score = -3680.8622391787\n",
      "Linear model: C = 0.005 score = -3242.3153285726785\n",
      "Linear model: C = 0.01 score = -2989.8472090262076\n",
      "Linear model: C = 0.05 score = -2626.746332989129\n",
      "Linear model: C = 0.1 score = -2515.923099783799\n",
      "Linear model: C = 0.5 score = -2351.941580854019\n",
      "Linear model: C = 1 score = -2351.941292995077\n",
      "Linear model: C = 5 score = -2286.272676692722\n",
      "Linear model: C = 10 score = -2286.27280561848\n",
      "Linear model: C = 50 score = -2286.273156839876\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3780.770898374703\n",
      "Linear model: C = 5e-05 score = -3773.353617495624\n",
      "Linear model: C = 0.0001 score = -3763.846199953614\n",
      "Linear model: C = 0.0005 score = -3691.386333246441\n",
      "Linear model: C = 0.001 score = -3609.631801852706\n",
      "Linear model: C = 0.005 score = -3170.688054518415\n",
      "Linear model: C = 0.01 score = -2906.87031273925\n",
      "Linear model: C = 0.05 score = -2535.328753787267\n",
      "Linear model: C = 0.1 score = -2426.3254398859444\n",
      "Linear model: C = 0.5 score = -2260.227877578452\n",
      "Linear model: C = 1 score = -2226.3388522950268\n",
      "Linear model: C = 5 score = -2226.338540227388\n",
      "Linear model: C = 10 score = -2226.33708646632\n",
      "Linear model: C = 50 score = -2182.0097543389907\n",
      "Linear model: C = 100 score = -2182.0093282136486\n",
      "Linear model: C = 500 score = -2182.0093282136486\n",
      "Linear model: C = 1000 score = -2182.0093282136486\n",
      "Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "Time left 3548.3130543231964\n",
      "Start fitting Lvl_0_Pipe_1_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1736.5\n",
      "[200]\tvalid's l1: 1626.96\n",
      "[300]\tvalid's l1: 1607.6\n",
      "[400]\tvalid's l1: 1590.7\n",
      "[500]\tvalid's l1: 1585.06\n",
      "[600]\tvalid's l1: 1578.92\n",
      "[700]\tvalid's l1: 1570.27\n",
      "[800]\tvalid's l1: 1564.75\n",
      "[900]\tvalid's l1: 1563.54\n",
      "[1000]\tvalid's l1: 1561.86\n",
      "[1100]\tvalid's l1: 1560.95\n",
      "[1200]\tvalid's l1: 1558.97\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1558.86\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1768.12\n",
      "[200]\tvalid's l1: 1655.76\n",
      "[300]\tvalid's l1: 1631.16\n",
      "[400]\tvalid's l1: 1616.25\n",
      "[500]\tvalid's l1: 1609.18\n",
      "[600]\tvalid's l1: 1603.06\n",
      "[700]\tvalid's l1: 1597.87\n",
      "[800]\tvalid's l1: 1595.9\n",
      "[900]\tvalid's l1: 1594.29\n",
      "[1000]\tvalid's l1: 1591.64\n",
      "[1100]\tvalid's l1: 1589.9\n",
      "[1200]\tvalid's l1: 1586.93\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1196]\tvalid's l1: 1586.93\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1748.72\n",
      "[200]\tvalid's l1: 1628.76\n",
      "[300]\tvalid's l1: 1599.39\n",
      "[400]\tvalid's l1: 1577.03\n",
      "[500]\tvalid's l1: 1567.53\n",
      "[600]\tvalid's l1: 1562.57\n",
      "[700]\tvalid's l1: 1554.71\n",
      "[800]\tvalid's l1: 1552.74\n",
      "[900]\tvalid's l1: 1550.08\n",
      "[1000]\tvalid's l1: 1545.51\n",
      "[1100]\tvalid's l1: 1543.97\n",
      "[1200]\tvalid's l1: 1543.18\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1543.17\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1890.35\n",
      "[200]\tvalid's l1: 1760.11\n",
      "[300]\tvalid's l1: 1723.96\n",
      "[400]\tvalid's l1: 1716.34\n",
      "[500]\tvalid's l1: 1702.74\n",
      "[600]\tvalid's l1: 1696.18\n",
      "[700]\tvalid's l1: 1691.63\n",
      "[800]\tvalid's l1: 1688.17\n",
      "[900]\tvalid's l1: 1685.74\n",
      "[1000]\tvalid's l1: 1684.22\n",
      "[1100]\tvalid's l1: 1681.92\n",
      "[1200]\tvalid's l1: 1681.03\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1681.03\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1754.33\n",
      "[200]\tvalid's l1: 1614.14\n",
      "[300]\tvalid's l1: 1587.79\n",
      "[400]\tvalid's l1: 1566.8\n",
      "[500]\tvalid's l1: 1552.5\n",
      "[600]\tvalid's l1: 1545.74\n",
      "[700]\tvalid's l1: 1541.36\n",
      "[800]\tvalid's l1: 1539.1\n",
      "[900]\tvalid's l1: 1535.43\n",
      "[1000]\tvalid's l1: 1534.06\n",
      "[1100]\tvalid's l1: 1531.34\n",
      "[1200]\tvalid's l1: 1528.68\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1528.68\n",
      "Lvl_0_Pipe_1_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 3093.242863869667 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[2021-05-17 19:12:53,110] (INFO): A new study created in memory with name: no-name-984f206d-2efc-4325-87cd-1057045a70d7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1616.83\n",
      "[200]\tvalid's l1: 1504.84\n",
      "[300]\tvalid's l1: 1484.81\n",
      "[400]\tvalid's l1: 1471.29\n",
      "[500]\tvalid's l1: 1465.03\n",
      "[600]\tvalid's l1: 1463.02\n",
      "[700]\tvalid's l1: 1456.03\n",
      "[800]\tvalid's l1: 1453.13\n",
      "[900]\tvalid's l1: 1449.7\n",
      "[1000]\tvalid's l1: 1447.63\n",
      "[1100]\tvalid's l1: 1444.97\n",
      "[1200]\tvalid's l1: 1442.95\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1187]\tvalid's l1: 1442.84\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:13:00,785] (INFO): Trial 0 finished with value: -1442.8358796018756 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 108, 'bagging_fraction': 0.5917173949330818, 'min_sum_hessian_in_leaf': 1.3145103232150122, 'reg_alpha': 0.0023531598052637494, 'reg_lambda': 0.00010291881465670109}. Best is trial 0 with value: -1442.8358796018756.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1567.08\n",
      "[200]\tvalid's l1: 1451.47\n",
      "[300]\tvalid's l1: 1438.36\n",
      "[400]\tvalid's l1: 1429.81\n",
      "[500]\tvalid's l1: 1425.1\n",
      "[600]\tvalid's l1: 1423.7\n",
      "[700]\tvalid's l1: 1423.14\n",
      "[800]\tvalid's l1: 1422.2\n",
      "[900]\tvalid's l1: 1420.29\n",
      "[1000]\tvalid's l1: 1418.46\n",
      "[1100]\tvalid's l1: 1416.8\n",
      "[1200]\tvalid's l1: 1415.35\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1415.35\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:13:12,510] (INFO): Trial 1 finished with value: -1415.3474591795862 and parameters: {'feature_fraction': 0.5499874579090014, 'num_leaves': 218, 'bagging_fraction': 0.9330880728874675, 'min_sum_hessian_in_leaf': 0.2537815508265665, 'reg_alpha': 0.023585940584142682, 'reg_lambda': 1.5320059381854043e-08}. Best is trial 1 with value: -1415.3474591795862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1578.03\n",
      "[200]\tvalid's l1: 1450.79\n",
      "[300]\tvalid's l1: 1431.3\n",
      "[400]\tvalid's l1: 1421.62\n",
      "[500]\tvalid's l1: 1417.35\n",
      "[600]\tvalid's l1: 1413.13\n",
      "[700]\tvalid's l1: 1410.15\n",
      "[800]\tvalid's l1: 1408.17\n",
      "[900]\tvalid's l1: 1406.47\n",
      "[1000]\tvalid's l1: 1403.34\n",
      "[1100]\tvalid's l1: 1401.72\n",
      "[1200]\tvalid's l1: 1400.49\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1189]\tvalid's l1: 1400.35\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:13:29,420] (INFO): Trial 2 finished with value: -1400.3482893991 and parameters: {'feature_fraction': 0.9849549260809971, 'num_leaves': 251, 'bagging_fraction': 0.9692763545078751, 'min_sum_hessian_in_leaf': 0.0010071984838809194, 'reg_alpha': 8.509499823666633, 'reg_lambda': 0.0036085571407386235}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1578.51\n",
      "[200]\tvalid's l1: 1474.03\n",
      "[300]\tvalid's l1: 1455.02\n",
      "[400]\tvalid's l1: 1450.06\n",
      "[500]\tvalid's l1: 1444.25\n",
      "[600]\tvalid's l1: 1444.39\n",
      "[700]\tvalid's l1: 1441.58\n",
      "[800]\tvalid's l1: 1437.74\n",
      "[900]\tvalid's l1: 1435.62\n",
      "[1000]\tvalid's l1: 1433.04\n",
      "[1100]\tvalid's l1: 1430.98\n",
      "[1200]\tvalid's l1: 1428.4\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1195]\tvalid's l1: 1428.38\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:13:44,074] (INFO): Trial 3 finished with value: -1428.3835778625407 and parameters: {'feature_fraction': 0.8058265802441404, 'num_leaves': 251, 'bagging_fraction': 0.5115312125207079, 'min_sum_hessian_in_leaf': 0.12563152773938666, 'reg_alpha': 3.9696182670988566e-05, 'reg_lambda': 2.630213296503227e-08}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1755.93\n",
      "[200]\tvalid's l1: 1645.51\n",
      "[300]\tvalid's l1: 1618.21\n",
      "[400]\tvalid's l1: 1601.2\n",
      "[500]\tvalid's l1: 1595.64\n",
      "[600]\tvalid's l1: 1589.57\n",
      "[700]\tvalid's l1: 1579.8\n",
      "[800]\tvalid's l1: 1572.78\n",
      "[900]\tvalid's l1: 1566.98\n",
      "[1000]\tvalid's l1: 1563.73\n",
      "[1100]\tvalid's l1: 1562.15\n",
      "[1200]\tvalid's l1: 1559.7\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1559.7\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:13:48,432] (INFO): Trial 4 finished with value: -1559.7048759295064 and parameters: {'feature_fraction': 0.9868777594207296, 'num_leaves': 30, 'bagging_fraction': 0.728034992108518, 'min_sum_hessian_in_leaf': 1.382623217936987, 'reg_alpha': 6.267062696005991e-07, 'reg_lambda': 0.00042472707398058225}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1591.22\n",
      "[200]\tvalid's l1: 1477.52\n",
      "[300]\tvalid's l1: 1468.77\n",
      "[400]\tvalid's l1: 1461.64\n",
      "[500]\tvalid's l1: 1458.45\n",
      "[600]\tvalid's l1: 1456.43\n",
      "[700]\tvalid's l1: 1454.62\n",
      "[800]\tvalid's l1: 1454.38\n",
      "[900]\tvalid's l1: 1453.84\n",
      "[1000]\tvalid's l1: 1453.93\n",
      "[1100]\tvalid's l1: 1452.49\n",
      "[1200]\tvalid's l1: 1450.88\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1450.87\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:13:58,388] (INFO): Trial 5 finished with value: -1450.8670836608228 and parameters: {'feature_fraction': 0.7962072844310213, 'num_leaves': 146, 'bagging_fraction': 0.9299702033681603, 'min_sum_hessian_in_leaf': 0.5262961031076743, 'reg_alpha': 0.00011336872639641431, 'reg_lambda': 1.316390230170444e-08}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1740.42\n",
      "[200]\tvalid's l1: 1634.11\n",
      "[300]\tvalid's l1: 1612.85\n",
      "[400]\tvalid's l1: 1598.37\n",
      "[500]\tvalid's l1: 1593.55\n",
      "[600]\tvalid's l1: 1587.62\n",
      "[700]\tvalid's l1: 1585.89\n",
      "[800]\tvalid's l1: 1582.86\n",
      "[900]\tvalid's l1: 1579.12\n",
      "[1000]\tvalid's l1: 1577.11\n",
      "[1100]\tvalid's l1: 1576.5\n",
      "[1200]\tvalid's l1: 1574.35\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1574.34\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:14:02,884] (INFO): Trial 6 finished with value: -1574.3428960502922 and parameters: {'feature_fraction': 0.9711008778424264, 'num_leaves': 29, 'bagging_fraction': 0.9041986740582306, 'min_sum_hessian_in_leaf': 0.01653693718282442, 'reg_alpha': 7.569183361880229e-08, 'reg_lambda': 0.014391207615728067}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1582.25\n",
      "[200]\tvalid's l1: 1467.62\n",
      "[300]\tvalid's l1: 1451.13\n",
      "[400]\tvalid's l1: 1445.69\n",
      "[500]\tvalid's l1: 1438.39\n",
      "[600]\tvalid's l1: 1432.32\n",
      "[700]\tvalid's l1: 1429.38\n",
      "[800]\tvalid's l1: 1425.53\n",
      "[900]\tvalid's l1: 1424.06\n",
      "[1000]\tvalid's l1: 1421.97\n",
      "[1100]\tvalid's l1: 1420.83\n",
      "[1200]\tvalid's l1: 1419.14\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1193]\tvalid's l1: 1419.06\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:14:15,062] (INFO): Trial 7 finished with value: -1419.062143462141 and parameters: {'feature_fraction': 0.7200762468698007, 'num_leaves': 214, 'bagging_fraction': 0.8049983288913105, 'min_sum_hessian_in_leaf': 2.1516897298083326, 'reg_alpha': 3.6331378936352306e-07, 'reg_lambda': 3.307847415252541e-05}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1590.01\n",
      "[200]\tvalid's l1: 1474.24\n",
      "[300]\tvalid's l1: 1453.35\n",
      "[400]\tvalid's l1: 1440\n",
      "[500]\tvalid's l1: 1431.78\n",
      "[600]\tvalid's l1: 1428\n",
      "[700]\tvalid's l1: 1421.83\n",
      "[800]\tvalid's l1: 1419.35\n",
      "[900]\tvalid's l1: 1417.55\n",
      "[1000]\tvalid's l1: 1416.02\n",
      "[1100]\tvalid's l1: 1414.79\n",
      "[1200]\tvalid's l1: 1413.58\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1196]\tvalid's l1: 1413.55\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:14:23,220] (INFO): Trial 8 finished with value: -1413.5547998030197 and parameters: {'feature_fraction': 0.5911180438940311, 'num_leaves': 147, 'bagging_fraction': 0.6558555380447055, 'min_sum_hessian_in_leaf': 0.12030178871154672, 'reg_alpha': 0.0008325158565947976, 'reg_lambda': 4.609885087947832e-07}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1580.66\n",
      "[200]\tvalid's l1: 1463.07\n",
      "[300]\tvalid's l1: 1445.58\n",
      "[400]\tvalid's l1: 1437.48\n",
      "[500]\tvalid's l1: 1433.9\n",
      "[600]\tvalid's l1: 1428.99\n",
      "[700]\tvalid's l1: 1424.73\n",
      "[800]\tvalid's l1: 1422.62\n",
      "[900]\tvalid's l1: 1419.3\n",
      "[1000]\tvalid's l1: 1416.57\n",
      "[1100]\tvalid's l1: 1415.12\n",
      "[1200]\tvalid's l1: 1414.28\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1191]\tvalid's l1: 1414.17\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:14:39,050] (INFO): Trial 9 finished with value: -1414.1674836919697 and parameters: {'feature_fraction': 0.9847923138822793, 'num_leaves': 233, 'bagging_fraction': 0.7248770666848828, 'min_sum_hessian_in_leaf': 0.03807158379249393, 'reg_alpha': 2.1874079799487576, 'reg_lambda': 0.0351113851431067}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1648.48\n",
      "[200]\tvalid's l1: 1523.49\n",
      "[300]\tvalid's l1: 1506.33\n",
      "[400]\tvalid's l1: 1500.05\n",
      "[500]\tvalid's l1: 1494.27\n",
      "[600]\tvalid's l1: 1492.84\n",
      "[700]\tvalid's l1: 1491.56\n",
      "[800]\tvalid's l1: 1490.52\n",
      "[900]\tvalid's l1: 1488.2\n",
      "[1000]\tvalid's l1: 1486.5\n",
      "[1100]\tvalid's l1: 1485.68\n",
      "[1200]\tvalid's l1: 1484.68\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1153]\tvalid's l1: 1484.65\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:14:47,667] (INFO): Trial 10 finished with value: -1484.6485560818185 and parameters: {'feature_fraction': 0.8886185629157468, 'num_leaves': 89, 'bagging_fraction': 0.9847685553939332, 'min_sum_hessian_in_leaf': 0.001095687045466094, 'reg_alpha': 7.158478382247568, 'reg_lambda': 1.475649304728376}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1591.96\n",
      "[200]\tvalid's l1: 1474.81\n",
      "[300]\tvalid's l1: 1456.79\n",
      "[400]\tvalid's l1: 1444.41\n",
      "[500]\tvalid's l1: 1438.13\n",
      "[600]\tvalid's l1: 1433.51\n",
      "[700]\tvalid's l1: 1428.2\n",
      "[800]\tvalid's l1: 1424.45\n",
      "[900]\tvalid's l1: 1422.14\n",
      "[1000]\tvalid's l1: 1419.48\n",
      "[1100]\tvalid's l1: 1418.66\n",
      "[1200]\tvalid's l1: 1417.48\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1175]\tvalid's l1: 1417.07\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:14:58,451] (INFO): Trial 11 finished with value: -1417.0741126119349 and parameters: {'feature_fraction': 0.5077973998292281, 'num_leaves': 171, 'bagging_fraction': 0.6207664609936584, 'min_sum_hessian_in_leaf': 0.004197645687336308, 'reg_alpha': 0.13190022876671673, 'reg_lambda': 1.6046259532508766e-06}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1583.63\n",
      "[200]\tvalid's l1: 1464.97\n",
      "[300]\tvalid's l1: 1448.76\n",
      "[400]\tvalid's l1: 1438.1\n",
      "[500]\tvalid's l1: 1431.93\n",
      "[600]\tvalid's l1: 1426.04\n",
      "[700]\tvalid's l1: 1422.35\n",
      "[800]\tvalid's l1: 1419.36\n",
      "[900]\tvalid's l1: 1415.6\n",
      "[1000]\tvalid's l1: 1413.58\n",
      "[1100]\tvalid's l1: 1413\n",
      "[1200]\tvalid's l1: 1411.9\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1165]\tvalid's l1: 1411.51\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:15:09,599] (INFO): Trial 12 finished with value: -1411.5077130637146 and parameters: {'feature_fraction': 0.606504606468049, 'num_leaves': 180, 'bagging_fraction': 0.6335081502800337, 'min_sum_hessian_in_leaf': 0.016180971440634198, 'reg_alpha': 7.566153744504703e-06, 'reg_lambda': 1.383251374443321e-06}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1583.62\n",
      "[200]\tvalid's l1: 1469.48\n",
      "[300]\tvalid's l1: 1453.38\n",
      "[400]\tvalid's l1: 1441.76\n",
      "[500]\tvalid's l1: 1433.74\n",
      "[600]\tvalid's l1: 1426.44\n",
      "[700]\tvalid's l1: 1422.92\n",
      "[800]\tvalid's l1: 1420.01\n",
      "[900]\tvalid's l1: 1418.48\n",
      "[1000]\tvalid's l1: 1415.7\n",
      "[1100]\tvalid's l1: 1415.38\n",
      "[1200]\tvalid's l1: 1412.56\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1412.56\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:15:20,586] (INFO): Trial 13 finished with value: -1412.5559822756113 and parameters: {'feature_fraction': 0.6192672277196036, 'num_leaves': 188, 'bagging_fraction': 0.513932332597848, 'min_sum_hessian_in_leaf': 0.0011025477809755997, 'reg_alpha': 5.970241488359884e-06, 'reg_lambda': 0.0050746152798907965}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1592.41\n",
      "[200]\tvalid's l1: 1476.49\n",
      "[300]\tvalid's l1: 1457.82\n",
      "[400]\tvalid's l1: 1448.38\n",
      "[500]\tvalid's l1: 1441.23\n",
      "[600]\tvalid's l1: 1436.35\n",
      "[700]\tvalid's l1: 1434.24\n",
      "[800]\tvalid's l1: 1430.83\n",
      "[900]\tvalid's l1: 1429.39\n",
      "[1000]\tvalid's l1: 1427.97\n",
      "[1100]\tvalid's l1: 1426.37\n",
      "[1200]\tvalid's l1: 1424.44\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1196]\tvalid's l1: 1424.39\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:15:32,771] (INFO): Trial 14 finished with value: -1424.3928429311234 and parameters: {'feature_fraction': 0.6606860072450443, 'num_leaves': 183, 'bagging_fraction': 0.7994155955078461, 'min_sum_hessian_in_leaf': 0.006425416264047453, 'reg_alpha': 1.3607890410117458e-08, 'reg_lambda': 4.875750956053463}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1627.42\n",
      "[200]\tvalid's l1: 1514.78\n",
      "[300]\tvalid's l1: 1498.54\n",
      "[400]\tvalid's l1: 1491.75\n",
      "[500]\tvalid's l1: 1486.63\n",
      "[600]\tvalid's l1: 1482.14\n",
      "[700]\tvalid's l1: 1479.56\n",
      "[800]\tvalid's l1: 1476.57\n",
      "[900]\tvalid's l1: 1474.2\n",
      "[1000]\tvalid's l1: 1471.96\n",
      "[1100]\tvalid's l1: 1470.53\n",
      "[1200]\tvalid's l1: 1469.45\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1189]\tvalid's l1: 1468.79\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:15:41,692] (INFO): Trial 15 finished with value: -1468.791512537844 and parameters: {'feature_fraction': 0.8842706000755459, 'num_leaves': 102, 'bagging_fraction': 0.6728191139166915, 'min_sum_hessian_in_leaf': 0.00362458528001066, 'reg_alpha': 6.110743180709231e-06, 'reg_lambda': 3.7909642769354863e-06}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1585.89\n",
      "[200]\tvalid's l1: 1473.05\n",
      "[300]\tvalid's l1: 1456.79\n",
      "[400]\tvalid's l1: 1444.79\n",
      "[500]\tvalid's l1: 1439.4\n",
      "[600]\tvalid's l1: 1434.15\n",
      "[700]\tvalid's l1: 1430.85\n",
      "[800]\tvalid's l1: 1427.66\n",
      "[900]\tvalid's l1: 1425.55\n",
      "[1000]\tvalid's l1: 1424.03\n",
      "[1100]\tvalid's l1: 1422.19\n",
      "[1200]\tvalid's l1: 1420.15\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1196]\tvalid's l1: 1420.11\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:15:54,973] (INFO): Trial 16 finished with value: -1420.1082584987387 and parameters: {'feature_fraction': 0.521952396519725, 'num_leaves': 254, 'bagging_fraction': 0.5587494333328601, 'min_sum_hessian_in_leaf': 7.1644313104393245, 'reg_alpha': 0.3042018727523018, 'reg_lambda': 0.10887940709358025}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1578.78\n",
      "[200]\tvalid's l1: 1459.47\n",
      "[300]\tvalid's l1: 1444.66\n",
      "[400]\tvalid's l1: 1439.66\n",
      "[500]\tvalid's l1: 1435.53\n",
      "[600]\tvalid's l1: 1432.57\n",
      "[700]\tvalid's l1: 1431.11\n",
      "[800]\tvalid's l1: 1428.55\n",
      "[900]\tvalid's l1: 1426.58\n",
      "[1000]\tvalid's l1: 1424.68\n",
      "[1100]\tvalid's l1: 1424.24\n",
      "[1200]\tvalid's l1: 1422.49\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1422.49\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:16:08,219] (INFO): Trial 17 finished with value: -1422.4923530994338 and parameters: {'feature_fraction': 0.7610734200213831, 'num_leaves': 208, 'bagging_fraction': 0.8266553072375877, 'min_sum_hessian_in_leaf': 0.02425656699018524, 'reg_alpha': 0.0038486782444645, 'reg_lambda': 0.00045935114194187713}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1654.53\n",
      "[200]\tvalid's l1: 1541.95\n",
      "[300]\tvalid's l1: 1514.96\n",
      "[400]\tvalid's l1: 1507.84\n",
      "[500]\tvalid's l1: 1503.65\n",
      "[600]\tvalid's l1: 1500.48\n",
      "[700]\tvalid's l1: 1498.05\n",
      "[800]\tvalid's l1: 1497.31\n",
      "[900]\tvalid's l1: 1495.02\n",
      "[1000]\tvalid's l1: 1492.91\n",
      "[1100]\tvalid's l1: 1490.99\n",
      "[1200]\tvalid's l1: 1489.46\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1196]\tvalid's l1: 1489.45\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:16:14,750] (INFO): Trial 18 finished with value: -1489.449209625218 and parameters: {'feature_fraction': 0.8879124430248126, 'num_leaves': 66, 'bagging_fraction': 0.8737258138740681, 'min_sum_hessian_in_leaf': 0.0010201459812303041, 'reg_alpha': 8.062402271441372e-06, 'reg_lambda': 1.9021000305279595e-07}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1564.17\n",
      "[200]\tvalid's l1: 1455.2\n",
      "[300]\tvalid's l1: 1447.15\n",
      "[400]\tvalid's l1: 1444.06\n",
      "[500]\tvalid's l1: 1440.8\n",
      "[600]\tvalid's l1: 1438.67\n",
      "[700]\tvalid's l1: 1435.86\n",
      "[800]\tvalid's l1: 1434.47\n",
      "[900]\tvalid's l1: 1431.62\n",
      "[1000]\tvalid's l1: 1430.23\n",
      "[1100]\tvalid's l1: 1428.96\n",
      "[1200]\tvalid's l1: 1427.6\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1195]\tvalid's l1: 1427.48\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:16:24,859] (INFO): Trial 19 finished with value: -1427.4822186739348 and parameters: {'feature_fraction': 0.5992456690278686, 'num_leaves': 166, 'bagging_fraction': 0.9919558944445384, 'min_sum_hessian_in_leaf': 0.008988707239988184, 'reg_alpha': 0.0002486568086329312, 'reg_lambda': 1.3865505452822973e-05}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1566.06\n",
      "[200]\tvalid's l1: 1450.38\n",
      "[300]\tvalid's l1: 1433.27\n",
      "[400]\tvalid's l1: 1426.47\n",
      "[500]\tvalid's l1: 1422.09\n",
      "[600]\tvalid's l1: 1417.68\n",
      "[700]\tvalid's l1: 1415.18\n",
      "[800]\tvalid's l1: 1413.55\n",
      "[900]\tvalid's l1: 1412.57\n",
      "[1000]\tvalid's l1: 1410.21\n",
      "[1100]\tvalid's l1: 1409.11\n",
      "[1200]\tvalid's l1: 1407.05\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1407.05\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:16:38,733] (INFO): Trial 20 finished with value: -1407.0550028136977 and parameters: {'feature_fraction': 0.6516360718312304, 'num_leaves': 240, 'bagging_fraction': 0.7015880628362278, 'min_sum_hessian_in_leaf': 0.0022229165569931987, 'reg_alpha': 4.230872998814943e-07, 'reg_lambda': 0.0019292013410170405}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1567.09\n",
      "[200]\tvalid's l1: 1455.09\n",
      "[300]\tvalid's l1: 1439.07\n",
      "[400]\tvalid's l1: 1431.39\n",
      "[500]\tvalid's l1: 1423.81\n",
      "[600]\tvalid's l1: 1420.35\n",
      "[700]\tvalid's l1: 1416.87\n",
      "[800]\tvalid's l1: 1414.22\n",
      "[900]\tvalid's l1: 1412.27\n",
      "[1000]\tvalid's l1: 1410.56\n",
      "[1100]\tvalid's l1: 1410.5\n",
      "[1200]\tvalid's l1: 1409.33\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1409.28\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:16:52,884] (INFO): Trial 21 finished with value: -1409.2797108857797 and parameters: {'feature_fraction': 0.6515388125821515, 'num_leaves': 244, 'bagging_fraction': 0.6830298229559848, 'min_sum_hessian_in_leaf': 0.002311066665351253, 'reg_alpha': 1.322549234337702e-08, 'reg_lambda': 0.002315821250620666}. Best is trial 2 with value: -1400.3482893991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1557.61\n",
      "[200]\tvalid's l1: 1442.61\n",
      "[300]\tvalid's l1: 1428.04\n",
      "[400]\tvalid's l1: 1418.66\n",
      "[500]\tvalid's l1: 1414.79\n",
      "[600]\tvalid's l1: 1410.03\n",
      "[700]\tvalid's l1: 1408.26\n",
      "[800]\tvalid's l1: 1406.47\n",
      "[900]\tvalid's l1: 1404.6\n",
      "[1000]\tvalid's l1: 1402.59\n",
      "[1100]\tvalid's l1: 1400.94\n",
      "[1200]\tvalid's l1: 1400.29\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1187]\tvalid's l1: 1400.09\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:17:06,732] (INFO): Trial 22 finished with value: -1400.091191490338 and parameters: {'feature_fraction': 0.6622590154203145, 'num_leaves': 255, 'bagging_fraction': 0.707042121920976, 'min_sum_hessian_in_leaf': 0.002409069274977411, 'reg_alpha': 1.0051891197981978e-08, 'reg_lambda': 0.002135119503707714}. Best is trial 22 with value: -1400.091191490338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1573.83\n",
      "[200]\tvalid's l1: 1462.36\n",
      "[300]\tvalid's l1: 1448.03\n",
      "[400]\tvalid's l1: 1439.64\n",
      "[500]\tvalid's l1: 1433.93\n",
      "[600]\tvalid's l1: 1431.44\n",
      "[700]\tvalid's l1: 1429.28\n",
      "[800]\tvalid's l1: 1425.68\n",
      "[900]\tvalid's l1: 1424.56\n",
      "[1000]\tvalid's l1: 1422.77\n",
      "[1100]\tvalid's l1: 1421.7\n",
      "[1200]\tvalid's l1: 1420.92\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1186]\tvalid's l1: 1420.9\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:17:19,736] (INFO): Trial 23 finished with value: -1420.8981909676438 and parameters: {'feature_fraction': 0.6959749373323715, 'num_leaves': 229, 'bagging_fraction': 0.7741691363990799, 'min_sum_hessian_in_leaf': 0.002290077394556672, 'reg_alpha': 6.945182845236389e-08, 'reg_lambda': 0.23799088397196494}. Best is trial 22 with value: -1400.091191490338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1560.65\n",
      "[200]\tvalid's l1: 1449.3\n",
      "[300]\tvalid's l1: 1432.15\n",
      "[400]\tvalid's l1: 1427.61\n",
      "[500]\tvalid's l1: 1422.27\n",
      "[600]\tvalid's l1: 1419.55\n",
      "[700]\tvalid's l1: 1416.13\n",
      "[800]\tvalid's l1: 1413.7\n",
      "[900]\tvalid's l1: 1414.09\n",
      "[1000]\tvalid's l1: 1413.83\n",
      "Early stopping, best iteration is:\n",
      "[889]\tvalid's l1: 1411.98\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:17:33,473] (INFO): Trial 24 finished with value: -1411.981220601337 and parameters: {'feature_fraction': 0.7548776193213413, 'num_leaves': 255, 'bagging_fraction': 0.7279712326293052, 'min_sum_hessian_in_leaf': 0.0016412850012381985, 'reg_alpha': 3.656243306859654e-07, 'reg_lambda': 0.0017398657269362718}. Best is trial 22 with value: -1400.091191490338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1560.47\n",
      "[200]\tvalid's l1: 1442.16\n",
      "[300]\tvalid's l1: 1425.66\n",
      "[400]\tvalid's l1: 1417.35\n",
      "[500]\tvalid's l1: 1411.26\n",
      "[600]\tvalid's l1: 1406.47\n",
      "[700]\tvalid's l1: 1406.53\n",
      "[800]\tvalid's l1: 1404.45\n",
      "[900]\tvalid's l1: 1402.01\n",
      "[1000]\tvalid's l1: 1399.8\n",
      "[1100]\tvalid's l1: 1398.97\n",
      "[1200]\tvalid's l1: 1397.78\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1397.78\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:17:45,614] (INFO): Trial 25 finished with value: -1397.7753108841196 and parameters: {'feature_fraction': 0.5565862509099688, 'num_leaves': 201, 'bagging_fraction': 0.6972248821194834, 'min_sum_hessian_in_leaf': 0.0443279921908503, 'reg_alpha': 1.3648230085899335e-08, 'reg_lambda': 0.013583645001830333}. Best is trial 25 with value: -1397.7753108841196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1570.57\n",
      "[200]\tvalid's l1: 1457.57\n",
      "[300]\tvalid's l1: 1439.75\n",
      "[400]\tvalid's l1: 1431.17\n",
      "[500]\tvalid's l1: 1426.39\n",
      "[600]\tvalid's l1: 1423.61\n",
      "[700]\tvalid's l1: 1420.59\n",
      "[800]\tvalid's l1: 1417.87\n",
      "[900]\tvalid's l1: 1415.52\n",
      "[1000]\tvalid's l1: 1413.08\n",
      "[1100]\tvalid's l1: 1410.43\n",
      "[1200]\tvalid's l1: 1408.69\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1408.69\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:17:56,923] (INFO): Trial 26 finished with value: -1408.6871933274856 and parameters: {'feature_fraction': 0.5337272366877734, 'num_leaves': 194, 'bagging_fraction': 0.7633436984605726, 'min_sum_hessian_in_leaf': 0.05009618563321319, 'reg_alpha': 4.3070773810238365e-08, 'reg_lambda': 0.3060187188452768}. Best is trial 25 with value: -1397.7753108841196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1478.99\n",
      "[200]\tvalid's l1: 1446.5\n",
      "[300]\tvalid's l1: 1436.53\n",
      "[400]\tvalid's l1: 1430.28\n",
      "[500]\tvalid's l1: 1426.9\n",
      "[600]\tvalid's l1: 1426.96\n",
      "Early stopping, best iteration is:\n",
      "[571]\tvalid's l1: 1424.29\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1495.73\n",
      "[200]\tvalid's l1: 1456.93\n",
      "[300]\tvalid's l1: 1443.18\n",
      "[400]\tvalid's l1: 1436.63\n",
      "[500]\tvalid's l1: 1430.97\n",
      "[600]\tvalid's l1: 1426.35\n",
      "[700]\tvalid's l1: 1423.99\n",
      "[800]\tvalid's l1: 1421.26\n",
      "[900]\tvalid's l1: 1419.49\n",
      "[1000]\tvalid's l1: 1416.95\n",
      "[1100]\tvalid's l1: 1415.89\n",
      "[1200]\tvalid's l1: 1414.75\n",
      "[1300]\tvalid's l1: 1414.23\n",
      "[1400]\tvalid's l1: 1412.25\n",
      "[1500]\tvalid's l1: 1411.79\n",
      "[1600]\tvalid's l1: 1410.52\n",
      "[1700]\tvalid's l1: 1410.26\n",
      "Early stopping, best iteration is:\n",
      "[1691]\tvalid's l1: 1410.08\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1447.98\n",
      "[200]\tvalid's l1: 1408.23\n",
      "[300]\tvalid's l1: 1398.14\n",
      "[400]\tvalid's l1: 1391.15\n",
      "[500]\tvalid's l1: 1388.48\n",
      "[600]\tvalid's l1: 1384.6\n",
      "[700]\tvalid's l1: 1382.68\n",
      "[800]\tvalid's l1: 1381.94\n",
      "[900]\tvalid's l1: 1379.83\n",
      "[1000]\tvalid's l1: 1378.35\n",
      "[1100]\tvalid's l1: 1377.17\n",
      "[1200]\tvalid's l1: 1376.53\n",
      "[1300]\tvalid's l1: 1376.82\n",
      "Early stopping, best iteration is:\n",
      "[1217]\tvalid's l1: 1376.1\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1597.09\n",
      "[200]\tvalid's l1: 1542.66\n",
      "[300]\tvalid's l1: 1529.69\n",
      "[400]\tvalid's l1: 1522.98\n",
      "[500]\tvalid's l1: 1517.92\n",
      "[600]\tvalid's l1: 1514.25\n",
      "[700]\tvalid's l1: 1511.9\n",
      "[800]\tvalid's l1: 1508.07\n",
      "[900]\tvalid's l1: 1505.76\n",
      "[1000]\tvalid's l1: 1504.6\n",
      "[1100]\tvalid's l1: 1503.72\n",
      "[1200]\tvalid's l1: 1502.1\n",
      "[1300]\tvalid's l1: 1499.98\n",
      "[1400]\tvalid's l1: 1498.65\n",
      "[1500]\tvalid's l1: 1498.19\n",
      "[1600]\tvalid's l1: 1498.2\n",
      "Early stopping, best iteration is:\n",
      "[1550]\tvalid's l1: 1497.7\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1452.89\n",
      "[200]\tvalid's l1: 1407.72\n",
      "[300]\tvalid's l1: 1397.29\n",
      "[400]\tvalid's l1: 1388.86\n",
      "[500]\tvalid's l1: 1382.83\n",
      "[600]\tvalid's l1: 1376.74\n",
      "[700]\tvalid's l1: 1373.27\n",
      "[800]\tvalid's l1: 1371.11\n",
      "[900]\tvalid's l1: 1368.55\n",
      "[1000]\tvalid's l1: 1365.82\n",
      "[1100]\tvalid's l1: 1364.13\n",
      "[1200]\tvalid's l1: 1361.92\n",
      "[1300]\tvalid's l1: 1360.77\n",
      "[1400]\tvalid's l1: 1360.21\n",
      "[1500]\tvalid's l1: 1359.08\n",
      "[1600]\tvalid's l1: 1358.04\n",
      "[1700]\tvalid's l1: 1356.9\n",
      "[1800]\tvalid's l1: 1355.86\n",
      "[1900]\tvalid's l1: 1354.89\n",
      "[2000]\tvalid's l1: 1353.82\n",
      "[2100]\tvalid's l1: 1353.51\n",
      "[2200]\tvalid's l1: 1353.13\n",
      "[2300]\tvalid's l1: 1352.85\n",
      "[2400]\tvalid's l1: 1351.49\n",
      "[2500]\tvalid's l1: 1351.57\n",
      "[2600]\tvalid's l1: 1352.4\n",
      "Early stopping, best iteration is:\n",
      "[2549]\tvalid's l1: 1351.23\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 3143.3778903484344\n",
      "Blending: Optimization starts with equal weights and score -1634.4662618454697\n",
      "Blending, iter 0: score = -1411.8832000381792, weights = [0. 0. 1.]\n",
      "Blending, iter 1: score = -1411.8832000381792, weights = [0. 0. 1.]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 456.75 seconds.\n",
      "Current random state: {'reader_params': {'random_state': 43}, 'general_params': {'return_all_predictions': False}}\n",
      "Found reader_params in kwargs, need to combine\n",
      "Merged variant for reader_params = {'n_jobs': 8, 'cv': 5, 'random_state': 43}\n",
      "Found general_params in kwargs, need to combine\n",
      "Merged variant for general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']], 'return_all_predictions': False}\n",
      "Start automl preset with listed constraints:\n",
      "- time: 3143.225255250931 seconds\n",
      "- cpus: 8 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (34994, 145)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 3135.2820961475372 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3700.609811899747\n",
      "Linear model: C = 5e-05 score = -3693.0764119344058\n",
      "Linear model: C = 0.0001 score = -3683.5170005103964\n",
      "Linear model: C = 0.0005 score = -3610.9404408149267\n",
      "Linear model: C = 0.001 score = -3529.054915908746\n",
      "Linear model: C = 0.005 score = -3096.906989810909\n",
      "Linear model: C = 0.01 score = -2842.687036979469\n",
      "Linear model: C = 0.05 score = -2483.5012541873266\n",
      "Linear model: C = 0.1 score = -2368.8912759435602\n",
      "Linear model: C = 0.5 score = -2192.0825406546114\n",
      "Linear model: C = 1 score = -2192.0821511630656\n",
      "Linear model: C = 5 score = -2117.5845773802907\n",
      "Linear model: C = 10 score = -2117.584519233818\n",
      "Linear model: C = 50 score = -2111.231929876614\n",
      "Linear model: C = 100 score = -2111.231929876614\n",
      "Linear model: C = 500 score = -2111.2319144848366\n",
      "Linear model: C = 1000 score = -2111.2319144848366\n",
      "Linear model: C = 5000 score = -2111.2319144848366\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3684.6356068445048\n",
      "Linear model: C = 5e-05 score = -3677.017125807314\n",
      "Linear model: C = 0.0001 score = -3667.4655903340545\n",
      "Linear model: C = 0.0005 score = -3595.588607349878\n",
      "Linear model: C = 0.001 score = -3515.008297711615\n",
      "Linear model: C = 0.005 score = -3082.0142491407814\n",
      "Linear model: C = 0.01 score = -2819.1766014859445\n",
      "Linear model: C = 0.05 score = -2455.907895968563\n",
      "Linear model: C = 0.1 score = -2351.0703586306395\n",
      "Linear model: C = 0.5 score = -2189.45149136121\n",
      "Linear model: C = 1 score = -2156.7967652878024\n",
      "Linear model: C = 5 score = -2156.7967652878024\n",
      "Linear model: C = 10 score = -2118.294924772404\n",
      "Linear model: C = 50 score = -2118.293222811345\n",
      "Linear model: C = 100 score = -2118.292725426927\n",
      "Linear model: C = 500 score = -2118.292177328128\n",
      "Linear model: C = 1000 score = -2118.2904618840025\n",
      "Linear model: C = 5000 score = -2118.2893545273664\n",
      "Linear model: C = 10000 score = -2118.2888682965363\n",
      "Linear model: C = 50000 score = -2118.2877111749694\n",
      "Linear model: C = 100000 score = -2118.286549167712\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3734.9655682884945\n",
      "Linear model: C = 5e-05 score = -3727.493296370743\n",
      "Linear model: C = 0.0001 score = -3718.1415316236585\n",
      "Linear model: C = 0.0005 score = -3646.7975044844575\n",
      "Linear model: C = 0.001 score = -3565.256573797652\n",
      "Linear model: C = 0.005 score = -3135.2315211491614\n",
      "Linear model: C = 0.01 score = -2877.51047749253\n",
      "Linear model: C = 0.05 score = -2521.2611269176236\n",
      "Linear model: C = 0.1 score = -2415.5078044623747\n",
      "Linear model: C = 0.5 score = -2253.7294514276314\n",
      "Linear model: C = 1 score = -2220.1382147304876\n",
      "Linear model: C = 5 score = -2174.840531185808\n",
      "Linear model: C = 10 score = -2174.8405041684423\n",
      "Linear model: C = 50 score = -2174.840491484397\n",
      "Linear model: C = 100 score = -2174.84050602592\n",
      "Linear model: C = 500 score = -2174.8406188873278\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3747.203592072863\n",
      "Linear model: C = 5e-05 score = -3739.5970054176264\n",
      "Linear model: C = 0.0001 score = -3730.203024574102\n",
      "Linear model: C = 0.0005 score = -3658.42062792592\n",
      "Linear model: C = 0.001 score = -3576.7931371613354\n",
      "Linear model: C = 0.005 score = -3140.7445957866767\n",
      "Linear model: C = 0.01 score = -2881.445588033665\n",
      "Linear model: C = 0.05 score = -2521.5654485936607\n",
      "Linear model: C = 0.1 score = -2418.2447758094295\n",
      "Linear model: C = 0.5 score = -2260.620622039982\n",
      "Linear model: C = 1 score = -2229.338997201692\n",
      "Linear model: C = 5 score = -2194.8768835982046\n",
      "Linear model: C = 10 score = -2194.8770045719075\n",
      "Linear model: C = 50 score = -2194.877043744635\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3861.2416851592084\n",
      "Linear model: C = 5e-05 score = -3853.7716194931254\n",
      "Linear model: C = 0.0001 score = -3844.446245139515\n",
      "Linear model: C = 0.0005 score = -3773.40640549225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model: C = 0.001 score = -3694.114310178187\n",
      "Linear model: C = 0.005 score = -3269.736781345159\n",
      "Linear model: C = 0.01 score = -3016.2954480159483\n",
      "Linear model: C = 0.05 score = -2653.484096931028\n",
      "Linear model: C = 0.1 score = -2544.3147179390166\n",
      "Linear model: C = 0.5 score = -2380.1736095261663\n",
      "Linear model: C = 1 score = -2380.1732643729247\n",
      "Linear model: C = 5 score = -2317.1337129135545\n",
      "Linear model: C = 10 score = -2317.1335388449606\n",
      "Linear model: C = 50 score = -2317.133166769703\n",
      "Linear model: C = 100 score = -2317.132642447795\n",
      "Linear model: C = 500 score = -2317.132151854723\n",
      "Linear model: C = 1000 score = -2317.1317811329795\n",
      "Linear model: C = 5000 score = -2317.1317811329795\n",
      "Linear model: C = 10000 score = -2317.1317811329795\n",
      "Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "Time left 3081.6834621429443\n",
      "Start fitting Selector_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Selector_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2037.88\n",
      "[200]\tvalid's l1: 1869.42\n",
      "[300]\tvalid's l1: 1816.1\n",
      "[400]\tvalid's l1: 1779.97\n",
      "[500]\tvalid's l1: 1753.72\n",
      "[600]\tvalid's l1: 1734.89\n",
      "[700]\tvalid's l1: 1721.99\n",
      "[800]\tvalid's l1: 1714.64\n",
      "[900]\tvalid's l1: 1706.39\n",
      "[1000]\tvalid's l1: 1698.32\n",
      "[1100]\tvalid's l1: 1691.44\n",
      "[1200]\tvalid's l1: 1687.56\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1687.56\n",
      "Selector_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1712.47\n",
      "[200]\tvalid's l1: 1583.14\n",
      "[300]\tvalid's l1: 1545.61\n",
      "[400]\tvalid's l1: 1535.84\n",
      "[500]\tvalid's l1: 1533.56\n",
      "[600]\tvalid's l1: 1532.75\n",
      "[700]\tvalid's l1: 1526.35\n",
      "[800]\tvalid's l1: 1519.56\n",
      "[900]\tvalid's l1: 1518.05\n",
      "[1000]\tvalid's l1: 1515.4\n",
      "[1100]\tvalid's l1: 1512.77\n",
      "[1200]\tvalid's l1: 1511.03\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1511.03\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1740.49\n",
      "[200]\tvalid's l1: 1631.58\n",
      "[300]\tvalid's l1: 1607.82\n",
      "[400]\tvalid's l1: 1595.43\n",
      "[500]\tvalid's l1: 1591.06\n",
      "[600]\tvalid's l1: 1586.57\n",
      "[700]\tvalid's l1: 1585\n",
      "[800]\tvalid's l1: 1580.67\n",
      "[900]\tvalid's l1: 1576.63\n",
      "[1000]\tvalid's l1: 1575.64\n",
      "[1100]\tvalid's l1: 1574.13\n",
      "[1200]\tvalid's l1: 1572.28\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1572.28\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1733.24\n",
      "[200]\tvalid's l1: 1613.11\n",
      "[300]\tvalid's l1: 1582.2\n",
      "[400]\tvalid's l1: 1571.75\n",
      "[500]\tvalid's l1: 1563.35\n",
      "[600]\tvalid's l1: 1559.64\n",
      "[700]\tvalid's l1: 1555.26\n",
      "[800]\tvalid's l1: 1552.47\n",
      "[900]\tvalid's l1: 1549.87\n",
      "[1000]\tvalid's l1: 1548.38\n",
      "[1100]\tvalid's l1: 1547.04\n",
      "[1200]\tvalid's l1: 1545.22\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1545.22\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1792.25\n",
      "[200]\tvalid's l1: 1664.34\n",
      "[300]\tvalid's l1: 1639.41\n",
      "[400]\tvalid's l1: 1627.46\n",
      "[500]\tvalid's l1: 1619.25\n",
      "[600]\tvalid's l1: 1612.55\n",
      "[700]\tvalid's l1: 1607.65\n",
      "[800]\tvalid's l1: 1603.9\n",
      "[900]\tvalid's l1: 1599.13\n",
      "[1000]\tvalid's l1: 1596.99\n",
      "[1100]\tvalid's l1: 1595.07\n",
      "[1200]\tvalid's l1: 1592.85\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1592.85\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1918.73\n",
      "[200]\tvalid's l1: 1778.66\n",
      "[300]\tvalid's l1: 1752.67\n",
      "[400]\tvalid's l1: 1735.88\n",
      "[500]\tvalid's l1: 1726.1\n",
      "[600]\tvalid's l1: 1719.82\n",
      "[700]\tvalid's l1: 1718.98\n",
      "[800]\tvalid's l1: 1717.39\n",
      "[900]\tvalid's l1: 1714.33\n",
      "[1000]\tvalid's l1: 1712.17\n",
      "[1100]\tvalid's l1: 1711.21\n",
      "[1200]\tvalid's l1: 1707.65\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1707.65\n",
      "Lvl_0_Pipe_1_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 2662.2091734170913 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:20:46,127] (INFO): A new study created in memory with name: no-name-af67cbb8-ca48-413f-973c-6d9530c62b66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1564.25\n",
      "[200]\tvalid's l1: 1433.47\n",
      "[300]\tvalid's l1: 1407.85\n",
      "[400]\tvalid's l1: 1394.77\n",
      "[500]\tvalid's l1: 1387.58\n",
      "[600]\tvalid's l1: 1381.99\n",
      "[700]\tvalid's l1: 1375.76\n",
      "[800]\tvalid's l1: 1371.86\n",
      "[900]\tvalid's l1: 1369.14\n",
      "[1000]\tvalid's l1: 1367.2\n",
      "[1100]\tvalid's l1: 1364.2\n",
      "[1200]\tvalid's l1: 1362.06\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1362.05\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:20:54,115] (INFO): Trial 0 finished with value: -1362.0525431384324 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 108, 'bagging_fraction': 0.5917173949330818, 'min_sum_hessian_in_leaf': 1.3145103232150122, 'reg_alpha': 0.0023531598052637494, 'reg_lambda': 0.00010291881465670109}. Best is trial 0 with value: -1362.0525431384324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1508.89\n",
      "[200]\tvalid's l1: 1372.39\n",
      "[300]\tvalid's l1: 1354.42\n",
      "[400]\tvalid's l1: 1347.04\n",
      "[500]\tvalid's l1: 1342.76\n",
      "[600]\tvalid's l1: 1338.17\n",
      "[700]\tvalid's l1: 1335.29\n",
      "[800]\tvalid's l1: 1332.97\n",
      "[900]\tvalid's l1: 1330.4\n",
      "[1000]\tvalid's l1: 1328.35\n",
      "[1100]\tvalid's l1: 1327.18\n",
      "[1200]\tvalid's l1: 1325.89\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1325.88\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:21:07,346] (INFO): Trial 1 finished with value: -1325.8772941043435 and parameters: {'feature_fraction': 0.5499874579090014, 'num_leaves': 218, 'bagging_fraction': 0.9330880728874675, 'min_sum_hessian_in_leaf': 0.2537815508265665, 'reg_alpha': 0.023585940584142682, 'reg_lambda': 1.5320059381854043e-08}. Best is trial 1 with value: -1325.8772941043435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1520.06\n",
      "[200]\tvalid's l1: 1375.69\n",
      "[300]\tvalid's l1: 1352.73\n",
      "[400]\tvalid's l1: 1343.7\n",
      "[500]\tvalid's l1: 1337.99\n",
      "[600]\tvalid's l1: 1334.19\n",
      "[700]\tvalid's l1: 1332.03\n",
      "[800]\tvalid's l1: 1328.53\n",
      "[900]\tvalid's l1: 1325.87\n",
      "[1000]\tvalid's l1: 1323.84\n",
      "[1100]\tvalid's l1: 1320.97\n",
      "[1200]\tvalid's l1: 1318.23\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1318.23\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:21:25,431] (INFO): Trial 2 finished with value: -1318.2290299277524 and parameters: {'feature_fraction': 0.9849549260809971, 'num_leaves': 251, 'bagging_fraction': 0.9692763545078751, 'min_sum_hessian_in_leaf': 0.0010071984838809194, 'reg_alpha': 8.509499823666633, 'reg_lambda': 0.0036085571407386235}. Best is trial 2 with value: -1318.2290299277524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1503.3\n",
      "[200]\tvalid's l1: 1383.65\n",
      "[300]\tvalid's l1: 1361.54\n",
      "[400]\tvalid's l1: 1349.15\n",
      "[500]\tvalid's l1: 1341.65\n",
      "[600]\tvalid's l1: 1336.62\n",
      "[700]\tvalid's l1: 1333.6\n",
      "[800]\tvalid's l1: 1331.77\n",
      "[900]\tvalid's l1: 1328.78\n",
      "[1000]\tvalid's l1: 1326.45\n",
      "[1100]\tvalid's l1: 1324.83\n",
      "[1200]\tvalid's l1: 1323.94\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1188]\tvalid's l1: 1323.71\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:21:39,806] (INFO): Trial 3 finished with value: -1323.7141607671756 and parameters: {'feature_fraction': 0.8058265802441404, 'num_leaves': 251, 'bagging_fraction': 0.5115312125207079, 'min_sum_hessian_in_leaf': 0.12563152773938666, 'reg_alpha': 3.9696182670988566e-05, 'reg_lambda': 2.630213296503227e-08}. Best is trial 2 with value: -1318.2290299277524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1727.02\n",
      "[200]\tvalid's l1: 1591.67\n",
      "[300]\tvalid's l1: 1553.61\n",
      "[400]\tvalid's l1: 1536.33\n",
      "[500]\tvalid's l1: 1524.48\n",
      "[600]\tvalid's l1: 1516.68\n",
      "[700]\tvalid's l1: 1509.91\n",
      "[800]\tvalid's l1: 1505.11\n",
      "[900]\tvalid's l1: 1502.03\n",
      "[1000]\tvalid's l1: 1498.99\n",
      "[1100]\tvalid's l1: 1493.97\n",
      "[1200]\tvalid's l1: 1491.41\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1491.41\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:21:43,736] (INFO): Trial 4 finished with value: -1491.4054376179022 and parameters: {'feature_fraction': 0.9868777594207296, 'num_leaves': 30, 'bagging_fraction': 0.728034992108518, 'min_sum_hessian_in_leaf': 1.382623217936987, 'reg_alpha': 6.267062696005991e-07, 'reg_lambda': 0.00042472707398058225}. Best is trial 2 with value: -1318.2290299277524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1522.52\n",
      "[200]\tvalid's l1: 1390.04\n",
      "[300]\tvalid's l1: 1379.65\n",
      "[400]\tvalid's l1: 1373.81\n",
      "[500]\tvalid's l1: 1367.87\n",
      "[600]\tvalid's l1: 1364.07\n",
      "[700]\tvalid's l1: 1360.21\n",
      "[800]\tvalid's l1: 1357.55\n",
      "[900]\tvalid's l1: 1355.7\n",
      "[1000]\tvalid's l1: 1353.99\n",
      "[1100]\tvalid's l1: 1352.93\n",
      "[1200]\tvalid's l1: 1352.33\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1352.33\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:21:53,501] (INFO): Trial 5 finished with value: -1352.3311350872507 and parameters: {'feature_fraction': 0.7962072844310213, 'num_leaves': 146, 'bagging_fraction': 0.9299702033681603, 'min_sum_hessian_in_leaf': 0.5262961031076743, 'reg_alpha': 0.00011336872639641431, 'reg_lambda': 1.316390230170444e-08}. Best is trial 2 with value: -1318.2290299277524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1727.65\n",
      "[200]\tvalid's l1: 1603.02\n",
      "[300]\tvalid's l1: 1566.72\n",
      "[400]\tvalid's l1: 1557.37\n",
      "[500]\tvalid's l1: 1551.22\n",
      "[600]\tvalid's l1: 1546.14\n",
      "[700]\tvalid's l1: 1542.18\n",
      "[800]\tvalid's l1: 1539.46\n",
      "[900]\tvalid's l1: 1537.53\n",
      "[1000]\tvalid's l1: 1535.74\n",
      "[1100]\tvalid's l1: 1534.59\n",
      "[1200]\tvalid's l1: 1532.53\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1532.53\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:21:57,639] (INFO): Trial 6 finished with value: -1532.5256832335435 and parameters: {'feature_fraction': 0.9711008778424264, 'num_leaves': 29, 'bagging_fraction': 0.9041986740582306, 'min_sum_hessian_in_leaf': 0.01653693718282442, 'reg_alpha': 7.569183361880229e-08, 'reg_lambda': 0.014391207615728067}. Best is trial 2 with value: -1318.2290299277524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1497.55\n",
      "[200]\tvalid's l1: 1370.37\n",
      "[300]\tvalid's l1: 1352.57\n",
      "[400]\tvalid's l1: 1341.68\n",
      "[500]\tvalid's l1: 1335.15\n",
      "[600]\tvalid's l1: 1330.49\n",
      "[700]\tvalid's l1: 1325.73\n",
      "[800]\tvalid's l1: 1323.17\n",
      "[900]\tvalid's l1: 1320.49\n",
      "[1000]\tvalid's l1: 1318.5\n",
      "[1100]\tvalid's l1: 1316.93\n",
      "[1200]\tvalid's l1: 1315.38\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1315.38\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:22:10,372] (INFO): Trial 7 finished with value: -1315.3832777143632 and parameters: {'feature_fraction': 0.7200762468698007, 'num_leaves': 214, 'bagging_fraction': 0.8049983288913105, 'min_sum_hessian_in_leaf': 2.1516897298083326, 'reg_alpha': 3.6331378936352306e-07, 'reg_lambda': 3.307847415252541e-05}. Best is trial 7 with value: -1315.3832777143632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1547.53\n",
      "[200]\tvalid's l1: 1406.66\n",
      "[300]\tvalid's l1: 1386.42\n",
      "[400]\tvalid's l1: 1374.49\n",
      "[500]\tvalid's l1: 1366.08\n",
      "[600]\tvalid's l1: 1358.71\n",
      "[700]\tvalid's l1: 1354.9\n",
      "[800]\tvalid's l1: 1351.19\n",
      "[900]\tvalid's l1: 1347.83\n",
      "[1000]\tvalid's l1: 1345.31\n",
      "[1100]\tvalid's l1: 1343.39\n",
      "[1200]\tvalid's l1: 1340.96\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1340.96\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:22:18,981] (INFO): Trial 8 finished with value: -1340.9551266898325 and parameters: {'feature_fraction': 0.5911180438940311, 'num_leaves': 147, 'bagging_fraction': 0.6558555380447055, 'min_sum_hessian_in_leaf': 0.12030178871154672, 'reg_alpha': 0.0008325158565947976, 'reg_lambda': 4.609885087947832e-07}. Best is trial 7 with value: -1315.3832777143632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1502.01\n",
      "[200]\tvalid's l1: 1373.23\n",
      "[300]\tvalid's l1: 1353.65\n",
      "[400]\tvalid's l1: 1344.78\n",
      "[500]\tvalid's l1: 1338.44\n",
      "[600]\tvalid's l1: 1333.04\n",
      "[700]\tvalid's l1: 1328.97\n",
      "[800]\tvalid's l1: 1326.04\n",
      "[900]\tvalid's l1: 1323.93\n",
      "[1000]\tvalid's l1: 1321.84\n",
      "[1100]\tvalid's l1: 1320.09\n",
      "[1200]\tvalid's l1: 1318.53\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1318.53\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:22:35,164] (INFO): Trial 9 finished with value: -1318.533403340289 and parameters: {'feature_fraction': 0.9847923138822793, 'num_leaves': 233, 'bagging_fraction': 0.7248770666848828, 'min_sum_hessian_in_leaf': 0.03807158379249393, 'reg_alpha': 2.1874079799487576, 'reg_lambda': 0.0351113851431067}. Best is trial 7 with value: -1315.3832777143632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1514.68\n",
      "[200]\tvalid's l1: 1383.94\n",
      "[300]\tvalid's l1: 1365.67\n",
      "[400]\tvalid's l1: 1357.41\n",
      "[500]\tvalid's l1: 1354.73\n",
      "[600]\tvalid's l1: 1351.96\n",
      "[700]\tvalid's l1: 1348.42\n",
      "[800]\tvalid's l1: 1345.71\n",
      "[900]\tvalid's l1: 1343.59\n",
      "[1000]\tvalid's l1: 1341.22\n",
      "[1100]\tvalid's l1: 1339.31\n",
      "[1200]\tvalid's l1: 1337.54\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1337.53\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:22:47,423] (INFO): Trial 10 finished with value: -1337.5297061616752 and parameters: {'feature_fraction': 0.6591377620440741, 'num_leaves': 189, 'bagging_fraction': 0.8480589016791605, 'min_sum_hessian_in_leaf': 6.467021580848944, 'reg_alpha': 1.7238246488428573e-08, 'reg_lambda': 6.423608282647379e-06}. Best is trial 7 with value: -1315.3832777143632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1520.33\n",
      "[200]\tvalid's l1: 1377.77\n",
      "[300]\tvalid's l1: 1356.77\n",
      "[400]\tvalid's l1: 1347.59\n",
      "[500]\tvalid's l1: 1339.69\n",
      "[600]\tvalid's l1: 1335.83\n",
      "[700]\tvalid's l1: 1332.89\n",
      "[800]\tvalid's l1: 1330.4\n",
      "[900]\tvalid's l1: 1328.41\n",
      "[1000]\tvalid's l1: 1326.43\n",
      "[1100]\tvalid's l1: 1325.32\n",
      "[1200]\tvalid's l1: 1323.55\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1323.54\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:23:01,376] (INFO): Trial 11 finished with value: -1323.5436009276439 and parameters: {'feature_fraction': 0.8823345246214993, 'num_leaves': 195, 'bagging_fraction': 0.9961813327301685, 'min_sum_hessian_in_leaf': 0.0011563491453820563, 'reg_alpha': 6.391162403755944, 'reg_lambda': 1.378828447107251}. Best is trial 7 with value: -1315.3832777143632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1485.53\n",
      "[200]\tvalid's l1: 1353.71\n",
      "[300]\tvalid's l1: 1334.64\n",
      "[400]\tvalid's l1: 1324.93\n",
      "[500]\tvalid's l1: 1319.17\n",
      "[600]\tvalid's l1: 1313.32\n",
      "[700]\tvalid's l1: 1309.74\n",
      "[800]\tvalid's l1: 1307.65\n",
      "[900]\tvalid's l1: 1305.99\n",
      "[1000]\tvalid's l1: 1304.25\n",
      "[1100]\tvalid's l1: 1302.46\n",
      "[1200]\tvalid's l1: 1300.33\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1300.32\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:23:16,220] (INFO): Trial 12 finished with value: -1300.3159062131028 and parameters: {'feature_fraction': 0.707639611538789, 'num_leaves': 248, 'bagging_fraction': 0.8155449288920525, 'min_sum_hessian_in_leaf': 0.0013020333492334587, 'reg_alpha': 2.6799444561661987e-06, 'reg_lambda': 0.002457796414062184}. Best is trial 12 with value: -1300.3159062131028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1514.12\n",
      "[200]\tvalid's l1: 1380.45\n",
      "[300]\tvalid's l1: 1361.05\n",
      "[400]\tvalid's l1: 1350.33\n",
      "[500]\tvalid's l1: 1343.85\n",
      "[600]\tvalid's l1: 1340.42\n",
      "[700]\tvalid's l1: 1337.75\n",
      "[800]\tvalid's l1: 1335.79\n",
      "[900]\tvalid's l1: 1331.91\n",
      "[1000]\tvalid's l1: 1330.28\n",
      "[1100]\tvalid's l1: 1328.33\n",
      "[1200]\tvalid's l1: 1327.47\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1196]\tvalid's l1: 1327.46\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:23:27,896] (INFO): Trial 13 finished with value: -1327.4573374936233 and parameters: {'feature_fraction': 0.6932069977096734, 'num_leaves': 186, 'bagging_fraction': 0.8244277786950481, 'min_sum_hessian_in_leaf': 0.006062929813169998, 'reg_alpha': 1.5640585793308112e-06, 'reg_lambda': 1.07844307457417e-05}. Best is trial 12 with value: -1300.3159062131028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1563.07\n",
      "[200]\tvalid's l1: 1423.66\n",
      "[300]\tvalid's l1: 1405.34\n",
      "[400]\tvalid's l1: 1396.83\n",
      "[500]\tvalid's l1: 1389.33\n",
      "[600]\tvalid's l1: 1382.6\n",
      "[700]\tvalid's l1: 1378.23\n",
      "[800]\tvalid's l1: 1376.53\n",
      "[900]\tvalid's l1: 1373.93\n",
      "[1000]\tvalid's l1: 1370.65\n",
      "[1100]\tvalid's l1: 1367.95\n",
      "[1200]\tvalid's l1: 1365.12\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1365.12\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:23:36,345] (INFO): Trial 14 finished with value: -1365.11704239678 and parameters: {'feature_fraction': 0.7443044599022312, 'num_leaves': 109, 'bagging_fraction': 0.8024197183138725, 'min_sum_hessian_in_leaf': 9.24601720289609, 'reg_alpha': 5.3621914728530135e-06, 'reg_lambda': 4.875750956053463}. Best is trial 12 with value: -1300.3159062131028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1505.21\n",
      "[200]\tvalid's l1: 1373.86\n",
      "[300]\tvalid's l1: 1354.5\n",
      "[400]\tvalid's l1: 1343.58\n",
      "[500]\tvalid's l1: 1336.9\n",
      "[600]\tvalid's l1: 1328.99\n",
      "[700]\tvalid's l1: 1325.28\n",
      "[800]\tvalid's l1: 1323.37\n",
      "[900]\tvalid's l1: 1321.03\n",
      "[1000]\tvalid's l1: 1319.53\n",
      "[1100]\tvalid's l1: 1317.85\n",
      "[1200]\tvalid's l1: 1315.9\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1315.9\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:23:48,750] (INFO): Trial 15 finished with value: -1315.9016062731164 and parameters: {'feature_fraction': 0.6181438743099915, 'num_leaves': 218, 'bagging_fraction': 0.7958032638664104, 'min_sum_hessian_in_leaf': 0.004196314456781265, 'reg_alpha': 1.3626219657708583e-07, 'reg_lambda': 0.08426814492277833}. Best is trial 12 with value: -1300.3159062131028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1498.32\n",
      "[200]\tvalid's l1: 1367.84\n",
      "[300]\tvalid's l1: 1344.28\n",
      "[400]\tvalid's l1: 1334.1\n",
      "[500]\tvalid's l1: 1328.85\n",
      "[600]\tvalid's l1: 1324.12\n",
      "[700]\tvalid's l1: 1319.7\n",
      "[800]\tvalid's l1: 1316.04\n",
      "[900]\tvalid's l1: 1313.39\n",
      "[1000]\tvalid's l1: 1310.97\n",
      "[1100]\tvalid's l1: 1309.75\n",
      "[1200]\tvalid's l1: 1308.29\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1308.29\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:24:03,788] (INFO): Trial 16 finished with value: -1308.2943286127934 and parameters: {'feature_fraction': 0.7549734290865706, 'num_leaves': 254, 'bagging_fraction': 0.6626269744248692, 'min_sum_hessian_in_leaf': 3.120447529854824, 'reg_alpha': 1.2647660067228726e-08, 'reg_lambda': 0.00047329992968580197}. Best is trial 12 with value: -1300.3159062131028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1491.91\n",
      "[200]\tvalid's l1: 1368.81\n",
      "[300]\tvalid's l1: 1350.97\n",
      "[400]\tvalid's l1: 1341.02\n",
      "[500]\tvalid's l1: 1333.47\n",
      "[600]\tvalid's l1: 1329.04\n",
      "[700]\tvalid's l1: 1325.43\n",
      "[800]\tvalid's l1: 1321.89\n",
      "[900]\tvalid's l1: 1318.89\n",
      "[1000]\tvalid's l1: 1317.74\n",
      "[1100]\tvalid's l1: 1315.98\n",
      "[1200]\tvalid's l1: 1314.09\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1314.03\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:24:20,331] (INFO): Trial 17 finished with value: -1314.0292825724061 and parameters: {'feature_fraction': 0.8529694011819126, 'num_leaves': 254, 'bagging_fraction': 0.6618648353209724, 'min_sum_hessian_in_leaf': 0.03858049323399239, 'reg_alpha': 1.0000809051432714e-08, 'reg_lambda': 0.0038826254354833735}. Best is trial 12 with value: -1300.3159062131028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1627.5\n",
      "[200]\tvalid's l1: 1488.25\n",
      "[300]\tvalid's l1: 1455.92\n",
      "[400]\tvalid's l1: 1440.61\n",
      "[500]\tvalid's l1: 1430.74\n",
      "[600]\tvalid's l1: 1422.27\n",
      "[700]\tvalid's l1: 1415.64\n",
      "[800]\tvalid's l1: 1409.64\n",
      "[900]\tvalid's l1: 1406.4\n",
      "[1000]\tvalid's l1: 1403.03\n",
      "[1100]\tvalid's l1: 1399.96\n",
      "[1200]\tvalid's l1: 1397.35\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1397.35\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:24:26,777] (INFO): Trial 18 finished with value: -1397.348940177583 and parameters: {'feature_fraction': 0.7942141218852105, 'num_leaves': 66, 'bagging_fraction': 0.5353173021796145, 'min_sum_hessian_in_leaf': 0.002685152655468893, 'reg_alpha': 1.0888898536584279e-05, 'reg_lambda': 0.4407513046351058}. Best is trial 12 with value: -1300.3159062131028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1539.88\n",
      "[200]\tvalid's l1: 1399.04\n",
      "[300]\tvalid's l1: 1376.41\n",
      "[400]\tvalid's l1: 1362.88\n",
      "[500]\tvalid's l1: 1356.77\n",
      "[600]\tvalid's l1: 1350.76\n",
      "[700]\tvalid's l1: 1347.35\n",
      "[800]\tvalid's l1: 1343.27\n",
      "[900]\tvalid's l1: 1340.8\n",
      "[1000]\tvalid's l1: 1338.85\n",
      "[1100]\tvalid's l1: 1337.59\n",
      "[1200]\tvalid's l1: 1336.49\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1336.49\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:24:36,740] (INFO): Trial 19 finished with value: -1336.4920114094673 and parameters: {'feature_fraction': 0.5152543029937195, 'num_leaves': 172, 'bagging_fraction': 0.6803395985027783, 'min_sum_hessian_in_leaf': 3.836948132093431, 'reg_alpha': 1.2745565406877822e-08, 'reg_lambda': 0.0003259215963381846}. Best is trial 12 with value: -1300.3159062131028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1500.49\n",
      "[200]\tvalid's l1: 1375.46\n",
      "[300]\tvalid's l1: 1354.44\n",
      "[400]\tvalid's l1: 1345.24\n",
      "[500]\tvalid's l1: 1338.51\n",
      "[600]\tvalid's l1: 1335.25\n",
      "[700]\tvalid's l1: 1332\n",
      "[800]\tvalid's l1: 1330.47\n",
      "[900]\tvalid's l1: 1328.46\n",
      "[1000]\tvalid's l1: 1326.69\n",
      "[1100]\tvalid's l1: 1324.99\n",
      "[1200]\tvalid's l1: 1323.69\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1323.69\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:24:52,597] (INFO): Trial 20 finished with value: -1323.6918133836523 and parameters: {'feature_fraction': 0.9054393454115087, 'num_leaves': 241, 'bagging_fraction': 0.5820825937953361, 'min_sum_hessian_in_leaf': 0.5044845917975775, 'reg_alpha': 0.016908951504080838, 'reg_lambda': 0.00146134927796615}. Best is trial 12 with value: -1300.3159062131028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1484.21\n",
      "[200]\tvalid's l1: 1362.82\n",
      "[300]\tvalid's l1: 1343.11\n",
      "[400]\tvalid's l1: 1331.55\n",
      "[500]\tvalid's l1: 1325.47\n",
      "[600]\tvalid's l1: 1321.84\n",
      "[700]\tvalid's l1: 1319.52\n",
      "[800]\tvalid's l1: 1316.79\n",
      "[900]\tvalid's l1: 1315.49\n",
      "[1000]\tvalid's l1: 1313.96\n",
      "[1100]\tvalid's l1: 1312.86\n",
      "[1200]\tvalid's l1: 1311.75\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1311.75\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:25:11,259] (INFO): Trial 21 finished with value: -1311.751015678902 and parameters: {'feature_fraction': 0.8614176496034924, 'num_leaves': 253, 'bagging_fraction': 0.6486499146779091, 'min_sum_hessian_in_leaf': 0.04101039262505511, 'reg_alpha': 1.1243778874400393e-08, 'reg_lambda': 0.004728539174024057}. Best is trial 12 with value: -1300.3159062131028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1494.29\n",
      "[200]\tvalid's l1: 1369.7\n",
      "[300]\tvalid's l1: 1349.35\n",
      "[400]\tvalid's l1: 1339.11\n",
      "[500]\tvalid's l1: 1333.29\n",
      "[600]\tvalid's l1: 1327.94\n",
      "[700]\tvalid's l1: 1324.76\n",
      "[800]\tvalid's l1: 1321.94\n",
      "[900]\tvalid's l1: 1320.15\n",
      "[1000]\tvalid's l1: 1318.7\n",
      "[1100]\tvalid's l1: 1316.97\n",
      "[1200]\tvalid's l1: 1314.98\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1314.97\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:25:30,504] (INFO): Trial 22 finished with value: -1314.972717845965 and parameters: {'feature_fraction': 0.8324455260733389, 'num_leaves': 255, 'bagging_fraction': 0.6162099220942345, 'min_sum_hessian_in_leaf': 0.014335020427127011, 'reg_alpha': 4.225310958345406e-08, 'reg_lambda': 0.0009045759376663862}. Best is trial 12 with value: -1300.3159062131028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1494.72\n",
      "[200]\tvalid's l1: 1368.09\n",
      "[300]\tvalid's l1: 1349.83\n",
      "[400]\tvalid's l1: 1338.67\n",
      "[500]\tvalid's l1: 1332.53\n",
      "[600]\tvalid's l1: 1326.99\n",
      "[700]\tvalid's l1: 1322.95\n",
      "[800]\tvalid's l1: 1321.16\n",
      "[900]\tvalid's l1: 1318.7\n",
      "[1000]\tvalid's l1: 1316.32\n",
      "[1100]\tvalid's l1: 1314.43\n",
      "[1200]\tvalid's l1: 1313.05\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1313.05\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:25:47,628] (INFO): Trial 23 finished with value: -1313.0520491615366 and parameters: {'feature_fraction': 0.7473109753950739, 'num_leaves': 230, 'bagging_fraction': 0.7345058301262042, 'min_sum_hessian_in_leaf': 0.02572080771814737, 'reg_alpha': 2.5910186622508132e-06, 'reg_lambda': 0.0932237614354777}. Best is trial 12 with value: -1300.3159062131028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1381.91\n",
      "[200]\tvalid's l1: 1342.39\n",
      "[300]\tvalid's l1: 1330.3\n",
      "[400]\tvalid's l1: 1325.55\n",
      "[500]\tvalid's l1: 1321.91\n",
      "[600]\tvalid's l1: 1319.28\n",
      "[700]\tvalid's l1: 1316.94\n",
      "[800]\tvalid's l1: 1315.48\n",
      "[900]\tvalid's l1: 1313.65\n",
      "[1000]\tvalid's l1: 1313.38\n",
      "[1100]\tvalid's l1: 1311.32\n",
      "[1200]\tvalid's l1: 1311.01\n",
      "[1300]\tvalid's l1: 1310\n",
      "[1400]\tvalid's l1: 1308.93\n",
      "[1500]\tvalid's l1: 1308.09\n",
      "[1600]\tvalid's l1: 1306.84\n",
      "[1700]\tvalid's l1: 1306.42\n",
      "[1800]\tvalid's l1: 1305.83\n",
      "[1900]\tvalid's l1: 1304.94\n",
      "[2000]\tvalid's l1: 1304.68\n",
      "[2100]\tvalid's l1: 1304.11\n",
      "[2200]\tvalid's l1: 1303.18\n",
      "[2300]\tvalid's l1: 1302.71\n",
      "Early stopping, best iteration is:\n",
      "[2298]\tvalid's l1: 1302.71\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1510.73\n",
      "[200]\tvalid's l1: 1475.59\n",
      "[300]\tvalid's l1: 1465.38\n",
      "[400]\tvalid's l1: 1460.42\n",
      "[500]\tvalid's l1: 1456.24\n",
      "[600]\tvalid's l1: 1453.72\n",
      "[700]\tvalid's l1: 1451.9\n",
      "[800]\tvalid's l1: 1450.44\n",
      "[900]\tvalid's l1: 1448.57\n",
      "[1000]\tvalid's l1: 1447.28\n",
      "[1100]\tvalid's l1: 1446.03\n",
      "[1200]\tvalid's l1: 1444.85\n",
      "[1300]\tvalid's l1: 1444.69\n",
      "[1400]\tvalid's l1: 1443.72\n",
      "[1500]\tvalid's l1: 1442.67\n",
      "[1600]\tvalid's l1: 1442.4\n",
      "Early stopping, best iteration is:\n",
      "[1595]\tvalid's l1: 1442.15\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1421.07\n",
      "[200]\tvalid's l1: 1380.44\n",
      "[300]\tvalid's l1: 1367.89\n",
      "[400]\tvalid's l1: 1359.39\n",
      "[500]\tvalid's l1: 1355.02\n",
      "[600]\tvalid's l1: 1352.13\n",
      "[700]\tvalid's l1: 1350.3\n",
      "[800]\tvalid's l1: 1349.13\n",
      "[900]\tvalid's l1: 1347.09\n",
      "[1000]\tvalid's l1: 1346.05\n",
      "[1100]\tvalid's l1: 1344.76\n",
      "[1200]\tvalid's l1: 1343.78\n",
      "[1300]\tvalid's l1: 1343.07\n",
      "[1400]\tvalid's l1: 1341.95\n",
      "[1500]\tvalid's l1: 1341.14\n",
      "[1600]\tvalid's l1: 1340.13\n",
      "[1700]\tvalid's l1: 1339.03\n",
      "[1800]\tvalid's l1: 1337.72\n",
      "[1900]\tvalid's l1: 1337.46\n",
      "[2000]\tvalid's l1: 1336.74\n",
      "[2100]\tvalid's l1: 1335.79\n",
      "[2200]\tvalid's l1: 1335.21\n",
      "[2300]\tvalid's l1: 1334.8\n",
      "[2400]\tvalid's l1: 1334.66\n",
      "[2500]\tvalid's l1: 1334.09\n",
      "[2600]\tvalid's l1: 1333.48\n",
      "[2700]\tvalid's l1: 1332.79\n",
      "[2800]\tvalid's l1: 1332.51\n",
      "[2900]\tvalid's l1: 1331.83\n",
      "[3000]\tvalid's l1: 1331.53\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2999]\tvalid's l1: 1331.52\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1440.49\n",
      "[200]\tvalid's l1: 1409.17\n",
      "[300]\tvalid's l1: 1398.2\n",
      "[400]\tvalid's l1: 1390.6\n",
      "[500]\tvalid's l1: 1385.32\n",
      "[600]\tvalid's l1: 1382.47\n",
      "[700]\tvalid's l1: 1380.15\n",
      "[800]\tvalid's l1: 1378.08\n",
      "[900]\tvalid's l1: 1376.52\n",
      "[1000]\tvalid's l1: 1375.14\n",
      "[1100]\tvalid's l1: 1374.97\n",
      "[1200]\tvalid's l1: 1374.3\n",
      "Early stopping, best iteration is:\n",
      "[1182]\tvalid's l1: 1373.88\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1631.04\n",
      "[200]\tvalid's l1: 1588.14\n",
      "[300]\tvalid's l1: 1570.96\n",
      "[400]\tvalid's l1: 1563.1\n",
      "[500]\tvalid's l1: 1557.51\n",
      "[600]\tvalid's l1: 1553.18\n",
      "[700]\tvalid's l1: 1549.82\n",
      "[800]\tvalid's l1: 1547.92\n",
      "[900]\tvalid's l1: 1545.77\n",
      "[1000]\tvalid's l1: 1543.9\n",
      "[1100]\tvalid's l1: 1541.79\n",
      "[1200]\tvalid's l1: 1540.75\n",
      "[1300]\tvalid's l1: 1539.51\n",
      "[1400]\tvalid's l1: 1538.3\n",
      "[1500]\tvalid's l1: 1537.32\n",
      "[1600]\tvalid's l1: 1536.13\n",
      "[1700]\tvalid's l1: 1535.62\n",
      "[1800]\tvalid's l1: 1535.13\n",
      "[1900]\tvalid's l1: 1534.43\n",
      "[2000]\tvalid's l1: 1533.15\n",
      "[2100]\tvalid's l1: 1532.84\n",
      "[2200]\tvalid's l1: 1532.79\n",
      "[2300]\tvalid's l1: 1532.14\n",
      "[2400]\tvalid's l1: 1531.31\n",
      "[2500]\tvalid's l1: 1531.67\n",
      "Early stopping, best iteration is:\n",
      "[2443]\tvalid's l1: 1531.08\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 2599.6835350990295\n",
      "Blending: Optimization starts with equal weights and score -1632.0140054298636\n",
      "Blending, iter 0: score = -1396.2638580625503, weights = [0. 0. 1.]\n",
      "Blending, iter 1: score = -1396.2638580625503, weights = [0. 0. 1.]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 543.68 seconds.\n",
      "Current random state: {'reader_params': {'random_state': 44}, 'general_params': {'return_all_predictions': False}}\n",
      "Found reader_params in kwargs, need to combine\n",
      "Merged variant for reader_params = {'n_jobs': 8, 'cv': 5, 'random_state': 44}\n",
      "Found general_params in kwargs, need to combine\n",
      "Merged variant for general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']], 'return_all_predictions': False}\n",
      "Start automl preset with listed constraints:\n",
      "- time: 2599.516398191452 seconds\n",
      "- cpus: 8 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (34994, 145)\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 2599.1002411842346 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3721.823771141413\n",
      "Linear model: C = 5e-05 score = -3716.6137016155767\n",
      "Linear model: C = 0.0001 score = -3710.035294941688\n",
      "Linear model: C = 0.0005 score = -3660.2710606607307\n",
      "Linear model: C = 0.001 score = -3603.9717733811303\n",
      "Linear model: C = 0.005 score = -3302.382820277644\n",
      "Linear model: C = 0.01 score = -3099.1988683387985\n",
      "Linear model: C = 0.05 score = -2647.004988148751\n",
      "Linear model: C = 0.1 score = -2522.862075357918\n",
      "Linear model: C = 0.5 score = -2311.141286159962\n",
      "Linear model: C = 1 score = -2269.6358718321585\n",
      "Linear model: C = 5 score = -2269.635742678031\n",
      "Linear model: C = 10 score = -2236.62280891752\n",
      "Linear model: C = 50 score = -2236.62280891752\n",
      "Linear model: C = 100 score = -2236.6229023225546\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3768.6403633136206\n",
      "Linear model: C = 5e-05 score = -3763.3387736333984\n",
      "Linear model: C = 0.0001 score = -3756.6351749329147\n",
      "Linear model: C = 0.0005 score = -3705.6635044194372\n",
      "Linear model: C = 0.001 score = -3649.280567529457\n",
      "Linear model: C = 0.005 score = -3347.0045831184043\n",
      "Linear model: C = 0.01 score = -3146.0398013974313\n",
      "Linear model: C = 0.05 score = -2701.2479351464467\n",
      "Linear model: C = 0.1 score = -2585.499252711761\n",
      "Linear model: C = 0.5 score = -2402.184903823541\n",
      "Linear model: C = 1 score = -2367.3711069008677\n",
      "Linear model: C = 5 score = -2367.3707559942295\n",
      "Linear model: C = 10 score = -2367.3698090764346\n",
      "Linear model: C = 50 score = -2326.518578465725\n",
      "Linear model: C = 100 score = -2326.5186018122827\n",
      "Linear model: C = 500 score = -2326.5185406980963\n",
      "Linear model: C = 1000 score = -2326.518577741919\n",
      "Linear model: C = 5000 score = -2326.5183585971267\n",
      "Linear model: C = 10000 score = -2326.518401914843\n",
      "Linear model: C = 50000 score = -2326.5183310565276\n",
      "Linear model: C = 100000 score = -2326.5183302978394\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3775.74330404483\n",
      "Linear model: C = 5e-05 score = -3770.443717231647\n",
      "Linear model: C = 0.0001 score = -3763.7588580246397\n",
      "Linear model: C = 0.0005 score = -3713.214443581226\n",
      "Linear model: C = 0.001 score = -3657.334177343415\n",
      "Linear model: C = 0.005 score = -3362.711043348447\n",
      "Linear model: C = 0.01 score = -3158.957250073767\n",
      "Linear model: C = 0.05 score = -2692.7531239781692\n",
      "Linear model: C = 0.1 score = -2570.1428752746015\n",
      "Linear model: C = 0.5 score = -2366.233665313699\n",
      "Linear model: C = 1 score = -2366.233117592609\n",
      "Linear model: C = 5 score = -2287.5315489487607\n",
      "Linear model: C = 10 score = -2287.531514170102\n",
      "Linear model: C = 50 score = -2287.5315073648\n",
      "Linear model: C = 100 score = -2279.4170901525667\n",
      "Linear model: C = 500 score = -2279.4172182624075\n",
      "Linear model: C = 1000 score = -2279.4172226902688\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3772.5832536623534\n",
      "Linear model: C = 5e-05 score = -3767.293553585222\n",
      "Linear model: C = 0.0001 score = -3760.8365016849507\n",
      "Linear model: C = 0.0005 score = -3710.829418746484\n",
      "Linear model: C = 0.001 score = -3654.8578962731285\n",
      "Linear model: C = 0.005 score = -3364.5326127415983\n",
      "Linear model: C = 0.01 score = -3165.540796593847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model: C = 0.05 score = -2723.119835282108\n",
      "Linear model: C = 0.1 score = -2599.157194974474\n",
      "Linear model: C = 0.5 score = -2412.5825188668528\n",
      "Linear model: C = 1 score = -2391.4906152293825\n",
      "Linear model: C = 5 score = -2379.7979906196338\n",
      "Linear model: C = 10 score = -2379.797780578827\n",
      "Linear model: C = 50 score = -2379.7978339044685\n",
      "Linear model: C = 100 score = -2379.7978019008538\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3692.679179995903\n",
      "Linear model: C = 5e-05 score = -3687.502493248629\n",
      "Linear model: C = 0.0001 score = -3681.046850020765\n",
      "Linear model: C = 0.0005 score = -3632.238424741053\n",
      "Linear model: C = 0.001 score = -3577.336278696815\n",
      "Linear model: C = 0.005 score = -3284.563430348953\n",
      "Linear model: C = 0.01 score = -3084.5870702023435\n",
      "Linear model: C = 0.05 score = -2638.6037694315596\n",
      "Linear model: C = 0.1 score = -2518.4819687845775\n",
      "Linear model: C = 0.5 score = -2323.082629009736\n",
      "Linear model: C = 1 score = -2281.9372942870805\n",
      "Linear model: C = 5 score = -2281.937025320397\n",
      "Linear model: C = 10 score = -2241.0607902055876\n",
      "Linear model: C = 50 score = -2241.060527725198\n",
      "Linear model: C = 100 score = -2241.0604379506203\n",
      "Linear model: C = 500 score = -2241.0603290540416\n",
      "Linear model: C = 1000 score = -2241.0601538826854\n",
      "Linear model: C = 5000 score = -2241.0600789269915\n",
      "Linear model: C = 10000 score = -2241.0600789269915\n",
      "Linear model: C = 50000 score = -2241.0600789269915\n",
      "Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "Time left 2564.0199971199036\n",
      "Start fitting Selector_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Selector_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2076.37\n",
      "[200]\tvalid's l1: 1909.45\n",
      "[300]\tvalid's l1: 1858.2\n",
      "[400]\tvalid's l1: 1828.06\n",
      "[500]\tvalid's l1: 1802.81\n",
      "[600]\tvalid's l1: 1786.69\n",
      "[700]\tvalid's l1: 1774.46\n",
      "[800]\tvalid's l1: 1765.07\n",
      "[900]\tvalid's l1: 1756.99\n",
      "[1000]\tvalid's l1: 1751.2\n",
      "[1100]\tvalid's l1: 1747.06\n",
      "[1200]\tvalid's l1: 1741.57\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1741.57\n",
      "Selector_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1765.62\n",
      "[200]\tvalid's l1: 1632.92\n",
      "[300]\tvalid's l1: 1604.79\n",
      "[400]\tvalid's l1: 1584.42\n",
      "[500]\tvalid's l1: 1565.72\n",
      "[600]\tvalid's l1: 1561.74\n",
      "[700]\tvalid's l1: 1558.72\n",
      "[800]\tvalid's l1: 1555.2\n",
      "[900]\tvalid's l1: 1553.34\n",
      "[1000]\tvalid's l1: 1545.54\n",
      "[1100]\tvalid's l1: 1543.96\n",
      "[1200]\tvalid's l1: 1540.49\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1540.49\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1831.81\n",
      "[200]\tvalid's l1: 1704.81\n",
      "[300]\tvalid's l1: 1662.11\n",
      "[400]\tvalid's l1: 1638.36\n",
      "[500]\tvalid's l1: 1629.85\n",
      "[600]\tvalid's l1: 1620.62\n",
      "[700]\tvalid's l1: 1618.27\n",
      "[800]\tvalid's l1: 1611.5\n",
      "[900]\tvalid's l1: 1605.39\n",
      "[1000]\tvalid's l1: 1595.89\n",
      "[1100]\tvalid's l1: 1591.5\n",
      "[1200]\tvalid's l1: 1584.34\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1584.34\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1783.23\n",
      "[200]\tvalid's l1: 1663.42\n",
      "[300]\tvalid's l1: 1624.5\n",
      "[400]\tvalid's l1: 1597.63\n",
      "[500]\tvalid's l1: 1584.02\n",
      "[600]\tvalid's l1: 1576.86\n",
      "[700]\tvalid's l1: 1573.82\n",
      "[800]\tvalid's l1: 1571.91\n",
      "[900]\tvalid's l1: 1567.54\n",
      "[1000]\tvalid's l1: 1562.39\n",
      "[1100]\tvalid's l1: 1561.55\n",
      "[1200]\tvalid's l1: 1557.78\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1557.78\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1785.6\n",
      "[200]\tvalid's l1: 1639.96\n",
      "[300]\tvalid's l1: 1598.66\n",
      "[400]\tvalid's l1: 1578.64\n",
      "[500]\tvalid's l1: 1568.64\n",
      "[600]\tvalid's l1: 1559.62\n",
      "[700]\tvalid's l1: 1555.21\n",
      "[800]\tvalid's l1: 1549.61\n",
      "[900]\tvalid's l1: 1542.36\n",
      "[1000]\tvalid's l1: 1539.45\n",
      "[1100]\tvalid's l1: 1537.96\n",
      "[1200]\tvalid's l1: 1534.75\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1534.75\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1727.58\n",
      "[200]\tvalid's l1: 1591.73\n",
      "[300]\tvalid's l1: 1553.5\n",
      "[400]\tvalid's l1: 1531.25\n",
      "[500]\tvalid's l1: 1522.87\n",
      "[600]\tvalid's l1: 1512.1\n",
      "[700]\tvalid's l1: 1504.96\n",
      "[800]\tvalid's l1: 1500.45\n",
      "[900]\tvalid's l1: 1495.92\n",
      "[1000]\tvalid's l1: 1491.76\n",
      "[1100]\tvalid's l1: 1486.21\n",
      "[1200]\tvalid's l1: 1482.37\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1482.37\n",
      "Lvl_0_Pipe_1_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 2202.2961052179335 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:29:21,435] (INFO): A new study created in memory with name: no-name-da621eb8-e26b-4791-a952-eb4e309156f3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1596.95\n",
      "[200]\tvalid's l1: 1471.22\n",
      "[300]\tvalid's l1: 1451.79\n",
      "[400]\tvalid's l1: 1442.79\n",
      "[500]\tvalid's l1: 1435.76\n",
      "[600]\tvalid's l1: 1428.32\n",
      "[700]\tvalid's l1: 1423.83\n",
      "[800]\tvalid's l1: 1420.81\n",
      "[900]\tvalid's l1: 1418.37\n",
      "[1000]\tvalid's l1: 1415.5\n",
      "[1100]\tvalid's l1: 1413.51\n",
      "[1200]\tvalid's l1: 1411.94\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1411.94\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:29:30,186] (INFO): Trial 0 finished with value: -1411.9419695695037 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 108, 'bagging_fraction': 0.5917173949330818, 'min_sum_hessian_in_leaf': 1.3145103232150122, 'reg_alpha': 0.0023531598052637494, 'reg_lambda': 0.00010291881465670109}. Best is trial 0 with value: -1411.9419695695037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1546.53\n",
      "[200]\tvalid's l1: 1431.62\n",
      "[300]\tvalid's l1: 1415.14\n",
      "[400]\tvalid's l1: 1408.07\n",
      "[500]\tvalid's l1: 1400.53\n",
      "[600]\tvalid's l1: 1396.82\n",
      "[700]\tvalid's l1: 1393.01\n",
      "[800]\tvalid's l1: 1390.75\n",
      "[900]\tvalid's l1: 1387.25\n",
      "[1000]\tvalid's l1: 1385.03\n",
      "[1100]\tvalid's l1: 1383.83\n",
      "[1200]\tvalid's l1: 1383.4\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1130]\tvalid's l1: 1383.31\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:29:43,749] (INFO): Trial 1 finished with value: -1383.3106173726044 and parameters: {'feature_fraction': 0.5499874579090014, 'num_leaves': 218, 'bagging_fraction': 0.9330880728874675, 'min_sum_hessian_in_leaf': 0.2537815508265665, 'reg_alpha': 0.023585940584142682, 'reg_lambda': 1.5320059381854043e-08}. Best is trial 1 with value: -1383.3106173726044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1568.84\n",
      "[200]\tvalid's l1: 1439.22\n",
      "[300]\tvalid's l1: 1419.62\n",
      "[400]\tvalid's l1: 1419.23\n",
      "[500]\tvalid's l1: 1446.68\n",
      "Early stopping, best iteration is:\n",
      "[362]\tvalid's l1: 1411.68\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:29:51,960] (INFO): Trial 2 finished with value: -1411.676633177408 and parameters: {'feature_fraction': 0.9849549260809971, 'num_leaves': 251, 'bagging_fraction': 0.9692763545078751, 'min_sum_hessian_in_leaf': 0.0010071984838809194, 'reg_alpha': 8.509499823666633, 'reg_lambda': 0.0036085571407386235}. Best is trial 1 with value: -1383.3106173726044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1537.96\n",
      "[200]\tvalid's l1: 1434.01\n",
      "[300]\tvalid's l1: 1415.4\n",
      "[400]\tvalid's l1: 1406.9\n",
      "[500]\tvalid's l1: 1401.29\n",
      "[600]\tvalid's l1: 1397.76\n",
      "[700]\tvalid's l1: 1393.92\n",
      "[800]\tvalid's l1: 1390.8\n",
      "[900]\tvalid's l1: 1388.45\n",
      "[1000]\tvalid's l1: 1387.05\n",
      "[1100]\tvalid's l1: 1386.12\n",
      "[1200]\tvalid's l1: 1384.97\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1384.97\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:30:07,809] (INFO): Trial 3 finished with value: -1384.9711950677074 and parameters: {'feature_fraction': 0.8058265802441404, 'num_leaves': 251, 'bagging_fraction': 0.5115312125207079, 'min_sum_hessian_in_leaf': 0.12563152773938666, 'reg_alpha': 3.9696182670988566e-05, 'reg_lambda': 2.630213296503227e-08}. Best is trial 1 with value: -1383.3106173726044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1769.83\n",
      "[200]\tvalid's l1: 1634.68\n",
      "[300]\tvalid's l1: 1590.21\n",
      "[400]\tvalid's l1: 1568.01\n",
      "[500]\tvalid's l1: 1560.5\n",
      "[600]\tvalid's l1: 1545.07\n",
      "[700]\tvalid's l1: 1540.16\n",
      "[800]\tvalid's l1: 1532.96\n",
      "[900]\tvalid's l1: 1526.88\n",
      "[1000]\tvalid's l1: 1523.75\n",
      "[1100]\tvalid's l1: 1519.09\n",
      "[1200]\tvalid's l1: 1516.27\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1516.27\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:30:13,090] (INFO): Trial 4 finished with value: -1516.2673920208103 and parameters: {'feature_fraction': 0.9868777594207296, 'num_leaves': 30, 'bagging_fraction': 0.728034992108518, 'min_sum_hessian_in_leaf': 1.382623217936987, 'reg_alpha': 6.267062696005991e-07, 'reg_lambda': 0.00042472707398058225}. Best is trial 1 with value: -1383.3106173726044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1543.92\n",
      "[200]\tvalid's l1: 1428.68\n",
      "[300]\tvalid's l1: 1416.49\n",
      "[400]\tvalid's l1: 1409.67\n",
      "[500]\tvalid's l1: 1404.85\n",
      "[600]\tvalid's l1: 1401.2\n",
      "[700]\tvalid's l1: 1395.78\n",
      "[800]\tvalid's l1: 1391.72\n",
      "[900]\tvalid's l1: 1388\n",
      "[1000]\tvalid's l1: 1387.48\n",
      "[1100]\tvalid's l1: 1386.31\n",
      "[1200]\tvalid's l1: 1383.5\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1383.5\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:30:23,494] (INFO): Trial 5 finished with value: -1383.496549290186 and parameters: {'feature_fraction': 0.7962072844310213, 'num_leaves': 146, 'bagging_fraction': 0.9299702033681603, 'min_sum_hessian_in_leaf': 0.5262961031076743, 'reg_alpha': 0.00011336872639641431, 'reg_lambda': 1.316390230170444e-08}. Best is trial 1 with value: -1383.3106173726044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1780.61\n",
      "[200]\tvalid's l1: 1649.17\n",
      "[300]\tvalid's l1: 1615.48\n",
      "[400]\tvalid's l1: 1591.57\n",
      "[500]\tvalid's l1: 1581.36\n",
      "[600]\tvalid's l1: 1571.84\n",
      "[700]\tvalid's l1: 1565.2\n",
      "[800]\tvalid's l1: 1561.12\n",
      "[900]\tvalid's l1: 1559.57\n",
      "[1000]\tvalid's l1: 1555.38\n",
      "[1100]\tvalid's l1: 1553.34\n",
      "[1200]\tvalid's l1: 1548.18\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1548.18\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:30:28,134] (INFO): Trial 6 finished with value: -1548.1776135306065 and parameters: {'feature_fraction': 0.9711008778424264, 'num_leaves': 29, 'bagging_fraction': 0.9041986740582306, 'min_sum_hessian_in_leaf': 0.01653693718282442, 'reg_alpha': 7.569183361880229e-08, 'reg_lambda': 0.014391207615728067}. Best is trial 1 with value: -1383.3106173726044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1532.86\n",
      "[200]\tvalid's l1: 1422.11\n",
      "[300]\tvalid's l1: 1408.36\n",
      "[400]\tvalid's l1: 1399.67\n",
      "[500]\tvalid's l1: 1394.48\n",
      "[600]\tvalid's l1: 1391.73\n",
      "[700]\tvalid's l1: 1389.13\n",
      "[800]\tvalid's l1: 1385.41\n",
      "[900]\tvalid's l1: 1383.04\n",
      "[1000]\tvalid's l1: 1381.11\n",
      "[1100]\tvalid's l1: 1379.36\n",
      "[1200]\tvalid's l1: 1378.72\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1378.67\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:30:40,141] (INFO): Trial 7 finished with value: -1378.6655925419946 and parameters: {'feature_fraction': 0.7200762468698007, 'num_leaves': 214, 'bagging_fraction': 0.8049983288913105, 'min_sum_hessian_in_leaf': 2.1516897298083326, 'reg_alpha': 3.6331378936352306e-07, 'reg_lambda': 3.307847415252541e-05}. Best is trial 7 with value: -1378.6655925419946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1579.01\n",
      "[200]\tvalid's l1: 1455.11\n",
      "[300]\tvalid's l1: 1438.33\n",
      "[400]\tvalid's l1: 1428.04\n",
      "[500]\tvalid's l1: 1421.73\n",
      "[600]\tvalid's l1: 1414.91\n",
      "[700]\tvalid's l1: 1411.02\n",
      "[800]\tvalid's l1: 1407.68\n",
      "[900]\tvalid's l1: 1404.69\n",
      "[1000]\tvalid's l1: 1401.58\n",
      "[1100]\tvalid's l1: 1400.3\n",
      "[1200]\tvalid's l1: 1397.17\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1397.17\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:30:48,167] (INFO): Trial 8 finished with value: -1397.1653611351164 and parameters: {'feature_fraction': 0.5911180438940311, 'num_leaves': 147, 'bagging_fraction': 0.6558555380447055, 'min_sum_hessian_in_leaf': 0.12030178871154672, 'reg_alpha': 0.0008325158565947976, 'reg_lambda': 4.609885087947832e-07}. Best is trial 7 with value: -1378.6655925419946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1546.42\n",
      "[200]\tvalid's l1: 1429.35\n",
      "[300]\tvalid's l1: 1412.27\n",
      "[400]\tvalid's l1: 1402.98\n",
      "[500]\tvalid's l1: 1396.81\n",
      "[600]\tvalid's l1: 1394.81\n",
      "[700]\tvalid's l1: 1393.52\n",
      "[800]\tvalid's l1: 1391.25\n",
      "[900]\tvalid's l1: 1389.23\n",
      "[1000]\tvalid's l1: 1387.78\n",
      "[1100]\tvalid's l1: 1386.16\n",
      "[1200]\tvalid's l1: 1385.4\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1385.34\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:31:04,025] (INFO): Trial 9 finished with value: -1385.3405271345316 and parameters: {'feature_fraction': 0.9847923138822793, 'num_leaves': 233, 'bagging_fraction': 0.7248770666848828, 'min_sum_hessian_in_leaf': 0.03807158379249393, 'reg_alpha': 2.1874079799487576, 'reg_lambda': 0.0351113851431067}. Best is trial 7 with value: -1378.6655925419946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1546.46\n",
      "[200]\tvalid's l1: 1431.8\n",
      "[300]\tvalid's l1: 1415.28\n",
      "[400]\tvalid's l1: 1408.5\n",
      "[500]\tvalid's l1: 1403.08\n",
      "[600]\tvalid's l1: 1398.65\n",
      "[700]\tvalid's l1: 1396.17\n",
      "[800]\tvalid's l1: 1392.64\n",
      "[900]\tvalid's l1: 1389.54\n",
      "[1000]\tvalid's l1: 1387.07\n",
      "[1100]\tvalid's l1: 1386.07\n",
      "[1200]\tvalid's l1: 1384.13\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1384.13\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:31:15,119] (INFO): Trial 10 finished with value: -1384.1312732622357 and parameters: {'feature_fraction': 0.6591377620440741, 'num_leaves': 189, 'bagging_fraction': 0.8480589016791605, 'min_sum_hessian_in_leaf': 6.467021580848944, 'reg_alpha': 1.7238246488428573e-08, 'reg_lambda': 6.423608282647379e-06}. Best is trial 7 with value: -1378.6655925419946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1565.75\n",
      "[200]\tvalid's l1: 1448.48\n",
      "[300]\tvalid's l1: 1427.26\n",
      "[400]\tvalid's l1: 1417.75\n",
      "[500]\tvalid's l1: 1412.32\n",
      "[600]\tvalid's l1: 1407.48\n",
      "[700]\tvalid's l1: 1404.28\n",
      "[800]\tvalid's l1: 1399.4\n",
      "[900]\tvalid's l1: 1397.16\n",
      "[1000]\tvalid's l1: 1396.42\n",
      "[1100]\tvalid's l1: 1395.18\n",
      "[1200]\tvalid's l1: 1393.15\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1393.13\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:31:26,215] (INFO): Trial 11 finished with value: -1393.1344601214741 and parameters: {'feature_fraction': 0.5115645892995797, 'num_leaves': 195, 'bagging_fraction': 0.8723610395107925, 'min_sum_hessian_in_leaf': 9.945747781351205, 'reg_alpha': 0.04977584413813994, 'reg_lambda': 0.6487469013672745}. Best is trial 7 with value: -1378.6655925419946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1556.89\n",
      "[200]\tvalid's l1: 1435.35\n",
      "[300]\tvalid's l1: 1418.49\n",
      "[400]\tvalid's l1: 1409.51\n",
      "[500]\tvalid's l1: 1404.14\n",
      "[600]\tvalid's l1: 1399.35\n",
      "[700]\tvalid's l1: 1395.25\n",
      "[800]\tvalid's l1: 1392.99\n",
      "[900]\tvalid's l1: 1390.27\n",
      "[1000]\tvalid's l1: 1388.21\n",
      "[1100]\tvalid's l1: 1386.66\n",
      "[1200]\tvalid's l1: 1384.96\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1384.95\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:31:37,512] (INFO): Trial 12 finished with value: -1384.9450820052873 and parameters: {'feature_fraction': 0.5470571599260617, 'num_leaves': 205, 'bagging_fraction': 0.7968437443081334, 'min_sum_hessian_in_leaf': 0.4748981710374227, 'reg_alpha': 0.07367743907015423, 'reg_lambda': 1.1430779873371454e-06}. Best is trial 7 with value: -1378.6655925419946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1595.18\n",
      "[200]\tvalid's l1: 1471.02\n",
      "[300]\tvalid's l1: 1458.55\n",
      "[400]\tvalid's l1: 1453.52\n",
      "[500]\tvalid's l1: 1450.9\n",
      "[600]\tvalid's l1: 1442.93\n",
      "[700]\tvalid's l1: 1437.34\n",
      "[800]\tvalid's l1: 1434.04\n",
      "[900]\tvalid's l1: 1431.5\n",
      "[1000]\tvalid's l1: 1430.26\n",
      "[1100]\tvalid's l1: 1429.29\n",
      "[1200]\tvalid's l1: 1427.77\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1186]\tvalid's l1: 1427.74\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:31:45,934] (INFO): Trial 13 finished with value: -1427.7417669622007 and parameters: {'feature_fraction': 0.8495620210653407, 'num_leaves': 97, 'bagging_fraction': 0.9913239280399375, 'min_sum_hessian_in_leaf': 3.825519851828592, 'reg_alpha': 3.6066727494657723e-06, 'reg_lambda': 4.588492805253924}. Best is trial 7 with value: -1378.6655925419946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1527.19\n",
      "[200]\tvalid's l1: 1414.1\n",
      "[300]\tvalid's l1: 1397.64\n",
      "[400]\tvalid's l1: 1390.14\n",
      "[500]\tvalid's l1: 1386.92\n",
      "[600]\tvalid's l1: 1384.23\n",
      "[700]\tvalid's l1: 1381.06\n",
      "[800]\tvalid's l1: 1378.74\n",
      "[900]\tvalid's l1: 1376.51\n",
      "[1000]\tvalid's l1: 1374.09\n",
      "[1100]\tvalid's l1: 1371.91\n",
      "[1200]\tvalid's l1: 1370.5\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1370.47\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:31:58,619] (INFO): Trial 14 finished with value: -1370.4748752609732 and parameters: {'feature_fraction': 0.6896424261359831, 'num_leaves': 218, 'bagging_fraction': 0.8076472671362661, 'min_sum_hessian_in_leaf': 0.0053122436494873575, 'reg_alpha': 0.07127936003357555, 'reg_lambda': 2.3436002023739304e-05}. Best is trial 14 with value: -1370.4748752609732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1552.1\n",
      "[200]\tvalid's l1: 1437.03\n",
      "[300]\tvalid's l1: 1418.67\n",
      "[400]\tvalid's l1: 1412.12\n",
      "[500]\tvalid's l1: 1407.73\n",
      "[600]\tvalid's l1: 1403.19\n",
      "[700]\tvalid's l1: 1398.96\n",
      "[800]\tvalid's l1: 1395.22\n",
      "[900]\tvalid's l1: 1393.46\n",
      "[1000]\tvalid's l1: 1390.35\n",
      "[1100]\tvalid's l1: 1388.1\n",
      "[1200]\tvalid's l1: 1386.97\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1386.97\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:32:09,377] (INFO): Trial 15 finished with value: -1386.9669699994288 and parameters: {'feature_fraction': 0.7011941668104474, 'num_leaves': 168, 'bagging_fraction': 0.7958032638664104, 'min_sum_hessian_in_leaf': 0.0014477417609424813, 'reg_alpha': 0.7611370479957396, 'reg_lambda': 2.4308143402885813e-05}. Best is trial 14 with value: -1370.4748752609732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1540.91\n",
      "[200]\tvalid's l1: 1428.61\n",
      "[300]\tvalid's l1: 1411.91\n",
      "[400]\tvalid's l1: 1405.57\n",
      "[500]\tvalid's l1: 1399.28\n",
      "[600]\tvalid's l1: 1394.97\n",
      "[700]\tvalid's l1: 1391.82\n",
      "[800]\tvalid's l1: 1389.46\n",
      "[900]\tvalid's l1: 1387.88\n",
      "[1000]\tvalid's l1: 1385.61\n",
      "[1100]\tvalid's l1: 1383.97\n",
      "[1200]\tvalid's l1: 1382.87\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1148]\tvalid's l1: 1382.81\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:32:22,729] (INFO): Trial 16 finished with value: -1382.8084997452402 and parameters: {'feature_fraction': 0.6236524948451638, 'num_leaves': 254, 'bagging_fraction': 0.6626269744248692, 'min_sum_hessian_in_leaf': 0.004472338987639301, 'reg_alpha': 5.7042469084709874e-06, 'reg_lambda': 0.0003530698951121962}. Best is trial 14 with value: -1370.4748752609732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1550.08\n",
      "[200]\tvalid's l1: 1430.4\n",
      "[300]\tvalid's l1: 1415.39\n",
      "[400]\tvalid's l1: 1408.84\n",
      "[500]\tvalid's l1: 1402.39\n",
      "[600]\tvalid's l1: 1399.4\n",
      "[700]\tvalid's l1: 1396.85\n",
      "[800]\tvalid's l1: 1394.58\n",
      "[900]\tvalid's l1: 1392.51\n",
      "[1000]\tvalid's l1: 1390.51\n",
      "[1100]\tvalid's l1: 1386.4\n",
      "[1200]\tvalid's l1: 1384.86\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1384.86\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:32:33,884] (INFO): Trial 17 finished with value: -1384.8594332782584 and parameters: {'feature_fraction': 0.7501925199475601, 'num_leaves': 172, 'bagging_fraction': 0.7849660697695989, 'min_sum_hessian_in_leaf': 0.0070454530640168146, 'reg_alpha': 0.0029061394388440833, 'reg_lambda': 5.172597459156187e-07}. Best is trial 14 with value: -1370.4748752609732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1528.83\n",
      "[200]\tvalid's l1: 1415.99\n",
      "[300]\tvalid's l1: 1399.54\n",
      "[400]\tvalid's l1: 1393.16\n",
      "[500]\tvalid's l1: 1389.65\n",
      "[600]\tvalid's l1: 1385.33\n",
      "[700]\tvalid's l1: 1381.09\n",
      "[800]\tvalid's l1: 1379.59\n",
      "[900]\tvalid's l1: 1377.82\n",
      "[1000]\tvalid's l1: 1376.9\n",
      "[1100]\tvalid's l1: 1376.6\n",
      "[1200]\tvalid's l1: 1375.81\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1196]\tvalid's l1: 1375.8\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:32:47,300] (INFO): Trial 18 finished with value: -1375.795047195141 and parameters: {'feature_fraction': 0.8626232813873017, 'num_leaves': 220, 'bagging_fraction': 0.841003339317699, 'min_sum_hessian_in_leaf': 0.03304048872978159, 'reg_alpha': 0.33242874212976203, 'reg_lambda': 1.8551610054850372e-05}. Best is trial 14 with value: -1370.4748752609732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1574.08\n",
      "[200]\tvalid's l1: 1450.32\n",
      "[300]\tvalid's l1: 1436.1\n",
      "[400]\tvalid's l1: 1430\n",
      "[500]\tvalid's l1: 1426.12\n",
      "[600]\tvalid's l1: 1422.49\n",
      "[700]\tvalid's l1: 1419.13\n",
      "[800]\tvalid's l1: 1417.35\n",
      "[900]\tvalid's l1: 1414.86\n",
      "[1000]\tvalid's l1: 1413.37\n",
      "[1100]\tvalid's l1: 1411.88\n",
      "[1200]\tvalid's l1: 1409.01\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1409.01\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:32:55,819] (INFO): Trial 19 finished with value: -1409.007901980683 and parameters: {'feature_fraction': 0.8993685700342023, 'num_leaves': 113, 'bagging_fraction': 0.8506267550784883, 'min_sum_hessian_in_leaf': 0.019840982165223613, 'reg_alpha': 1.1816401311581373, 'reg_lambda': 5.175733393661284e-06}. Best is trial 14 with value: -1370.4748752609732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1619.37\n",
      "[200]\tvalid's l1: 1484.56\n",
      "[300]\tvalid's l1: 1466.34\n",
      "[400]\tvalid's l1: 1457.74\n",
      "[500]\tvalid's l1: 1451.16\n",
      "[600]\tvalid's l1: 1445.98\n",
      "[700]\tvalid's l1: 1439.79\n",
      "[800]\tvalid's l1: 1436.91\n",
      "[900]\tvalid's l1: 1434.91\n",
      "[1000]\tvalid's l1: 1433.51\n",
      "[1100]\tvalid's l1: 1429.99\n",
      "[1200]\tvalid's l1: 1428.57\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1428.57\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:33:02,341] (INFO): Trial 20 finished with value: -1428.5740946661253 and parameters: {'feature_fraction': 0.907081450957954, 'num_leaves': 79, 'bagging_fraction': 0.7020358933404531, 'min_sum_hessian_in_leaf': 0.0031280913002477762, 'reg_alpha': 0.21829066464570127, 'reg_lambda': 7.248715717895558e-08}. Best is trial 14 with value: -1370.4748752609732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1518.02\n",
      "[200]\tvalid's l1: 1408.95\n",
      "[300]\tvalid's l1: 1394.25\n",
      "[400]\tvalid's l1: 1387.01\n",
      "[500]\tvalid's l1: 1383.23\n",
      "[600]\tvalid's l1: 1384.38\n",
      "[700]\tvalid's l1: 1380.77\n",
      "[800]\tvalid's l1: 1378.3\n",
      "[900]\tvalid's l1: 1376.06\n",
      "[1000]\tvalid's l1: 1374.79\n",
      "[1100]\tvalid's l1: 1374.04\n",
      "[1200]\tvalid's l1: 1372.45\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1196]\tvalid's l1: 1372.42\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:33:16,853] (INFO): Trial 21 finished with value: -1372.4217373274926 and parameters: {'feature_fraction': 0.7508446540222204, 'num_leaves': 227, 'bagging_fraction': 0.8218585678588612, 'min_sum_hessian_in_leaf': 0.04495336691037154, 'reg_alpha': 0.009237006907723225, 'reg_lambda': 3.7918895939722e-05}. Best is trial 14 with value: -1370.4748752609732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1523.58\n",
      "[200]\tvalid's l1: 1411.75\n",
      "[300]\tvalid's l1: 1397.87\n",
      "[400]\tvalid's l1: 1391.28\n",
      "[500]\tvalid's l1: 1388.08\n",
      "[600]\tvalid's l1: 1384.21\n",
      "[700]\tvalid's l1: 1382.78\n",
      "[800]\tvalid's l1: 1381.29\n",
      "[900]\tvalid's l1: 1379.19\n",
      "[1000]\tvalid's l1: 1376.92\n",
      "[1100]\tvalid's l1: 1375.61\n",
      "[1200]\tvalid's l1: 1374.29\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1374.24\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:33:31,020] (INFO): Trial 22 finished with value: -1374.2415359924992 and parameters: {'feature_fraction': 0.7555032411482943, 'num_leaves': 229, 'bagging_fraction': 0.8403939512492167, 'min_sum_hessian_in_leaf': 0.043471750811833736, 'reg_alpha': 0.009348963785890597, 'reg_lambda': 0.0010064266390864844}. Best is trial 14 with value: -1370.4748752609732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1509.8\n",
      "[200]\tvalid's l1: 1400.45\n",
      "[300]\tvalid's l1: 1385.51\n",
      "[400]\tvalid's l1: 1379.74\n",
      "[500]\tvalid's l1: 1375.05\n",
      "[600]\tvalid's l1: 1373.39\n",
      "[700]\tvalid's l1: 1371.2\n",
      "[800]\tvalid's l1: 1367.49\n",
      "[900]\tvalid's l1: 1365.95\n",
      "[1000]\tvalid's l1: 1363.92\n",
      "[1100]\tvalid's l1: 1362.33\n",
      "[1200]\tvalid's l1: 1361.13\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1361.09\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:33:45,955] (INFO): Trial 23 finished with value: -1361.0892363110004 and parameters: {'feature_fraction': 0.7589103996105991, 'num_leaves': 238, 'bagging_fraction': 0.8906734454479195, 'min_sum_hessian_in_leaf': 0.054700690134589745, 'reg_alpha': 0.011370692054557608, 'reg_lambda': 0.0012187268274637252}. Best is trial 23 with value: -1361.0892363110004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1514.22\n",
      "[200]\tvalid's l1: 1406.09\n",
      "[300]\tvalid's l1: 1393.59\n",
      "[400]\tvalid's l1: 1385.82\n",
      "[500]\tvalid's l1: 1381.33\n",
      "[600]\tvalid's l1: 1376.72\n",
      "[700]\tvalid's l1: 1372.97\n",
      "[800]\tvalid's l1: 1370.1\n",
      "[900]\tvalid's l1: 1368.6\n",
      "[1000]\tvalid's l1: 1367.35\n",
      "[1100]\tvalid's l1: 1364.37\n",
      "[1200]\tvalid's l1: 1361.62\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1361.62\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:34:00,988] (INFO): Trial 24 finished with value: -1361.6234789693985 and parameters: {'feature_fraction': 0.7902054810477598, 'num_leaves': 236, 'bagging_fraction': 0.8920946102348388, 'min_sum_hessian_in_leaf': 0.009818530139012401, 'reg_alpha': 0.007405688651165403, 'reg_lambda': 0.0039663052538989685}. Best is trial 23 with value: -1361.0892363110004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1515.47\n",
      "[200]\tvalid's l1: 1402.85\n",
      "[300]\tvalid's l1: 1392.45\n",
      "[400]\tvalid's l1: 1386.78\n",
      "[500]\tvalid's l1: 1379.77\n",
      "[600]\tvalid's l1: 1376.52\n",
      "[700]\tvalid's l1: 1374.23\n",
      "[800]\tvalid's l1: 1373.42\n",
      "[900]\tvalid's l1: 1372.39\n",
      "[1000]\tvalid's l1: 1370.2\n",
      "[1100]\tvalid's l1: 1368.7\n",
      "[1200]\tvalid's l1: 1369.53\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1120]\tvalid's l1: 1368.09\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:34:17,125] (INFO): Trial 25 finished with value: -1368.0909259647349 and parameters: {'feature_fraction': 0.8009135039449025, 'num_leaves': 247, 'bagging_fraction': 0.8965750609883641, 'min_sum_hessian_in_leaf': 0.009720651557967884, 'reg_alpha': 0.00031500103352303247, 'reg_lambda': 0.17062056989118826}. Best is trial 23 with value: -1361.0892363110004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1511.63\n",
      "[200]\tvalid's l1: 1398.98\n",
      "[300]\tvalid's l1: 1385.18\n",
      "[400]\tvalid's l1: 1380.58\n",
      "[500]\tvalid's l1: 1377.67\n",
      "[600]\tvalid's l1: 1373.49\n",
      "[700]\tvalid's l1: 1369.39\n",
      "[800]\tvalid's l1: 1368.32\n",
      "[900]\tvalid's l1: 1366.39\n",
      "[1000]\tvalid's l1: 1365.15\n",
      "[1100]\tvalid's l1: 1364.68\n",
      "[1200]\tvalid's l1: 1363.56\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1188]\tvalid's l1: 1363.5\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:34:32,369] (INFO): Trial 26 finished with value: -1363.5034352197597 and parameters: {'feature_fraction': 0.8016847057927835, 'num_leaves': 242, 'bagging_fraction': 0.8970758864682553, 'min_sum_hessian_in_leaf': 0.010999946050604292, 'reg_alpha': 0.0003251452885491664, 'reg_lambda': 0.17241340929175047}. Best is trial 23 with value: -1361.0892363110004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1422.56\n",
      "[200]\tvalid's l1: 1398.67\n",
      "[300]\tvalid's l1: 1386.36\n",
      "[400]\tvalid's l1: 1380.91\n",
      "[500]\tvalid's l1: 1376.29\n",
      "[600]\tvalid's l1: 1374.26\n",
      "[700]\tvalid's l1: 1371.69\n",
      "[800]\tvalid's l1: 1370.07\n",
      "[900]\tvalid's l1: 1367.68\n",
      "[1000]\tvalid's l1: 1366.08\n",
      "[1100]\tvalid's l1: 1364.99\n",
      "[1200]\tvalid's l1: 1364.56\n",
      "[1300]\tvalid's l1: 1366.32\n",
      "Early stopping, best iteration is:\n",
      "[1200]\tvalid's l1: 1364.56\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1493.47\n",
      "[200]\tvalid's l1: 1456.42\n",
      "[300]\tvalid's l1: 1451.84\n",
      "[400]\tvalid's l1: 1445.58\n",
      "[500]\tvalid's l1: 1438.93\n",
      "[600]\tvalid's l1: 1435.21\n",
      "[700]\tvalid's l1: 1430.65\n",
      "[800]\tvalid's l1: 1426.87\n",
      "[900]\tvalid's l1: 1424.2\n",
      "[1000]\tvalid's l1: 1422.05\n",
      "[1100]\tvalid's l1: 1420.1\n",
      "[1200]\tvalid's l1: 1418.69\n",
      "[1300]\tvalid's l1: 1417.55\n",
      "[1400]\tvalid's l1: 1416.52\n",
      "[1500]\tvalid's l1: 1415.5\n",
      "[1600]\tvalid's l1: 1414.68\n",
      "[1700]\tvalid's l1: 1412.9\n",
      "[1800]\tvalid's l1: 1411.7\n",
      "[1900]\tvalid's l1: 1410.47\n",
      "[2000]\tvalid's l1: 1409.69\n",
      "[2100]\tvalid's l1: 1408.99\n",
      "[2200]\tvalid's l1: 1408.1\n",
      "[2300]\tvalid's l1: 1407.32\n",
      "[2400]\tvalid's l1: 1406.33\n",
      "[2500]\tvalid's l1: 1405.53\n",
      "[2600]\tvalid's l1: 1405.16\n",
      "[2700]\tvalid's l1: 1404.21\n",
      "[2800]\tvalid's l1: 1403.57\n",
      "[2900]\tvalid's l1: 1402.64\n",
      "[3000]\tvalid's l1: 1402.29\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid's l1: 1402.29\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1456.43\n",
      "[200]\tvalid's l1: 1421.86\n",
      "[300]\tvalid's l1: 1412.41\n",
      "[400]\tvalid's l1: 1405.03\n",
      "[500]\tvalid's l1: 1398.81\n",
      "[600]\tvalid's l1: 1394.61\n",
      "[700]\tvalid's l1: 1392.03\n",
      "[800]\tvalid's l1: 1390.48\n",
      "[900]\tvalid's l1: 1388.28\n",
      "[1000]\tvalid's l1: 1387.02\n",
      "[1100]\tvalid's l1: 1386.12\n",
      "[1200]\tvalid's l1: 1384.27\n",
      "[1300]\tvalid's l1: 1382.05\n",
      "[1400]\tvalid's l1: 1380.51\n",
      "[1500]\tvalid's l1: 1378.87\n",
      "[1600]\tvalid's l1: 1377.82\n",
      "[1700]\tvalid's l1: 1376.22\n",
      "[1800]\tvalid's l1: 1375.72\n",
      "[1900]\tvalid's l1: 1374.87\n",
      "[2000]\tvalid's l1: 1374.6\n",
      "[2100]\tvalid's l1: 1374.12\n",
      "[2200]\tvalid's l1: 1374.07\n",
      "[2300]\tvalid's l1: 1373.8\n",
      "[2400]\tvalid's l1: 1373.09\n",
      "[2500]\tvalid's l1: 1372.67\n",
      "[2600]\tvalid's l1: 1372.18\n",
      "[2700]\tvalid's l1: 1371.79\n",
      "[2800]\tvalid's l1: 1371.26\n",
      "[2900]\tvalid's l1: 1370.81\n",
      "[3000]\tvalid's l1: 1370.72\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2988]\tvalid's l1: 1370.59\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1433.68\n",
      "[200]\tvalid's l1: 1399.52\n",
      "[300]\tvalid's l1: 1388.45\n",
      "[400]\tvalid's l1: 1383.49\n",
      "[500]\tvalid's l1: 1381.84\n",
      "[600]\tvalid's l1: 1375.89\n",
      "[700]\tvalid's l1: 1372.32\n",
      "[800]\tvalid's l1: 1369.51\n",
      "[900]\tvalid's l1: 1366.17\n",
      "[1000]\tvalid's l1: 1365.13\n",
      "[1100]\tvalid's l1: 1364.34\n",
      "[1200]\tvalid's l1: 1363.55\n",
      "[1300]\tvalid's l1: 1363.29\n",
      "[1400]\tvalid's l1: 1362.64\n",
      "[1500]\tvalid's l1: 1361.02\n",
      "[1600]\tvalid's l1: 1360.13\n",
      "[1700]\tvalid's l1: 1359.37\n",
      "[1800]\tvalid's l1: 1358.08\n",
      "[1900]\tvalid's l1: 1357.03\n",
      "[2000]\tvalid's l1: 1355.95\n",
      "[2100]\tvalid's l1: 1355.29\n",
      "[2200]\tvalid's l1: 1354.73\n",
      "[2300]\tvalid's l1: 1354.62\n",
      "[2400]\tvalid's l1: 1354.4\n",
      "[2500]\tvalid's l1: 1353.93\n",
      "[2600]\tvalid's l1: 1353.23\n",
      "[2700]\tvalid's l1: 1352.69\n",
      "[2800]\tvalid's l1: 1352.28\n",
      "[2900]\tvalid's l1: 1352.06\n",
      "[3000]\tvalid's l1: 1351.34\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid's l1: 1351.34\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1371.09\n",
      "[200]\tvalid's l1: 1332.18\n",
      "[300]\tvalid's l1: 1320.71\n",
      "[400]\tvalid's l1: 1313.78\n",
      "[500]\tvalid's l1: 1308.7\n",
      "[600]\tvalid's l1: 1304.71\n",
      "[700]\tvalid's l1: 1303.01\n",
      "[800]\tvalid's l1: 1300.69\n",
      "[900]\tvalid's l1: 1298.66\n",
      "[1000]\tvalid's l1: 1296.43\n",
      "[1100]\tvalid's l1: 1295.06\n",
      "[1200]\tvalid's l1: 1293.93\n",
      "[1300]\tvalid's l1: 1292.47\n",
      "[1400]\tvalid's l1: 1290.74\n",
      "[1500]\tvalid's l1: 1289.67\n",
      "[1600]\tvalid's l1: 1289.16\n",
      "[1700]\tvalid's l1: 1288.77\n",
      "[1800]\tvalid's l1: 1288.48\n",
      "[1900]\tvalid's l1: 1287.56\n",
      "[2000]\tvalid's l1: 1287.29\n",
      "[2100]\tvalid's l1: 1286.44\n",
      "[2200]\tvalid's l1: 1286.12\n",
      "[2300]\tvalid's l1: 1285.88\n",
      "[2400]\tvalid's l1: 1284.85\n",
      "[2500]\tvalid's l1: 1283.1\n",
      "[2600]\tvalid's l1: 1282.75\n",
      "[2700]\tvalid's l1: 1282.35\n",
      "[2800]\tvalid's l1: 1282.2\n",
      "[2900]\tvalid's l1: 1282.09\n",
      "Early stopping, best iteration is:\n",
      "[2809]\tvalid's l1: 1282.05\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 2063.0931344032288\n",
      "Blending: Optimization starts with equal weights and score -1617.3129921917262\n",
      "Blending, iter 0: score = -1354.1704915410485, weights = [0. 0. 1.]\n",
      "Blending, iter 1: score = -1354.1704915410485, weights = [0. 0. 1.]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 536.56 seconds.\n",
      "Current random state: {'reader_params': {'random_state': 45}, 'general_params': {'return_all_predictions': False}}\n",
      "Found reader_params in kwargs, need to combine\n",
      "Merged variant for reader_params = {'n_jobs': 8, 'cv': 5, 'random_state': 45}\n",
      "Found general_params in kwargs, need to combine\n",
      "Merged variant for general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']], 'return_all_predictions': False}\n",
      "Start automl preset with listed constraints:\n",
      "- time: 2062.9229969978333 seconds\n",
      "- cpus: 8 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (34994, 145)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 2053.966593027115 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3799.348315454105\n",
      "Linear model: C = 5e-05 score = -3791.87655459569\n",
      "Linear model: C = 0.0001 score = -3782.4950314470148\n",
      "Linear model: C = 0.0005 score = -3710.9604279405985\n",
      "Linear model: C = 0.001 score = -3630.6425205344626\n",
      "Linear model: C = 0.005 score = -3198.3290122258763\n",
      "Linear model: C = 0.01 score = -2943.8031991837893\n",
      "Linear model: C = 0.05 score = -2587.2887720973818\n",
      "Linear model: C = 0.1 score = -2479.6046772583636\n",
      "Linear model: C = 0.5 score = -2314.263441683991\n",
      "Linear model: C = 1 score = -2314.263441683991\n",
      "Linear model: C = 5 score = -2236.5419447814793\n",
      "Linear model: C = 10 score = -2236.541898031135\n",
      "Linear model: C = 50 score = -2236.541735119199\n",
      "Linear model: C = 100 score = -2236.5416318318694\n",
      "Linear model: C = 500 score = -2236.541524279644\n",
      "Linear model: C = 1000 score = -2236.541457137375\n",
      "Linear model: C = 5000 score = -2236.5410939715457\n",
      "Linear model: C = 10000 score = -2236.5410019538967\n",
      "Linear model: C = 50000 score = -2236.540832383818\n",
      "Linear model: C = 100000 score = -2236.540696126799\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3686.1892770046948\n",
      "Linear model: C = 5e-05 score = -3678.7788626263014\n",
      "Linear model: C = 0.0001 score = -3669.45856805576\n",
      "Linear model: C = 0.0005 score = -3598.2980805642437\n",
      "Linear model: C = 0.001 score = -3519.102482169607\n",
      "Linear model: C = 0.005 score = -3096.674037137599\n",
      "Linear model: C = 0.01 score = -2844.89290910054\n",
      "Linear model: C = 0.05 score = -2504.035663220487\n",
      "Linear model: C = 0.1 score = -2400.7023628617476\n",
      "Linear model: C = 0.5 score = -2231.8645133606997\n",
      "Linear model: C = 1 score = -2196.7722706735467\n",
      "Linear model: C = 5 score = -2196.7719424166394\n",
      "Linear model: C = 10 score = -2196.7713582725214\n",
      "Linear model: C = 50 score = -2152.8403330640904\n",
      "Linear model: C = 100 score = -2152.8403403212264\n",
      "Linear model: C = 500 score = -2152.840451968297\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3855.079233626567\n",
      "Linear model: C = 5e-05 score = -3847.4865079777023\n",
      "Linear model: C = 0.0001 score = -3838.0419432826343\n",
      "Linear model: C = 0.0005 score = -3765.8353870586425\n",
      "Linear model: C = 0.001 score = -3684.270972443608\n",
      "Linear model: C = 0.005 score = -3247.1341579332066\n",
      "Linear model: C = 0.01 score = -2983.675693012166\n",
      "Linear model: C = 0.05 score = -2620.185280915004\n",
      "Linear model: C = 0.1 score = -2516.3860555071883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model: C = 0.5 score = -2357.2062724942325\n",
      "Linear model: C = 1 score = -2323.2965183304386\n",
      "Linear model: C = 5 score = -2323.296025126436\n",
      "Linear model: C = 10 score = -2272.654879697954\n",
      "Linear model: C = 50 score = -2272.654415882218\n",
      "Linear model: C = 100 score = -2272.654415882218\n",
      "Linear model: C = 500 score = -2272.654415882218\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3725.1090353518694\n",
      "Linear model: C = 5e-05 score = -3717.6194047880167\n",
      "Linear model: C = 0.0001 score = -3708.2231377641\n",
      "Linear model: C = 0.0005 score = -3636.385076355774\n",
      "Linear model: C = 0.001 score = -3555.088693648479\n",
      "Linear model: C = 0.005 score = -3126.878028037906\n",
      "Linear model: C = 0.01 score = -2867.5919584074536\n",
      "Linear model: C = 0.05 score = -2503.712900659087\n",
      "Linear model: C = 0.1 score = -2395.562812372146\n",
      "Linear model: C = 0.5 score = -2235.4128837176672\n",
      "Linear model: C = 1 score = -2235.412474851231\n",
      "Linear model: C = 5 score = -2179.163051783451\n",
      "Linear model: C = 10 score = -2179.163051783451\n",
      "Linear model: C = 50 score = -2179.162901615514\n",
      "Linear model: C = 100 score = -2179.1626457228526\n",
      "Linear model: C = 500 score = -2179.1626457228526\n",
      "Linear model: C = 1000 score = -2179.1626457228526\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3662.9033410006095\n",
      "Linear model: C = 5e-05 score = -3655.2758274127427\n",
      "Linear model: C = 0.0001 score = -3645.921818412962\n",
      "Linear model: C = 0.0005 score = -3573.7477031663066\n",
      "Linear model: C = 0.001 score = -3492.1040715176437\n",
      "Linear model: C = 0.005 score = -3063.110367580222\n",
      "Linear model: C = 0.01 score = -2808.7854632363724\n",
      "Linear model: C = 0.05 score = -2451.832064471881\n",
      "Linear model: C = 0.1 score = -2347.294246658866\n",
      "Linear model: C = 0.5 score = -2184.732232192204\n",
      "Linear model: C = 1 score = -2153.428422459605\n",
      "Linear model: C = 5 score = -2117.4918037059138\n",
      "Linear model: C = 10 score = -2117.4917564359384\n",
      "Linear model: C = 50 score = -2117.4918300959002\n",
      "Linear model: C = 100 score = -2117.4918748278315\n",
      "Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "Time left 2002.2662620544434\n",
      "Start fitting Selector_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Selector_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2136.78\n",
      "[200]\tvalid's l1: 1981.05\n",
      "[300]\tvalid's l1: 1935.09\n",
      "[400]\tvalid's l1: 1893.78\n",
      "[500]\tvalid's l1: 1858.81\n",
      "[600]\tvalid's l1: 1845.09\n",
      "[700]\tvalid's l1: 1831.06\n",
      "[800]\tvalid's l1: 1818.69\n",
      "[900]\tvalid's l1: 1809.87\n",
      "[1000]\tvalid's l1: 1805.38\n",
      "[1100]\tvalid's l1: 1796.56\n",
      "[1200]\tvalid's l1: 1791.43\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1791.43\n",
      "Selector_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1849.89\n",
      "[200]\tvalid's l1: 1727.88\n",
      "[300]\tvalid's l1: 1690.44\n",
      "[400]\tvalid's l1: 1679.69\n",
      "[500]\tvalid's l1: 1670.63\n",
      "[600]\tvalid's l1: 1665.52\n",
      "[700]\tvalid's l1: 1660.82\n",
      "[800]\tvalid's l1: 1657.42\n",
      "[900]\tvalid's l1: 1655.98\n",
      "[1000]\tvalid's l1: 1654.48\n",
      "[1100]\tvalid's l1: 1653.08\n",
      "[1200]\tvalid's l1: 1650.89\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1650.89\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1838.71\n",
      "[200]\tvalid's l1: 1703.48\n",
      "[300]\tvalid's l1: 1668.2\n",
      "[400]\tvalid's l1: 1649.94\n",
      "[500]\tvalid's l1: 1641.22\n",
      "[600]\tvalid's l1: 1637.97\n",
      "[700]\tvalid's l1: 1634.94\n",
      "[800]\tvalid's l1: 1631.87\n",
      "[900]\tvalid's l1: 1627.28\n",
      "[1000]\tvalid's l1: 1623.15\n",
      "[1100]\tvalid's l1: 1618.63\n",
      "[1200]\tvalid's l1: 1617.97\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1162]\tvalid's l1: 1617.8\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1898.17\n",
      "[200]\tvalid's l1: 1775.66\n",
      "[300]\tvalid's l1: 1741.84\n",
      "[400]\tvalid's l1: 1730.14\n",
      "[500]\tvalid's l1: 1720.38\n",
      "[600]\tvalid's l1: 1715.42\n",
      "[700]\tvalid's l1: 1707.89\n",
      "[800]\tvalid's l1: 1704.31\n",
      "[900]\tvalid's l1: 1699.89\n",
      "[1000]\tvalid's l1: 1698.19\n",
      "[1100]\tvalid's l1: 1692\n",
      "[1200]\tvalid's l1: 1690.17\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1690.17\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1752.63\n",
      "[200]\tvalid's l1: 1639.99\n",
      "[300]\tvalid's l1: 1602.39\n",
      "[400]\tvalid's l1: 1589.21\n",
      "[500]\tvalid's l1: 1579.13\n",
      "[600]\tvalid's l1: 1570.98\n",
      "[700]\tvalid's l1: 1568.08\n",
      "[800]\tvalid's l1: 1562.67\n",
      "[900]\tvalid's l1: 1558.12\n",
      "[1000]\tvalid's l1: 1555.62\n",
      "[1100]\tvalid's l1: 1555\n",
      "[1200]\tvalid's l1: 1552.48\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1552.47\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1721.35\n",
      "[200]\tvalid's l1: 1591.43\n",
      "[300]\tvalid's l1: 1566.41\n",
      "[400]\tvalid's l1: 1552.56\n",
      "[500]\tvalid's l1: 1544.77\n",
      "[600]\tvalid's l1: 1543.36\n",
      "[700]\tvalid's l1: 1540.75\n",
      "[800]\tvalid's l1: 1536.82\n",
      "[900]\tvalid's l1: 1534.76\n",
      "[1000]\tvalid's l1: 1532.98\n",
      "[1100]\tvalid's l1: 1530.6\n",
      "[1200]\tvalid's l1: 1529.02\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1194]\tvalid's l1: 1528.98\n",
      "Lvl_0_Pipe_1_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 1690.601155090332 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:38:42,819] (INFO): A new study created in memory with name: no-name-771b70ca-377e-49b0-875b-0a4938ff545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1726.51\n",
      "[200]\tvalid's l1: 1587.69\n",
      "[300]\tvalid's l1: 1556.55\n",
      "[400]\tvalid's l1: 1540.18\n",
      "[500]\tvalid's l1: 1527.91\n",
      "[600]\tvalid's l1: 1519.96\n",
      "[700]\tvalid's l1: 1513.27\n",
      "[800]\tvalid's l1: 1507.99\n",
      "[900]\tvalid's l1: 1502.89\n",
      "[1000]\tvalid's l1: 1498.61\n",
      "[1100]\tvalid's l1: 1495.69\n",
      "[1200]\tvalid's l1: 1492.86\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1492.86\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:38:51,232] (INFO): Trial 0 finished with value: -1492.863637832867 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 108, 'bagging_fraction': 0.5917173949330818, 'min_sum_hessian_in_leaf': 1.3145103232150122, 'reg_alpha': 0.0023531598052637494, 'reg_lambda': 0.00010291881465670109}. Best is trial 0 with value: -1492.863637832867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1689.22\n",
      "[200]\tvalid's l1: 1544.41\n",
      "[300]\tvalid's l1: 1521.91\n",
      "[400]\tvalid's l1: 1506.51\n",
      "[500]\tvalid's l1: 1496.15\n",
      "[600]\tvalid's l1: 1487.71\n",
      "[700]\tvalid's l1: 1484.14\n",
      "[800]\tvalid's l1: 1480.06\n",
      "[900]\tvalid's l1: 1476.92\n",
      "[1000]\tvalid's l1: 1475.51\n",
      "[1100]\tvalid's l1: 1472.54\n",
      "[1200]\tvalid's l1: 1470.77\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1470.77\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:39:04,777] (INFO): Trial 1 finished with value: -1470.7673112646326 and parameters: {'feature_fraction': 0.5499874579090014, 'num_leaves': 218, 'bagging_fraction': 0.9330880728874675, 'min_sum_hessian_in_leaf': 0.2537815508265665, 'reg_alpha': 0.023585940584142682, 'reg_lambda': 1.5320059381854043e-08}. Best is trial 1 with value: -1470.7673112646326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1657.42\n",
      "[200]\tvalid's l1: 1517.04\n",
      "[300]\tvalid's l1: 1488.77\n",
      "[400]\tvalid's l1: 1476.98\n",
      "[500]\tvalid's l1: 1468.04\n",
      "[600]\tvalid's l1: 1462.13\n",
      "[700]\tvalid's l1: 1457.6\n",
      "[800]\tvalid's l1: 1455.07\n",
      "[900]\tvalid's l1: 1452.68\n",
      "[1000]\tvalid's l1: 1448.95\n",
      "[1100]\tvalid's l1: 1446.49\n",
      "[1200]\tvalid's l1: 1444.6\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1444.59\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:39:23,546] (INFO): Trial 2 finished with value: -1444.5866789942147 and parameters: {'feature_fraction': 0.9849549260809971, 'num_leaves': 251, 'bagging_fraction': 0.9692763545078751, 'min_sum_hessian_in_leaf': 0.0010071984838809194, 'reg_alpha': 8.509499823666633, 'reg_lambda': 0.0036085571407386235}. Best is trial 2 with value: -1444.5866789942147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1666.87\n",
      "[200]\tvalid's l1: 1541.4\n",
      "[300]\tvalid's l1: 1508.68\n",
      "[400]\tvalid's l1: 1491.63\n",
      "[500]\tvalid's l1: 1481.74\n",
      "[600]\tvalid's l1: 1474.67\n",
      "[700]\tvalid's l1: 1470.1\n",
      "[800]\tvalid's l1: 1467.24\n",
      "[900]\tvalid's l1: 1464.98\n",
      "[1000]\tvalid's l1: 1463.39\n",
      "[1100]\tvalid's l1: 1460.71\n",
      "[1200]\tvalid's l1: 1458.54\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1458.48\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:39:39,632] (INFO): Trial 3 finished with value: -1458.4815177343492 and parameters: {'feature_fraction': 0.8058265802441404, 'num_leaves': 251, 'bagging_fraction': 0.5115312125207079, 'min_sum_hessian_in_leaf': 0.12563152773938666, 'reg_alpha': 3.9696182670988566e-05, 'reg_lambda': 2.630213296503227e-08}. Best is trial 2 with value: -1444.5866789942147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1861.66\n",
      "[200]\tvalid's l1: 1741.68\n",
      "[300]\tvalid's l1: 1699.18\n",
      "[400]\tvalid's l1: 1686.13\n",
      "[500]\tvalid's l1: 1666.82\n",
      "[600]\tvalid's l1: 1658.9\n",
      "[700]\tvalid's l1: 1654.97\n",
      "[800]\tvalid's l1: 1648.16\n",
      "[900]\tvalid's l1: 1645.39\n",
      "[1000]\tvalid's l1: 1640.5\n",
      "[1100]\tvalid's l1: 1636.85\n",
      "[1200]\tvalid's l1: 1634.1\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1196]\tvalid's l1: 1634.08\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:39:44,214] (INFO): Trial 4 finished with value: -1634.0811937860906 and parameters: {'feature_fraction': 0.9868777594207296, 'num_leaves': 30, 'bagging_fraction': 0.728034992108518, 'min_sum_hessian_in_leaf': 1.382623217936987, 'reg_alpha': 6.267062696005991e-07, 'reg_lambda': 0.00042472707398058225}. Best is trial 2 with value: -1444.5866789942147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1675.41\n",
      "[200]\tvalid's l1: 1548.23\n",
      "[300]\tvalid's l1: 1531.22\n",
      "[400]\tvalid's l1: 1522.72\n",
      "[500]\tvalid's l1: 1518.25\n",
      "[600]\tvalid's l1: 1511.3\n",
      "[700]\tvalid's l1: 1506.99\n",
      "[800]\tvalid's l1: 1503.14\n",
      "[900]\tvalid's l1: 1498.89\n",
      "[1000]\tvalid's l1: 1495.51\n",
      "[1100]\tvalid's l1: 1493.84\n",
      "[1200]\tvalid's l1: 1491.94\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1491.94\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:39:55,111] (INFO): Trial 5 finished with value: -1491.9397566209745 and parameters: {'feature_fraction': 0.7962072844310213, 'num_leaves': 146, 'bagging_fraction': 0.9299702033681603, 'min_sum_hessian_in_leaf': 0.5262961031076743, 'reg_alpha': 0.00011336872639641431, 'reg_lambda': 1.316390230170444e-08}. Best is trial 2 with value: -1444.5866789942147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1868.44\n",
      "[200]\tvalid's l1: 1745.86\n",
      "[300]\tvalid's l1: 1712.96\n",
      "[400]\tvalid's l1: 1704.24\n",
      "[500]\tvalid's l1: 1691.6\n",
      "[600]\tvalid's l1: 1682.19\n",
      "[700]\tvalid's l1: 1676.21\n",
      "[800]\tvalid's l1: 1673.27\n",
      "[900]\tvalid's l1: 1668.77\n",
      "[1000]\tvalid's l1: 1666.05\n",
      "[1100]\tvalid's l1: 1664.3\n",
      "[1200]\tvalid's l1: 1663.21\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1663.21\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:40:00,061] (INFO): Trial 6 finished with value: -1663.206526402819 and parameters: {'feature_fraction': 0.9711008778424264, 'num_leaves': 29, 'bagging_fraction': 0.9041986740582306, 'min_sum_hessian_in_leaf': 0.01653693718282442, 'reg_alpha': 7.569183361880229e-08, 'reg_lambda': 0.014391207615728067}. Best is trial 2 with value: -1444.5866789942147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1661.93\n",
      "[200]\tvalid's l1: 1532.21\n",
      "[300]\tvalid's l1: 1504.11\n",
      "[400]\tvalid's l1: 1490.28\n",
      "[500]\tvalid's l1: 1480.42\n",
      "[600]\tvalid's l1: 1473.31\n",
      "[700]\tvalid's l1: 1468.75\n",
      "[800]\tvalid's l1: 1465.61\n",
      "[900]\tvalid's l1: 1462.29\n",
      "[1000]\tvalid's l1: 1460.32\n",
      "[1100]\tvalid's l1: 1457.78\n",
      "[1200]\tvalid's l1: 1456.19\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1456.19\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:40:14,072] (INFO): Trial 7 finished with value: -1456.1928756378825 and parameters: {'feature_fraction': 0.7200762468698007, 'num_leaves': 214, 'bagging_fraction': 0.8049983288913105, 'min_sum_hessian_in_leaf': 2.1516897298083326, 'reg_alpha': 3.6331378936352306e-07, 'reg_lambda': 3.307847415252541e-05}. Best is trial 2 with value: -1444.5866789942147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1714.87\n",
      "[200]\tvalid's l1: 1567.37\n",
      "[300]\tvalid's l1: 1535.1\n",
      "[400]\tvalid's l1: 1520.24\n",
      "[500]\tvalid's l1: 1509.26\n",
      "[600]\tvalid's l1: 1502.39\n",
      "[700]\tvalid's l1: 1498.7\n",
      "[800]\tvalid's l1: 1494.1\n",
      "[900]\tvalid's l1: 1489.7\n",
      "[1000]\tvalid's l1: 1486.12\n",
      "[1100]\tvalid's l1: 1484.21\n",
      "[1200]\tvalid's l1: 1481.26\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1481.25\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:40:23,588] (INFO): Trial 8 finished with value: -1481.251000185782 and parameters: {'feature_fraction': 0.5911180438940311, 'num_leaves': 147, 'bagging_fraction': 0.6558555380447055, 'min_sum_hessian_in_leaf': 0.12030178871154672, 'reg_alpha': 0.0008325158565947976, 'reg_lambda': 4.609885087947832e-07}. Best is trial 2 with value: -1444.5866789942147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1656.27\n",
      "[200]\tvalid's l1: 1512.05\n",
      "[300]\tvalid's l1: 1482.92\n",
      "[400]\tvalid's l1: 1470.1\n",
      "[500]\tvalid's l1: 1462.75\n",
      "[600]\tvalid's l1: 1456.94\n",
      "[700]\tvalid's l1: 1452.63\n",
      "[800]\tvalid's l1: 1449.6\n",
      "[900]\tvalid's l1: 1447.29\n",
      "[1000]\tvalid's l1: 1444.98\n",
      "[1100]\tvalid's l1: 1442.57\n",
      "[1200]\tvalid's l1: 1441.51\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1441.51\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:40:40,445] (INFO): Trial 9 finished with value: -1441.509306218364 and parameters: {'feature_fraction': 0.9847923138822793, 'num_leaves': 233, 'bagging_fraction': 0.7248770666848828, 'min_sum_hessian_in_leaf': 0.03807158379249393, 'reg_alpha': 2.1874079799487576, 'reg_lambda': 0.0351113851431067}. Best is trial 9 with value: -1441.509306218364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1676.64\n",
      "[200]\tvalid's l1: 1533.95\n",
      "[300]\tvalid's l1: 1504.45\n",
      "[400]\tvalid's l1: 1491.2\n",
      "[500]\tvalid's l1: 1482.46\n",
      "[600]\tvalid's l1: 1476.86\n",
      "[700]\tvalid's l1: 1471.03\n",
      "[800]\tvalid's l1: 1467.02\n",
      "[900]\tvalid's l1: 1464.14\n",
      "[1000]\tvalid's l1: 1461.62\n",
      "[1100]\tvalid's l1: 1458.9\n",
      "[1200]\tvalid's l1: 1456.77\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1456.77\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:40:54,313] (INFO): Trial 10 finished with value: -1456.765580498571 and parameters: {'feature_fraction': 0.8886185629157468, 'num_leaves': 189, 'bagging_fraction': 0.8097051848286712, 'min_sum_hessian_in_leaf': 0.011537653383416786, 'reg_alpha': 7.154200555296032, 'reg_lambda': 1.475649304728376}. Best is trial 9 with value: -1441.509306218364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1666.63\n",
      "[200]\tvalid's l1: 1523.4\n",
      "[300]\tvalid's l1: 1493.51\n",
      "[400]\tvalid's l1: 1480.26\n",
      "[500]\tvalid's l1: 1471.75\n",
      "[600]\tvalid's l1: 1465.26\n",
      "[700]\tvalid's l1: 1459.97\n",
      "[800]\tvalid's l1: 1457.04\n",
      "[900]\tvalid's l1: 1453.24\n",
      "[1000]\tvalid's l1: 1450.22\n",
      "[1100]\tvalid's l1: 1448.54\n",
      "[1200]\tvalid's l1: 1447.56\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1447.56\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:41:10,439] (INFO): Trial 11 finished with value: -1447.5597080989457 and parameters: {'feature_fraction': 0.9081201178672933, 'num_leaves': 252, 'bagging_fraction': 0.7190136248107628, 'min_sum_hessian_in_leaf': 0.001126240624595019, 'reg_alpha': 7.804075989965754, 'reg_lambda': 0.23538505092265555}. Best is trial 9 with value: -1441.509306218364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1636.9\n",
      "[200]\tvalid's l1: 1505.01\n",
      "[300]\tvalid's l1: 1480.67\n",
      "[400]\tvalid's l1: 1469.57\n",
      "[500]\tvalid's l1: 1462.17\n",
      "[600]\tvalid's l1: 1455.56\n",
      "[700]\tvalid's l1: 1451.85\n",
      "[800]\tvalid's l1: 1447.94\n",
      "[900]\tvalid's l1: 1446.58\n",
      "[1000]\tvalid's l1: 1443.62\n",
      "[1100]\tvalid's l1: 1442.69\n",
      "[1200]\tvalid's l1: 1440.49\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1440.47\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:41:26,986] (INFO): Trial 12 finished with value: -1440.4687137793755 and parameters: {'feature_fraction': 0.9114340224650807, 'num_leaves': 248, 'bagging_fraction': 0.8354793185509454, 'min_sum_hessian_in_leaf': 0.0013480941691265509, 'reg_alpha': 0.27539190982201783, 'reg_lambda': 0.01606310173985748}. Best is trial 12 with value: -1440.4687137793755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1652.48\n",
      "[200]\tvalid's l1: 1513.18\n",
      "[300]\tvalid's l1: 1490.82\n",
      "[400]\tvalid's l1: 1478.77\n",
      "[500]\tvalid's l1: 1472.78\n",
      "[600]\tvalid's l1: 1467.89\n",
      "[700]\tvalid's l1: 1463.47\n",
      "[800]\tvalid's l1: 1458.74\n",
      "[900]\tvalid's l1: 1454.36\n",
      "[1000]\tvalid's l1: 1451.49\n",
      "[1100]\tvalid's l1: 1448.92\n",
      "[1200]\tvalid's l1: 1446.91\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1446.91\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:41:41,838] (INFO): Trial 13 finished with value: -1446.914343478186 and parameters: {'feature_fraction': 0.8858320716284691, 'num_leaves': 188, 'bagging_fraction': 0.8370641470010465, 'min_sum_hessian_in_leaf': 0.010410456323255648, 'reg_alpha': 0.09139430150764159, 'reg_lambda': 7.406156039909503}. Best is trial 12 with value: -1440.4687137793755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1711.95\n",
      "[200]\tvalid's l1: 1578.11\n",
      "[300]\tvalid's l1: 1553.06\n",
      "[400]\tvalid's l1: 1539.39\n",
      "[500]\tvalid's l1: 1532.31\n",
      "[600]\tvalid's l1: 1525.81\n",
      "[700]\tvalid's l1: 1518.83\n",
      "[800]\tvalid's l1: 1514.59\n",
      "[900]\tvalid's l1: 1509.89\n",
      "[1000]\tvalid's l1: 1505.87\n",
      "[1100]\tvalid's l1: 1502.32\n",
      "[1200]\tvalid's l1: 1500.17\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1500.17\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:41:50,518] (INFO): Trial 14 finished with value: -1500.1715840957577 and parameters: {'feature_fraction': 0.9281612089091543, 'num_leaves': 98, 'bagging_fraction': 0.6389042678618915, 'min_sum_hessian_in_leaf': 8.153462976252296, 'reg_alpha': 0.20657815129482654, 'reg_lambda': 0.0795808647253937}. Best is trial 12 with value: -1440.4687137793755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1648.25\n",
      "[200]\tvalid's l1: 1508.31\n",
      "[300]\tvalid's l1: 1482.16\n",
      "[400]\tvalid's l1: 1469.94\n",
      "[500]\tvalid's l1: 1463.03\n",
      "[600]\tvalid's l1: 1458.61\n",
      "[700]\tvalid's l1: 1455.7\n",
      "[800]\tvalid's l1: 1451.67\n",
      "[900]\tvalid's l1: 1447.32\n",
      "[1000]\tvalid's l1: 1444.65\n",
      "[1100]\tvalid's l1: 1442.43\n",
      "[1200]\tvalid's l1: 1441.45\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1441.45\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:42:05,835] (INFO): Trial 15 finished with value: -1441.4543471009345 and parameters: {'feature_fraction': 0.8361130882772976, 'num_leaves': 218, 'bagging_fraction': 0.8758067124078945, 'min_sum_hessian_in_leaf': 0.0031951229607654784, 'reg_alpha': 2.1884917886729314, 'reg_lambda': 0.0043675678489920365}. Best is trial 12 with value: -1440.4687137793755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1651.91\n",
      "[200]\tvalid's l1: 1523.7\n",
      "[300]\tvalid's l1: 1504.71\n",
      "[400]\tvalid's l1: 1495.11\n",
      "[500]\tvalid's l1: 1486.4\n",
      "[600]\tvalid's l1: 1479.94\n",
      "[700]\tvalid's l1: 1474.35\n",
      "[800]\tvalid's l1: 1470.34\n",
      "[900]\tvalid's l1: 1467.57\n",
      "[1000]\tvalid's l1: 1465.92\n",
      "[1100]\tvalid's l1: 1463.79\n",
      "[1200]\tvalid's l1: 1462.22\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1462.2\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:42:18,928] (INFO): Trial 16 finished with value: -1462.201064035933 and parameters: {'feature_fraction': 0.827856876133822, 'num_leaves': 183, 'bagging_fraction': 0.8803837090436517, 'min_sum_hessian_in_leaf': 0.0029071260316357764, 'reg_alpha': 0.3589316645857106, 'reg_lambda': 0.0014519325939403105}. Best is trial 12 with value: -1440.4687137793755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1637.88\n",
      "[200]\tvalid's l1: 1515.07\n",
      "[300]\tvalid's l1: 1501.03\n",
      "[400]\tvalid's l1: 1492.29\n",
      "[500]\tvalid's l1: 1485.16\n",
      "[600]\tvalid's l1: 1478.45\n",
      "[700]\tvalid's l1: 1473.88\n",
      "[800]\tvalid's l1: 1471.33\n",
      "[900]\tvalid's l1: 1468.48\n",
      "[1000]\tvalid's l1: 1465.74\n",
      "[1100]\tvalid's l1: 1464.67\n",
      "[1200]\tvalid's l1: 1463.17\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1463.17\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:42:32,698] (INFO): Trial 17 finished with value: -1463.1685706012793 and parameters: {'feature_fraction': 0.8478248300112026, 'num_leaves': 214, 'bagging_fraction': 0.9898232498406144, 'min_sum_hessian_in_leaf': 0.0031809444244336313, 'reg_alpha': 0.008201264150037984, 'reg_lambda': 1.442173114751991e-05}. Best is trial 12 with value: -1440.4687137793755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1676.4\n",
      "[200]\tvalid's l1: 1543.75\n",
      "[300]\tvalid's l1: 1519.38\n",
      "[400]\tvalid's l1: 1507.09\n",
      "[500]\tvalid's l1: 1498.52\n",
      "[600]\tvalid's l1: 1493.66\n",
      "[700]\tvalid's l1: 1488.82\n",
      "[800]\tvalid's l1: 1484.43\n",
      "[900]\tvalid's l1: 1480.2\n",
      "[1000]\tvalid's l1: 1477.17\n",
      "[1100]\tvalid's l1: 1473.99\n",
      "[1200]\tvalid's l1: 1472.16\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1472.16\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:42:44,094] (INFO): Trial 18 finished with value: -1472.1577989597 and parameters: {'feature_fraction': 0.756155381083431, 'num_leaves': 168, 'bagging_fraction': 0.8514507273488532, 'min_sum_hessian_in_leaf': 0.0031404682326471867, 'reg_alpha': 0.7267387531133465, 'reg_lambda': 1.1301554117971047}. Best is trial 12 with value: -1440.4687137793755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1752.85\n",
      "[200]\tvalid's l1: 1606.24\n",
      "[300]\tvalid's l1: 1580.86\n",
      "[400]\tvalid's l1: 1566.21\n",
      "[500]\tvalid's l1: 1555.3\n",
      "[600]\tvalid's l1: 1546.9\n",
      "[700]\tvalid's l1: 1542.48\n",
      "[800]\tvalid's l1: 1535.23\n",
      "[900]\tvalid's l1: 1531.22\n",
      "[1000]\tvalid's l1: 1528.59\n",
      "[1100]\tvalid's l1: 1526.28\n",
      "[1200]\tvalid's l1: 1523.19\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1523.19\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:42:51,058] (INFO): Trial 19 finished with value: -1523.1854870603806 and parameters: {'feature_fraction': 0.6480230593615819, 'num_leaves': 84, 'bagging_fraction': 0.7784966102520325, 'min_sum_hessian_in_leaf': 0.0015691236297919622, 'reg_alpha': 0.02854335713363218, 'reg_lambda': 4.4267483878020815e-06}. Best is trial 12 with value: -1440.4687137793755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1640.04\n",
      "[200]\tvalid's l1: 1509.2\n",
      "[300]\tvalid's l1: 1488.99\n",
      "[400]\tvalid's l1: 1482.07\n",
      "[500]\tvalid's l1: 1474.87\n",
      "[600]\tvalid's l1: 1468.52\n",
      "[700]\tvalid's l1: 1464.36\n",
      "[800]\tvalid's l1: 1460.4\n",
      "[900]\tvalid's l1: 1457.49\n",
      "[1000]\tvalid's l1: 1455.07\n",
      "[1100]\tvalid's l1: 1453.35\n",
      "[1200]\tvalid's l1: 1451.5\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1451.5\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:43:06,002] (INFO): Trial 20 finished with value: -1451.5021881128246 and parameters: {'feature_fraction': 0.7597954017930355, 'num_leaves': 230, 'bagging_fraction': 0.8701230818680996, 'min_sum_hessian_in_leaf': 0.03931220701930835, 'reg_alpha': 1.2939757350582707e-05, 'reg_lambda': 0.006317965400748231}. Best is trial 12 with value: -1440.4687137793755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1646.12\n",
      "[200]\tvalid's l1: 1509.34\n",
      "[300]\tvalid's l1: 1485.55\n",
      "[400]\tvalid's l1: 1475.9\n",
      "[500]\tvalid's l1: 1465.72\n",
      "[600]\tvalid's l1: 1459.41\n",
      "[700]\tvalid's l1: 1454.99\n",
      "[800]\tvalid's l1: 1452.14\n",
      "[900]\tvalid's l1: 1449.14\n",
      "[1000]\tvalid's l1: 1448.06\n",
      "[1100]\tvalid's l1: 1445.59\n",
      "[1200]\tvalid's l1: 1444.42\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1196]\tvalid's l1: 1444.33\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:43:22,740] (INFO): Trial 21 finished with value: -1444.3315518580603 and parameters: {'feature_fraction': 0.9288098030035297, 'num_leaves': 244, 'bagging_fraction': 0.7547611291884875, 'min_sum_hessian_in_leaf': 0.0289515557915341, 'reg_alpha': 1.8183822723425709, 'reg_lambda': 0.043478308453352536}. Best is trial 12 with value: -1440.4687137793755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1653.16\n",
      "[200]\tvalid's l1: 1514.52\n",
      "[300]\tvalid's l1: 1484.81\n",
      "[400]\tvalid's l1: 1469.84\n",
      "[500]\tvalid's l1: 1461.09\n",
      "[600]\tvalid's l1: 1455.59\n",
      "[700]\tvalid's l1: 1450.97\n",
      "[800]\tvalid's l1: 1447.3\n",
      "[900]\tvalid's l1: 1444.36\n",
      "[1000]\tvalid's l1: 1441.83\n",
      "[1100]\tvalid's l1: 1440.16\n",
      "[1200]\tvalid's l1: 1437.68\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1193]\tvalid's l1: 1437.5\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:43:38,284] (INFO): Trial 22 finished with value: -1437.5002129248576 and parameters: {'feature_fraction': 0.8590191983118689, 'num_leaves': 233, 'bagging_fraction': 0.7311151203526169, 'min_sum_hessian_in_leaf': 0.005583009585004241, 'reg_alpha': 1.6056809882616976, 'reg_lambda': 0.0006163731422523285}. Best is trial 22 with value: -1437.5002129248576.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1654.45\n",
      "[200]\tvalid's l1: 1525.77\n",
      "[300]\tvalid's l1: 1498.79\n",
      "[400]\tvalid's l1: 1487.85\n",
      "[500]\tvalid's l1: 1477.58\n",
      "[600]\tvalid's l1: 1470.88\n",
      "[700]\tvalid's l1: 1466.3\n",
      "[800]\tvalid's l1: 1462.5\n",
      "[900]\tvalid's l1: 1459.63\n",
      "[1000]\tvalid's l1: 1456.96\n",
      "[1100]\tvalid's l1: 1454.69\n",
      "[1200]\tvalid's l1: 1452.1\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1452.04\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:43:51,069] (INFO): Trial 23 finished with value: -1452.0389918191106 and parameters: {'feature_fraction': 0.8216006626306901, 'num_leaves': 205, 'bagging_fraction': 0.6752771297605508, 'min_sum_hessian_in_leaf': 0.006535755963538398, 'reg_alpha': 0.09290233066204101, 'reg_lambda': 0.0007986485801840574}. Best is trial 22 with value: -1437.5002129248576.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1542.19\n",
      "[200]\tvalid's l1: 1488.94\n",
      "[300]\tvalid's l1: 1472.5\n",
      "[400]\tvalid's l1: 1464.68\n",
      "[500]\tvalid's l1: 1457.67\n",
      "[600]\tvalid's l1: 1453.08\n",
      "[700]\tvalid's l1: 1448.08\n",
      "[800]\tvalid's l1: 1445.98\n",
      "[900]\tvalid's l1: 1443.95\n",
      "[1000]\tvalid's l1: 1442.78\n",
      "[1100]\tvalid's l1: 1441.2\n",
      "[1200]\tvalid's l1: 1440.53\n",
      "[1300]\tvalid's l1: 1438.96\n",
      "[1400]\tvalid's l1: 1437.78\n",
      "[1500]\tvalid's l1: 1436.11\n",
      "[1600]\tvalid's l1: 1434.98\n",
      "[1700]\tvalid's l1: 1434.55\n",
      "[1800]\tvalid's l1: 1433.82\n",
      "[1900]\tvalid's l1: 1433.3\n",
      "[2000]\tvalid's l1: 1432.88\n",
      "[2100]\tvalid's l1: 1432.42\n",
      "[2200]\tvalid's l1: 1431.89\n",
      "[2300]\tvalid's l1: 1431.26\n",
      "[2400]\tvalid's l1: 1430.57\n",
      "[2500]\tvalid's l1: 1429.88\n",
      "[2600]\tvalid's l1: 1429.14\n",
      "[2700]\tvalid's l1: 1428.95\n",
      "[2800]\tvalid's l1: 1428.75\n",
      "[2900]\tvalid's l1: 1428.44\n",
      "[3000]\tvalid's l1: 1428.09\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2996]\tvalid's l1: 1428.06\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1526.46\n",
      "[200]\tvalid's l1: 1486.93\n",
      "[300]\tvalid's l1: 1474.35\n",
      "[400]\tvalid's l1: 1465.86\n",
      "[500]\tvalid's l1: 1460.34\n",
      "[600]\tvalid's l1: 1456.5\n",
      "[700]\tvalid's l1: 1454.68\n",
      "[800]\tvalid's l1: 1453.87\n",
      "[900]\tvalid's l1: 1452.26\n",
      "[1000]\tvalid's l1: 1451.58\n",
      "[1100]\tvalid's l1: 1450.71\n",
      "[1200]\tvalid's l1: 1449.37\n",
      "[1300]\tvalid's l1: 1448.07\n",
      "[1400]\tvalid's l1: 1446.91\n",
      "[1500]\tvalid's l1: 1445.6\n",
      "Early stopping, best iteration is:\n",
      "[1494]\tvalid's l1: 1445.49\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1601.02\n",
      "[200]\tvalid's l1: 1559.77\n",
      "[300]\tvalid's l1: 1547.32\n",
      "[400]\tvalid's l1: 1542.74\n",
      "[500]\tvalid's l1: 1538.57\n",
      "[600]\tvalid's l1: 1533.87\n",
      "[700]\tvalid's l1: 1530.11\n",
      "[800]\tvalid's l1: 1527.46\n",
      "[900]\tvalid's l1: 1525.62\n",
      "[1000]\tvalid's l1: 1524.19\n",
      "[1100]\tvalid's l1: 1522.82\n",
      "[1200]\tvalid's l1: 1521.01\n",
      "[1300]\tvalid's l1: 1521.26\n",
      "Early stopping, best iteration is:\n",
      "[1221]\tvalid's l1: 1520.63\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1470.41\n",
      "[200]\tvalid's l1: 1432.07\n",
      "[300]\tvalid's l1: 1420.86\n",
      "[400]\tvalid's l1: 1413.72\n",
      "[500]\tvalid's l1: 1408.58\n",
      "[600]\tvalid's l1: 1404.81\n",
      "[700]\tvalid's l1: 1402.91\n",
      "[800]\tvalid's l1: 1401.42\n",
      "[900]\tvalid's l1: 1400.06\n",
      "[1000]\tvalid's l1: 1398.05\n",
      "[1100]\tvalid's l1: 1396.74\n",
      "[1200]\tvalid's l1: 1395.5\n",
      "[1300]\tvalid's l1: 1394.8\n",
      "[1400]\tvalid's l1: 1393.41\n",
      "[1500]\tvalid's l1: 1392.97\n",
      "[1600]\tvalid's l1: 1392.76\n",
      "[1700]\tvalid's l1: 1392.35\n",
      "[1800]\tvalid's l1: 1391.87\n",
      "[1900]\tvalid's l1: 1391.24\n",
      "Early stopping, best iteration is:\n",
      "[1894]\tvalid's l1: 1391.2\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1434.68\n",
      "[200]\tvalid's l1: 1400.46\n",
      "[300]\tvalid's l1: 1385.31\n",
      "[400]\tvalid's l1: 1377.82\n",
      "[500]\tvalid's l1: 1374.02\n",
      "[600]\tvalid's l1: 1369.29\n",
      "[700]\tvalid's l1: 1366.96\n",
      "[800]\tvalid's l1: 1364.91\n",
      "[900]\tvalid's l1: 1363.07\n",
      "[1000]\tvalid's l1: 1362.25\n",
      "[1100]\tvalid's l1: 1360.28\n",
      "[1200]\tvalid's l1: 1358.26\n",
      "[1300]\tvalid's l1: 1357.74\n",
      "[1400]\tvalid's l1: 1356.53\n",
      "[1500]\tvalid's l1: 1355.61\n",
      "[1600]\tvalid's l1: 1354.62\n",
      "[1700]\tvalid's l1: 1353.46\n",
      "[1800]\tvalid's l1: 1353.25\n",
      "[1900]\tvalid's l1: 1352.59\n",
      "[2000]\tvalid's l1: 1352.18\n",
      "[2100]\tvalid's l1: 1351.73\n",
      "[2200]\tvalid's l1: 1352.02\n",
      "Early stopping, best iteration is:\n",
      "[2115]\tvalid's l1: 1351.55\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 1538.7630710601807\n",
      "Blending: Optimization starts with equal weights and score -1649.6315399517282\n",
      "Blending, iter 0: score = -1427.3894234687702, weights = [0. 0. 1.]\n",
      "Blending, iter 1: score = -1427.3894234687702, weights = [0. 0. 1.]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 524.32 seconds.\n",
      "Current random state: {'reader_params': {'random_state': 46}, 'general_params': {'return_all_predictions': False}}\n",
      "Found reader_params in kwargs, need to combine\n",
      "Merged variant for reader_params = {'n_jobs': 8, 'cv': 5, 'random_state': 46}\n",
      "Found general_params in kwargs, need to combine\n",
      "Merged variant for general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']], 'return_all_predictions': False}\n",
      "Start automl preset with listed constraints:\n",
      "- time: 1538.5697269439697 seconds\n",
      "- cpus: 8 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (34994, 145)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 1529.948749780655 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3671.7254901160545\n",
      "Linear model: C = 5e-05 score = -3664.9970598478353\n",
      "Linear model: C = 0.0001 score = -3656.588166717734\n",
      "Linear model: C = 0.0005 score = -3591.860697454547\n",
      "Linear model: C = 0.001 score = -3516.6439631233593\n",
      "Linear model: C = 0.005 score = -3082.4869241944753\n",
      "Linear model: C = 0.01 score = -2831.593992285327\n",
      "Linear model: C = 0.05 score = -2473.6075919356103\n",
      "Linear model: C = 0.1 score = -2363.7632913160264\n",
      "Linear model: C = 0.5 score = -2205.637360913053\n",
      "Linear model: C = 1 score = -2205.6369564096185\n",
      "Linear model: C = 5 score = -2149.342534807175\n",
      "Linear model: C = 10 score = -2149.342534807175\n",
      "Linear model: C = 50 score = -2149.3424984391954\n",
      "Linear model: C = 100 score = -2149.34243316694\n",
      "Linear model: C = 500 score = -2149.342385941871\n",
      "Linear model: C = 1000 score = -2149.3423682685784\n",
      "Linear model: C = 5000 score = -2149.3423012582075\n",
      "Linear model: C = 10000 score = -2149.342177491202\n",
      "Linear model: C = 50000 score = -2149.342162037291\n",
      "Linear model: C = 100000 score = -2149.342150172977\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3656.1184812813663\n",
      "Linear model: C = 5e-05 score = -3649.534178082918\n",
      "Linear model: C = 0.0001 score = -3641.277581297886\n",
      "Linear model: C = 0.0005 score = -3577.187800998636\n",
      "Linear model: C = 0.001 score = -3502.2712004686496\n",
      "Linear model: C = 0.005 score = -3068.5581168141907\n",
      "Linear model: C = 0.01 score = -2810.289996752008\n",
      "Linear model: C = 0.05 score = -2476.6634990963566\n",
      "Linear model: C = 0.1 score = -2377.8773211571706\n",
      "Linear model: C = 0.5 score = -2222.2284969379434\n",
      "Linear model: C = 1 score = -2222.228567471963\n",
      "Linear model: C = 5 score = -2156.7831292117658\n",
      "Linear model: C = 10 score = -2156.783038392648\n",
      "Linear model: C = 50 score = -2156.7829718052244\n",
      "Linear model: C = 100 score = -2156.7827899953027\n",
      "Linear model: C = 500 score = -2156.782780959719\n",
      "Linear model: C = 1000 score = -2156.782683150532\n",
      "Linear model: C = 5000 score = -2156.782594108772\n",
      "Linear model: C = 10000 score = -2156.7824627270884\n",
      "Linear model: C = 50000 score = -2156.782330140878\n",
      "Linear model: C = 100000 score = -2156.7821852864836\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3794.200535239688\n",
      "Linear model: C = 5e-05 score = -3787.5433816507825\n",
      "Linear model: C = 0.0001 score = -3779.2674160622278\n",
      "Linear model: C = 0.0005 score = -3714.606172777752\n",
      "Linear model: C = 0.001 score = -3638.845943986697\n",
      "Linear model: C = 0.005 score = -3198.885752486474\n",
      "Linear model: C = 0.01 score = -2932.880154826468\n",
      "Linear model: C = 0.05 score = -2565.003851460668\n",
      "Linear model: C = 0.1 score = -2463.2805651269446\n",
      "Linear model: C = 0.5 score = -2307.8409382710715\n",
      "Linear model: C = 1 score = -2307.840596843948\n",
      "Linear model: C = 5 score = -2237.127887882255\n",
      "Linear model: C = 10 score = -2237.127889019197\n",
      "Linear model: C = 50 score = -2237.127889019197\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3766.7700696221114\n",
      "Linear model: C = 5e-05 score = -3760.175095744705\n",
      "Linear model: C = 0.0001 score = -3751.910129460459\n",
      "Linear model: C = 0.0005 score = -3687.0914145659203\n",
      "Linear model: C = 0.001 score = -3611.290204578612\n",
      "Linear model: C = 0.005 score = -3175.547541745204\n",
      "Linear model: C = 0.01 score = -2916.710948742974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model: C = 0.05 score = -2550.882087303649\n",
      "Linear model: C = 0.1 score = -2440.436003839651\n",
      "Linear model: C = 0.5 score = -2265.5123912491345\n",
      "Linear model: C = 1 score = -2231.6825125915425\n",
      "Linear model: C = 5 score = -2231.6825125915425\n",
      "Linear model: C = 10 score = -2231.6823142469057\n",
      "Linear model: C = 50 score = -2193.5791236211408\n",
      "Linear model: C = 100 score = -2193.5791196434784\n",
      "Linear model: C = 500 score = -2193.5790638809867\n",
      "Linear model: C = 1000 score = -2193.579030419132\n",
      "Linear model: C = 5000 score = -2193.579030419132\n",
      "Linear model: C = 10000 score = -2193.579030419132\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3840.914507869994\n",
      "Linear model: C = 5e-05 score = -3834.3024414620695\n",
      "Linear model: C = 0.0001 score = -3825.9893657186094\n",
      "Linear model: C = 0.0005 score = -3760.8686791371197\n",
      "Linear model: C = 0.001 score = -3685.644924289194\n",
      "Linear model: C = 0.005 score = -3248.0931262343092\n",
      "Linear model: C = 0.01 score = -2978.3410927379223\n",
      "Linear model: C = 0.05 score = -2605.1760477467787\n",
      "Linear model: C = 0.1 score = -2489.7362774328085\n",
      "Linear model: C = 0.5 score = -2304.6373005812766\n",
      "Linear model: C = 1 score = -2265.018284395648\n",
      "Linear model: C = 5 score = -2265.0182858620005\n",
      "Linear model: C = 10 score = -2265.0182858620005\n",
      "Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "Time left 1485.3168170452118\n",
      "Start fitting Lvl_0_Pipe_1_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1728.81\n",
      "[200]\tvalid's l1: 1599.66\n",
      "[300]\tvalid's l1: 1576.12\n",
      "[400]\tvalid's l1: 1562.15\n",
      "[500]\tvalid's l1: 1556.19\n",
      "[600]\tvalid's l1: 1550.99\n",
      "[700]\tvalid's l1: 1548.95\n",
      "[800]\tvalid's l1: 1544.38\n",
      "[900]\tvalid's l1: 1541.45\n",
      "[1000]\tvalid's l1: 1538.09\n",
      "[1100]\tvalid's l1: 1535.63\n",
      "[1200]\tvalid's l1: 1533.32\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1533.32\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1787.04\n",
      "[200]\tvalid's l1: 1655.5\n",
      "[300]\tvalid's l1: 1627.19\n",
      "[400]\tvalid's l1: 1617.02\n",
      "[500]\tvalid's l1: 1609.46\n",
      "[600]\tvalid's l1: 1604.25\n",
      "[700]\tvalid's l1: 1596.12\n",
      "[800]\tvalid's l1: 1590.97\n",
      "[900]\tvalid's l1: 1587.78\n",
      "[1000]\tvalid's l1: 1585.88\n",
      "[1100]\tvalid's l1: 1585.39\n",
      "[1200]\tvalid's l1: 1584.24\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1584.24\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1834.4\n",
      "[200]\tvalid's l1: 1698.38\n",
      "[300]\tvalid's l1: 1670.86\n",
      "[400]\tvalid's l1: 1653.97\n",
      "[500]\tvalid's l1: 1644.11\n",
      "[600]\tvalid's l1: 1636.53\n",
      "[700]\tvalid's l1: 1631.63\n",
      "[800]\tvalid's l1: 1629.96\n",
      "[900]\tvalid's l1: 1626.65\n",
      "[1000]\tvalid's l1: 1620.15\n",
      "[1100]\tvalid's l1: 1618.71\n",
      "[1200]\tvalid's l1: 1616.57\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1616.57\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1817.69\n",
      "[200]\tvalid's l1: 1680.23\n",
      "[300]\tvalid's l1: 1648.01\n",
      "[400]\tvalid's l1: 1632.9\n",
      "[500]\tvalid's l1: 1623.42\n",
      "[600]\tvalid's l1: 1620.2\n",
      "[700]\tvalid's l1: 1617.52\n",
      "[800]\tvalid's l1: 1613.9\n",
      "[900]\tvalid's l1: 1612.56\n",
      "[1000]\tvalid's l1: 1609.64\n",
      "[1100]\tvalid's l1: 1607.94\n",
      "[1200]\tvalid's l1: 1606.86\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1606.86\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1851.64\n",
      "[200]\tvalid's l1: 1714.31\n",
      "[300]\tvalid's l1: 1679.25\n",
      "[400]\tvalid's l1: 1666.73\n",
      "[500]\tvalid's l1: 1650.3\n",
      "[600]\tvalid's l1: 1643.32\n",
      "[700]\tvalid's l1: 1638.88\n",
      "[800]\tvalid's l1: 1636.87\n",
      "[900]\tvalid's l1: 1633.51\n",
      "[1000]\tvalid's l1: 1631.53\n",
      "[1100]\tvalid's l1: 1630.55\n",
      "[1200]\tvalid's l1: 1629.43\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1629.43\n",
      "Lvl_0_Pipe_1_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 1212.010508298874 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:47:19,651] (INFO): A new study created in memory with name: no-name-1485a402-9bcc-4917-8330-8ad59c57fbef\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1602.02\n",
      "[200]\tvalid's l1: 1462.38\n",
      "[300]\tvalid's l1: 1439.14\n",
      "[400]\tvalid's l1: 1424.52\n",
      "[500]\tvalid's l1: 1417.65\n",
      "[600]\tvalid's l1: 1410.1\n",
      "[700]\tvalid's l1: 1405.49\n",
      "[800]\tvalid's l1: 1401.56\n",
      "[900]\tvalid's l1: 1396.58\n",
      "[1000]\tvalid's l1: 1393.2\n",
      "[1100]\tvalid's l1: 1390.62\n",
      "[1200]\tvalid's l1: 1388.36\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1388.36\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:47:28,840] (INFO): Trial 0 finished with value: -1388.358428664217 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 108, 'bagging_fraction': 0.5917173949330818, 'min_sum_hessian_in_leaf': 1.3145103232150122, 'reg_alpha': 0.0023531598052637494, 'reg_lambda': 0.00010291881465670109}. Best is trial 0 with value: -1388.358428664217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1563.61\n",
      "[200]\tvalid's l1: 1412.72\n",
      "[300]\tvalid's l1: 1388.98\n",
      "[400]\tvalid's l1: 1378.46\n",
      "[500]\tvalid's l1: 1368.33\n",
      "[600]\tvalid's l1: 1363.5\n",
      "[700]\tvalid's l1: 1358.82\n",
      "[800]\tvalid's l1: 1355.68\n",
      "[900]\tvalid's l1: 1352.55\n",
      "[1000]\tvalid's l1: 1350.47\n",
      "[1100]\tvalid's l1: 1349.04\n",
      "[1200]\tvalid's l1: 1347.39\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1347.39\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:47:43,620] (INFO): Trial 1 finished with value: -1347.3911970853194 and parameters: {'feature_fraction': 0.5499874579090014, 'num_leaves': 218, 'bagging_fraction': 0.9330880728874675, 'min_sum_hessian_in_leaf': 0.2537815508265665, 'reg_alpha': 0.023585940584142682, 'reg_lambda': 1.5320059381854043e-08}. Best is trial 1 with value: -1347.3911970853194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1542.15\n",
      "[200]\tvalid's l1: 1398.58\n",
      "[300]\tvalid's l1: 1377.01\n",
      "[400]\tvalid's l1: 1366.71\n",
      "[500]\tvalid's l1: 1360.79\n",
      "[600]\tvalid's l1: 1355.44\n",
      "[700]\tvalid's l1: 1351.41\n",
      "[800]\tvalid's l1: 1349\n",
      "[900]\tvalid's l1: 1347.34\n",
      "[1000]\tvalid's l1: 1345.64\n",
      "[1100]\tvalid's l1: 1344.09\n",
      "[1200]\tvalid's l1: 1343.22\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1343.21\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:48:03,351] (INFO): Trial 2 finished with value: -1343.2110717626688 and parameters: {'feature_fraction': 0.9849549260809971, 'num_leaves': 251, 'bagging_fraction': 0.9692763545078751, 'min_sum_hessian_in_leaf': 0.0010071984838809194, 'reg_alpha': 8.509499823666633, 'reg_lambda': 0.0036085571407386235}. Best is trial 2 with value: -1343.2110717626688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1534.49\n",
      "[200]\tvalid's l1: 1408.57\n",
      "[300]\tvalid's l1: 1385.76\n",
      "[400]\tvalid's l1: 1375.01\n",
      "[500]\tvalid's l1: 1366.05\n",
      "[600]\tvalid's l1: 1361.01\n",
      "[700]\tvalid's l1: 1356.92\n",
      "[800]\tvalid's l1: 1353.3\n",
      "[900]\tvalid's l1: 1350.99\n",
      "[1000]\tvalid's l1: 1349.21\n",
      "[1100]\tvalid's l1: 1348.14\n",
      "[1200]\tvalid's l1: 1346.97\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1346.97\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:48:19,745] (INFO): Trial 3 finished with value: -1346.9701823763446 and parameters: {'feature_fraction': 0.8058265802441404, 'num_leaves': 251, 'bagging_fraction': 0.5115312125207079, 'min_sum_hessian_in_leaf': 0.12563152773938666, 'reg_alpha': 3.9696182670988566e-05, 'reg_lambda': 2.630213296503227e-08}. Best is trial 2 with value: -1343.2110717626688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1733.17\n",
      "[200]\tvalid's l1: 1609.06\n",
      "[300]\tvalid's l1: 1579.72\n",
      "[400]\tvalid's l1: 1568.03\n",
      "[500]\tvalid's l1: 1557.17\n",
      "[600]\tvalid's l1: 1548.07\n",
      "[700]\tvalid's l1: 1539.09\n",
      "[800]\tvalid's l1: 1531.99\n",
      "[900]\tvalid's l1: 1526.95\n",
      "[1000]\tvalid's l1: 1523.33\n",
      "[1100]\tvalid's l1: 1521.47\n",
      "[1200]\tvalid's l1: 1519.6\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1519.51\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:48:25,414] (INFO): Trial 4 finished with value: -1519.5066718100084 and parameters: {'feature_fraction': 0.9868777594207296, 'num_leaves': 30, 'bagging_fraction': 0.728034992108518, 'min_sum_hessian_in_leaf': 1.382623217936987, 'reg_alpha': 6.267062696005991e-07, 'reg_lambda': 0.00042472707398058225}. Best is trial 2 with value: -1343.2110717626688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1544.01\n",
      "[200]\tvalid's l1: 1414.09\n",
      "[300]\tvalid's l1: 1397.89\n",
      "[400]\tvalid's l1: 1389.36\n",
      "[500]\tvalid's l1: 1384.63\n",
      "[600]\tvalid's l1: 1380.37\n",
      "[700]\tvalid's l1: 1379.21\n",
      "[800]\tvalid's l1: 1377.05\n",
      "[900]\tvalid's l1: 1374.42\n",
      "[1000]\tvalid's l1: 1372.74\n",
      "[1100]\tvalid's l1: 1370.61\n",
      "[1200]\tvalid's l1: 1368.42\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1368.42\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:48:38,461] (INFO): Trial 5 finished with value: -1368.4231292675147 and parameters: {'feature_fraction': 0.7962072844310213, 'num_leaves': 146, 'bagging_fraction': 0.9299702033681603, 'min_sum_hessian_in_leaf': 0.5262961031076743, 'reg_alpha': 0.00011336872639641431, 'reg_lambda': 1.316390230170444e-08}. Best is trial 2 with value: -1343.2110717626688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1738.85\n",
      "[200]\tvalid's l1: 1615.38\n",
      "[300]\tvalid's l1: 1584.73\n",
      "[400]\tvalid's l1: 1571.02\n",
      "[500]\tvalid's l1: 1562.68\n",
      "[600]\tvalid's l1: 1558.46\n",
      "[700]\tvalid's l1: 1553.46\n",
      "[800]\tvalid's l1: 1551.7\n",
      "[900]\tvalid's l1: 1549.32\n",
      "[1000]\tvalid's l1: 1548.12\n",
      "[1100]\tvalid's l1: 1547.34\n",
      "[1200]\tvalid's l1: 1545.87\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1545.87\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:48:44,251] (INFO): Trial 6 finished with value: -1545.8697938025978 and parameters: {'feature_fraction': 0.9711008778424264, 'num_leaves': 29, 'bagging_fraction': 0.9041986740582306, 'min_sum_hessian_in_leaf': 0.01653693718282442, 'reg_alpha': 7.569183361880229e-08, 'reg_lambda': 0.014391207615728067}. Best is trial 2 with value: -1343.2110717626688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1527.92\n",
      "[200]\tvalid's l1: 1396.24\n",
      "[300]\tvalid's l1: 1376.86\n",
      "[400]\tvalid's l1: 1364.73\n",
      "[500]\tvalid's l1: 1358.57\n",
      "[600]\tvalid's l1: 1353\n",
      "[700]\tvalid's l1: 1349.3\n",
      "[800]\tvalid's l1: 1346.7\n",
      "[900]\tvalid's l1: 1344.21\n",
      "[1000]\tvalid's l1: 1341.35\n",
      "[1100]\tvalid's l1: 1339.12\n",
      "[1200]\tvalid's l1: 1338.2\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1183]\tvalid's l1: 1338.19\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:48:58,591] (INFO): Trial 7 finished with value: -1338.1868133021349 and parameters: {'feature_fraction': 0.7200762468698007, 'num_leaves': 214, 'bagging_fraction': 0.8049983288913105, 'min_sum_hessian_in_leaf': 2.1516897298083326, 'reg_alpha': 3.6331378936352306e-07, 'reg_lambda': 3.307847415252541e-05}. Best is trial 7 with value: -1338.1868133021349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1600.53\n",
      "[200]\tvalid's l1: 1456.92\n",
      "[300]\tvalid's l1: 1426.19\n",
      "[400]\tvalid's l1: 1410.34\n",
      "[500]\tvalid's l1: 1400.46\n",
      "[600]\tvalid's l1: 1393.39\n",
      "[700]\tvalid's l1: 1387.8\n",
      "[800]\tvalid's l1: 1384.52\n",
      "[900]\tvalid's l1: 1379.78\n",
      "[1000]\tvalid's l1: 1376.19\n",
      "[1100]\tvalid's l1: 1373.38\n",
      "[1200]\tvalid's l1: 1371.1\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1186]\tvalid's l1: 1370.99\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:49:09,056] (INFO): Trial 8 finished with value: -1370.9929735888104 and parameters: {'feature_fraction': 0.5911180438940311, 'num_leaves': 147, 'bagging_fraction': 0.6558555380447055, 'min_sum_hessian_in_leaf': 0.12030178871154672, 'reg_alpha': 0.0008325158565947976, 'reg_lambda': 4.609885087947832e-07}. Best is trial 7 with value: -1338.1868133021349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1523.85\n",
      "[200]\tvalid's l1: 1395.29\n",
      "[300]\tvalid's l1: 1375.43\n",
      "[400]\tvalid's l1: 1363.59\n",
      "[500]\tvalid's l1: 1357.06\n",
      "[600]\tvalid's l1: 1352.66\n",
      "[700]\tvalid's l1: 1349.47\n",
      "[800]\tvalid's l1: 1346.01\n",
      "[900]\tvalid's l1: 1343.45\n",
      "[1000]\tvalid's l1: 1341.52\n",
      "[1100]\tvalid's l1: 1339.39\n",
      "[1200]\tvalid's l1: 1337.81\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1337.81\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:49:26,256] (INFO): Trial 9 finished with value: -1337.8061129048879 and parameters: {'feature_fraction': 0.9847923138822793, 'num_leaves': 233, 'bagging_fraction': 0.7248770666848828, 'min_sum_hessian_in_leaf': 0.03807158379249393, 'reg_alpha': 2.1874079799487576, 'reg_lambda': 0.0351113851431067}. Best is trial 9 with value: -1337.8061129048879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1558.33\n",
      "[200]\tvalid's l1: 1415.9\n",
      "[300]\tvalid's l1: 1392.13\n",
      "[400]\tvalid's l1: 1380.14\n",
      "[500]\tvalid's l1: 1373.42\n",
      "[600]\tvalid's l1: 1368.11\n",
      "[700]\tvalid's l1: 1364.41\n",
      "[800]\tvalid's l1: 1361.71\n",
      "[900]\tvalid's l1: 1359.24\n",
      "[1000]\tvalid's l1: 1357.38\n",
      "[1100]\tvalid's l1: 1355.86\n",
      "[1200]\tvalid's l1: 1353.41\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1353.41\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:49:41,637] (INFO): Trial 10 finished with value: -1353.4055697285528 and parameters: {'feature_fraction': 0.8886185629157468, 'num_leaves': 189, 'bagging_fraction': 0.8097051848286712, 'min_sum_hessian_in_leaf': 0.011537653383416786, 'reg_alpha': 7.154200555296032, 'reg_lambda': 1.475649304728376}. Best is trial 9 with value: -1337.8061129048879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1550.91\n",
      "[200]\tvalid's l1: 1415.21\n",
      "[300]\tvalid's l1: 1393.8\n",
      "[400]\tvalid's l1: 1383.89\n",
      "[500]\tvalid's l1: 1377.22\n",
      "[600]\tvalid's l1: 1370.49\n",
      "[700]\tvalid's l1: 1366.07\n",
      "[800]\tvalid's l1: 1363.32\n",
      "[900]\tvalid's l1: 1360.32\n",
      "[1000]\tvalid's l1: 1358.15\n",
      "[1100]\tvalid's l1: 1355.68\n",
      "[1200]\tvalid's l1: 1353.38\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1353.38\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:49:55,255] (INFO): Trial 11 finished with value: -1353.3806551439982 and parameters: {'feature_fraction': 0.6808112248798672, 'num_leaves': 196, 'bagging_fraction': 0.8049468174448701, 'min_sum_hessian_in_leaf': 9.971759606454258, 'reg_alpha': 0.10440880463036205, 'reg_lambda': 1.378828447107251}. Best is trial 9 with value: -1337.8061129048879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1534.16\n",
      "[200]\tvalid's l1: 1402.37\n",
      "[300]\tvalid's l1: 1374.78\n",
      "[400]\tvalid's l1: 1363.33\n",
      "[500]\tvalid's l1: 1355.09\n",
      "[600]\tvalid's l1: 1350.65\n",
      "[700]\tvalid's l1: 1346.21\n",
      "[800]\tvalid's l1: 1343.2\n",
      "[900]\tvalid's l1: 1341.15\n",
      "[1000]\tvalid's l1: 1339.58\n",
      "[1100]\tvalid's l1: 1337.12\n",
      "[1200]\tvalid's l1: 1335.3\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1335.3\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:50:10,820] (INFO): Trial 12 finished with value: -1335.2963886976345 and parameters: {'feature_fraction': 0.707639611538789, 'num_leaves': 228, 'bagging_fraction': 0.7041144922029271, 'min_sum_hessian_in_leaf': 0.022825825349638583, 'reg_alpha': 2.6799444561661987e-06, 'reg_lambda': 6.454017260532084e-06}. Best is trial 12 with value: -1335.2963886976345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1552.22\n",
      "[200]\tvalid's l1: 1408.75\n",
      "[300]\tvalid's l1: 1381.78\n",
      "[400]\tvalid's l1: 1367.32\n",
      "[500]\tvalid's l1: 1360.84\n",
      "[600]\tvalid's l1: 1355.97\n",
      "[700]\tvalid's l1: 1351.65\n",
      "[800]\tvalid's l1: 1347.96\n",
      "[900]\tvalid's l1: 1344.24\n",
      "[1000]\tvalid's l1: 1341.37\n",
      "[1100]\tvalid's l1: 1338.41\n",
      "[1200]\tvalid's l1: 1336.87\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1336.85\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:50:26,111] (INFO): Trial 13 finished with value: -1336.8495956646884 and parameters: {'feature_fraction': 0.6192672277196036, 'num_leaves': 251, 'bagging_fraction': 0.6907879376889303, 'min_sum_hessian_in_leaf': 0.0169159633201643, 'reg_alpha': 3.6066727494657723e-06, 'reg_lambda': 3.0759010080706543e-06}. Best is trial 12 with value: -1335.2963886976345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1625.37\n",
      "[200]\tvalid's l1: 1482.63\n",
      "[300]\tvalid's l1: 1449.9\n",
      "[400]\tvalid's l1: 1431.96\n",
      "[500]\tvalid's l1: 1421.13\n",
      "[600]\tvalid's l1: 1414.33\n",
      "[700]\tvalid's l1: 1410.06\n",
      "[800]\tvalid's l1: 1405.04\n",
      "[900]\tvalid's l1: 1400.93\n",
      "[1000]\tvalid's l1: 1397.92\n",
      "[1100]\tvalid's l1: 1395.26\n",
      "[1200]\tvalid's l1: 1393.7\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1393.7\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:50:34,791] (INFO): Trial 14 finished with value: -1393.7042442888749 and parameters: {'feature_fraction': 0.6187558544652172, 'num_leaves': 101, 'bagging_fraction': 0.6253285603944095, 'min_sum_hessian_in_leaf': 0.002327161105117699, 'reg_alpha': 6.62007450343884e-06, 'reg_lambda': 1.3428050799078128e-06}. Best is trial 12 with value: -1335.2963886976345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1610.6\n",
      "[200]\tvalid's l1: 1456.32\n",
      "[300]\tvalid's l1: 1422.71\n",
      "[400]\tvalid's l1: 1407.74\n",
      "[500]\tvalid's l1: 1397.71\n",
      "[600]\tvalid's l1: 1392.16\n",
      "[700]\tvalid's l1: 1385.73\n",
      "[800]\tvalid's l1: 1380.83\n",
      "[900]\tvalid's l1: 1377.78\n",
      "[1000]\tvalid's l1: 1375.16\n",
      "[1100]\tvalid's l1: 1374\n",
      "[1200]\tvalid's l1: 1371.31\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1371.29\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:50:45,699] (INFO): Trial 15 finished with value: -1371.2852853555341 and parameters: {'feature_fraction': 0.5166280172201545, 'num_leaves': 180, 'bagging_fraction': 0.5429519536861079, 'min_sum_hessian_in_leaf': 0.004416170874087896, 'reg_alpha': 1.302184213867467e-08, 'reg_lambda': 1.2681372413351911e-06}. Best is trial 12 with value: -1335.2963886976345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1545.23\n",
      "[200]\tvalid's l1: 1409.58\n",
      "[300]\tvalid's l1: 1381.48\n",
      "[400]\tvalid's l1: 1369.88\n",
      "[500]\tvalid's l1: 1362.09\n",
      "[600]\tvalid's l1: 1357.84\n",
      "[700]\tvalid's l1: 1353.6\n",
      "[800]\tvalid's l1: 1349.92\n",
      "[900]\tvalid's l1: 1347.34\n",
      "[1000]\tvalid's l1: 1344.35\n",
      "[1100]\tvalid's l1: 1341.08\n",
      "[1200]\tvalid's l1: 1340.09\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1340.09\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:51:00,526] (INFO): Trial 16 finished with value: -1340.0934489882065 and parameters: {'feature_fraction': 0.6287433332939351, 'num_leaves': 254, 'bagging_fraction': 0.6792527326305617, 'min_sum_hessian_in_leaf': 0.03520161111608382, 'reg_alpha': 4.552432274644878e-06, 'reg_lambda': 9.588140725430072e-06}. Best is trial 12 with value: -1335.2963886976345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1652.22\n",
      "[200]\tvalid's l1: 1512.83\n",
      "[300]\tvalid's l1: 1488.28\n",
      "[400]\tvalid's l1: 1470.99\n",
      "[500]\tvalid's l1: 1460.17\n",
      "[600]\tvalid's l1: 1453.03\n",
      "[700]\tvalid's l1: 1448.68\n",
      "[800]\tvalid's l1: 1442.44\n",
      "[900]\tvalid's l1: 1438.77\n",
      "[1000]\tvalid's l1: 1435.84\n",
      "[1100]\tvalid's l1: 1433.13\n",
      "[1200]\tvalid's l1: 1428.14\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1428.07\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:51:07,710] (INFO): Trial 17 finished with value: -1428.0725826682628 and parameters: {'feature_fraction': 0.7805033968888809, 'num_leaves': 61, 'bagging_fraction': 0.5867291340943912, 'min_sum_hessian_in_leaf': 0.0063389973473963615, 'reg_alpha': 1.0002320927098959e-08, 'reg_lambda': 1.9971786916444498e-07}. Best is trial 12 with value: -1335.2963886976345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1540.64\n",
      "[200]\tvalid's l1: 1412.56\n",
      "[300]\tvalid's l1: 1392.72\n",
      "[400]\tvalid's l1: 1382.26\n",
      "[500]\tvalid's l1: 1373.82\n",
      "[600]\tvalid's l1: 1368.8\n",
      "[700]\tvalid's l1: 1364.65\n",
      "[800]\tvalid's l1: 1360.57\n",
      "[900]\tvalid's l1: 1357.63\n",
      "[1000]\tvalid's l1: 1353.78\n",
      "[1100]\tvalid's l1: 1351.32\n",
      "[1200]\tvalid's l1: 1349.33\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1349.32\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:51:21,434] (INFO): Trial 18 finished with value: -1349.3167961498962 and parameters: {'feature_fraction': 0.8626232813873017, 'num_leaves': 166, 'bagging_fraction': 0.6893852913380736, 'min_sum_hessian_in_leaf': 0.031401924617101694, 'reg_alpha': 6.908794273381125e-06, 'reg_lambda': 7.9123694600612e-06}. Best is trial 12 with value: -1335.2963886976345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1549.14\n",
      "[200]\tvalid's l1: 1408.03\n",
      "[300]\tvalid's l1: 1382.92\n",
      "[400]\tvalid's l1: 1370.42\n",
      "[500]\tvalid's l1: 1364.39\n",
      "[600]\tvalid's l1: 1360.8\n",
      "[700]\tvalid's l1: 1357.32\n",
      "[800]\tvalid's l1: 1353.86\n",
      "[900]\tvalid's l1: 1350.04\n",
      "[1000]\tvalid's l1: 1347.59\n",
      "[1100]\tvalid's l1: 1346.61\n",
      "[1200]\tvalid's l1: 1344.44\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1344.42\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:51:37,524] (INFO): Trial 19 finished with value: -1344.4195929584478 and parameters: {'feature_fraction': 0.6570956069972215, 'num_leaves': 227, 'bagging_fraction': 0.7642099848101362, 'min_sum_hessian_in_leaf': 0.003205161553901499, 'reg_alpha': 5.611036691321753e-07, 'reg_lambda': 0.0003386423522243304}. Best is trial 12 with value: -1335.2963886976345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1581.15\n",
      "[200]\tvalid's l1: 1447.7\n",
      "[300]\tvalid's l1: 1428.27\n",
      "[400]\tvalid's l1: 1412.17\n",
      "[500]\tvalid's l1: 1404.44\n",
      "[600]\tvalid's l1: 1399.77\n",
      "[700]\tvalid's l1: 1394.98\n",
      "[800]\tvalid's l1: 1391.12\n",
      "[900]\tvalid's l1: 1387.09\n",
      "[1000]\tvalid's l1: 1384.8\n",
      "[1100]\tvalid's l1: 1382.6\n",
      "[1200]\tvalid's l1: 1381.31\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1381.31\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:51:47,811] (INFO): Trial 20 finished with value: -1381.3081082251092 and parameters: {'feature_fraction': 0.7366410835474713, 'num_leaves': 120, 'bagging_fraction': 0.7632528306584996, 'min_sum_hessian_in_leaf': 0.0016604058569046035, 'reg_alpha': 2.681964438719631e-05, 'reg_lambda': 7.248715717895558e-08}. Best is trial 12 with value: -1335.2963886976345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1572.13\n",
      "[200]\tvalid's l1: 1433.58\n",
      "[300]\tvalid's l1: 1405.45\n",
      "[400]\tvalid's l1: 1392.14\n",
      "[500]\tvalid's l1: 1384.1\n",
      "[600]\tvalid's l1: 1376.82\n",
      "[700]\tvalid's l1: 1371.92\n",
      "[800]\tvalid's l1: 1369.08\n",
      "[900]\tvalid's l1: 1364.73\n",
      "[1000]\tvalid's l1: 1362.88\n",
      "[1100]\tvalid's l1: 1359.76\n",
      "[1200]\tvalid's l1: 1357.55\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1357.54\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:52:01,875] (INFO): Trial 21 finished with value: -1357.5410581365418 and parameters: {'feature_fraction': 0.5662374445345695, 'num_leaves': 229, 'bagging_fraction': 0.7185348684491378, 'min_sum_hessian_in_leaf': 0.035875380583432606, 'reg_alpha': 0.48960042559135175, 'reg_lambda': 0.10847707653174746}. Best is trial 12 with value: -1335.2963886976345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1512.88\n",
      "[200]\tvalid's l1: 1382.29\n",
      "[300]\tvalid's l1: 1360\n",
      "[400]\tvalid's l1: 1346.69\n",
      "[500]\tvalid's l1: 1340.65\n",
      "[600]\tvalid's l1: 1336.53\n",
      "[700]\tvalid's l1: 1333.43\n",
      "[800]\tvalid's l1: 1330.35\n",
      "[900]\tvalid's l1: 1328.27\n",
      "[1000]\tvalid's l1: 1326.49\n",
      "[1100]\tvalid's l1: 1324.41\n",
      "[1200]\tvalid's l1: 1322.79\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1322.78\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:52:20,463] (INFO): Trial 22 finished with value: -1322.7815351807435 and parameters: {'feature_fraction': 0.8599163056089478, 'num_leaves': 255, 'bagging_fraction': 0.842305745621851, 'min_sum_hessian_in_leaf': 0.05123808906963574, 'reg_alpha': 8.330384977363979e-08, 'reg_lambda': 0.0012741566446357704}. Best is trial 22 with value: -1322.7815351807435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1400.85\n",
      "[200]\tvalid's l1: 1363.08\n",
      "[300]\tvalid's l1: 1352.53\n",
      "[400]\tvalid's l1: 1343.42\n",
      "[500]\tvalid's l1: 1338.1\n",
      "[600]\tvalid's l1: 1333.06\n",
      "[700]\tvalid's l1: 1329.86\n",
      "[800]\tvalid's l1: 1327.19\n",
      "[900]\tvalid's l1: 1325.37\n",
      "[1000]\tvalid's l1: 1323.87\n",
      "[1100]\tvalid's l1: 1321.54\n",
      "[1200]\tvalid's l1: 1319.98\n",
      "[1300]\tvalid's l1: 1318.61\n",
      "[1400]\tvalid's l1: 1317.95\n",
      "[1500]\tvalid's l1: 1316.92\n",
      "[1600]\tvalid's l1: 1317.06\n",
      "[1700]\tvalid's l1: 1315.95\n",
      "[1800]\tvalid's l1: 1314.9\n",
      "[1900]\tvalid's l1: 1314.86\n",
      "Early stopping, best iteration is:\n",
      "[1868]\tvalid's l1: 1314.46\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1472.84\n",
      "[200]\tvalid's l1: 1445.26\n",
      "[300]\tvalid's l1: 1439.28\n",
      "[400]\tvalid's l1: 1435.83\n",
      "[500]\tvalid's l1: 1431.62\n",
      "[600]\tvalid's l1: 1428.76\n",
      "[700]\tvalid's l1: 1427.31\n",
      "[800]\tvalid's l1: 1426.13\n",
      "[900]\tvalid's l1: 1425.41\n",
      "[1000]\tvalid's l1: 1422.85\n",
      "[1100]\tvalid's l1: 1422.46\n",
      "Early stopping, best iteration is:\n",
      "[1028]\tvalid's l1: 1422.15\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1505.14\n",
      "[200]\tvalid's l1: 1462.32\n",
      "[300]\tvalid's l1: 1446.92\n",
      "[400]\tvalid's l1: 1442.16\n",
      "[500]\tvalid's l1: 1439.89\n",
      "[600]\tvalid's l1: 1436.91\n",
      "[700]\tvalid's l1: 1434.03\n",
      "[800]\tvalid's l1: 1433.25\n",
      "[900]\tvalid's l1: 1431.05\n",
      "[1000]\tvalid's l1: 1429.41\n",
      "[1100]\tvalid's l1: 1432.78\n",
      "Early stopping, best iteration is:\n",
      "[1059]\tvalid's l1: 1429.01\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1486.46\n",
      "[200]\tvalid's l1: 1448\n",
      "[300]\tvalid's l1: 1438.26\n",
      "[400]\tvalid's l1: 1428.75\n",
      "[500]\tvalid's l1: 1422.88\n",
      "[600]\tvalid's l1: 1419.29\n",
      "[700]\tvalid's l1: 1417.53\n",
      "[800]\tvalid's l1: 1414.65\n",
      "[900]\tvalid's l1: 1413.31\n",
      "[1000]\tvalid's l1: 1411.74\n",
      "[1100]\tvalid's l1: 1410.5\n",
      "[1200]\tvalid's l1: 1409.39\n",
      "[1300]\tvalid's l1: 1408.06\n",
      "[1400]\tvalid's l1: 1406.84\n",
      "[1500]\tvalid's l1: 1406.05\n",
      "[1600]\tvalid's l1: 1405.27\n",
      "[1700]\tvalid's l1: 1404.5\n",
      "[1800]\tvalid's l1: 1402.79\n",
      "[1900]\tvalid's l1: 1401.94\n",
      "[2000]\tvalid's l1: 1401.69\n",
      "[2100]\tvalid's l1: 1401.18\n",
      "[2200]\tvalid's l1: 1400.68\n",
      "[2300]\tvalid's l1: 1400.37\n",
      "[2400]\tvalid's l1: 1399.6\n",
      "[2500]\tvalid's l1: 1399.37\n",
      "[2600]\tvalid's l1: 1398.79\n",
      "[2700]\tvalid's l1: 1398.55\n",
      "Early stopping, best iteration is:\n",
      "[2622]\tvalid's l1: 1398.35\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1525.76\n",
      "[200]\tvalid's l1: 1480.57\n",
      "[300]\tvalid's l1: 1465.06\n",
      "[400]\tvalid's l1: 1457.56\n",
      "[500]\tvalid's l1: 1451.48\n",
      "[600]\tvalid's l1: 1443.53\n",
      "[700]\tvalid's l1: 1439.65\n",
      "[800]\tvalid's l1: 1436.52\n",
      "[900]\tvalid's l1: 1434.4\n",
      "[1000]\tvalid's l1: 1432.1\n",
      "[1100]\tvalid's l1: 1430.48\n",
      "[1200]\tvalid's l1: 1429.7\n",
      "[1300]\tvalid's l1: 1428.25\n",
      "[1400]\tvalid's l1: 1427.36\n",
      "[1500]\tvalid's l1: 1426.92\n",
      "[1600]\tvalid's l1: 1425.81\n",
      "[1700]\tvalid's l1: 1425.33\n",
      "[1800]\tvalid's l1: 1424.76\n",
      "[1900]\tvalid's l1: 1424.4\n",
      "[2000]\tvalid's l1: 1423.77\n",
      "[2100]\tvalid's l1: 1423.16\n",
      "[2200]\tvalid's l1: 1422.65\n",
      "[2300]\tvalid's l1: 1421.97\n",
      "[2400]\tvalid's l1: 1420.94\n",
      "[2500]\tvalid's l1: 1419.9\n",
      "[2600]\tvalid's l1: 1419.84\n",
      "[2700]\tvalid's l1: 1419.52\n",
      "[2800]\tvalid's l1: 1419.12\n",
      "[2900]\tvalid's l1: 1418.54\n",
      "[3000]\tvalid's l1: 1418.52\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2983]\tvalid's l1: 1418.45\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 1006.7258970737457\n",
      "Blending: Optimization starts with equal weights and score -1640.0092306414106\n",
      "Blending, iter 0: score = -1396.4840012204095, weights = [0. 0. 1.]\n",
      "Blending, iter 1: score = -1396.4840012204095, weights = [0. 0. 1.]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 532.02 seconds.\n",
      "Current random state: {'reader_params': {'random_state': 47}, 'general_params': {'return_all_predictions': False}}\n",
      "Found reader_params in kwargs, need to combine\n",
      "Merged variant for reader_params = {'n_jobs': 8, 'cv': 5, 'random_state': 47}\n",
      "Found general_params in kwargs, need to combine\n",
      "Merged variant for general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']], 'return_all_predictions': False}\n",
      "Start automl preset with listed constraints:\n",
      "- time: 1006.5275361537933 seconds\n",
      "- cpus: 8 cores\n",
      "- memory: 16 gb\n",
      "\n",
      "Train data shape: (34994, 145)\n",
      "Feats was rejected during automatic roles guess: []\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 997.4967024326324 secs\n",
      "Start fitting Lvl_0_Pipe_0_Mod_0_LinearL2 ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3756.9943561622085\n",
      "Linear model: C = 5e-05 score = -3749.655293704067\n",
      "Linear model: C = 0.0001 score = -3740.3741219797585\n",
      "Linear model: C = 0.0005 score = -3669.4798523463733\n",
      "Linear model: C = 0.001 score = -3588.924018930718\n",
      "Linear model: C = 0.005 score = -3157.3496964328338\n",
      "Linear model: C = 0.01 score = -2896.0638637605402\n",
      "Linear model: C = 0.05 score = -2531.430887315491\n",
      "Linear model: C = 0.1 score = -2423.7399716628656\n",
      "Linear model: C = 0.5 score = -2256.507507690482\n",
      "Linear model: C = 1 score = -2221.092921228541\n",
      "Linear model: C = 5 score = -2221.092690586516\n",
      "Linear model: C = 10 score = -2170.342304613441\n",
      "Linear model: C = 50 score = -2170.342206728494\n",
      "Linear model: C = 100 score = -2170.3422600116232\n",
      "Linear model: C = 500 score = -2170.3422901236954\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3788.293657394695\n",
      "Linear model: C = 5e-05 score = -3780.791862251248\n",
      "Linear model: C = 0.0001 score = -3771.223463145405\n",
      "Linear model: C = 0.0005 score = -3699.3498676778045\n",
      "Linear model: C = 0.001 score = -3618.259553889953\n",
      "Linear model: C = 0.005 score = -3182.819554724205\n",
      "Linear model: C = 0.01 score = -2925.3537427262077\n",
      "Linear model: C = 0.05 score = -2557.0915303784177\n",
      "Linear model: C = 0.1 score = -2445.3876780174614\n",
      "Linear model: C = 0.5 score = -2283.3562384843995\n",
      "Linear model: C = 1 score = -2283.355584814031\n",
      "Linear model: C = 5 score = -2223.176904502026\n",
      "Linear model: C = 10 score = -2223.1770651073757\n",
      "Linear model: C = 50 score = -2223.1770583434964\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3749.247600417526\n",
      "Linear model: C = 5e-05 score = -3741.7194502604725\n",
      "Linear model: C = 0.0001 score = -3732.2160218968224\n",
      "Linear model: C = 0.0005 score = -3659.488790739637\n",
      "Linear model: C = 0.001 score = -3578.3195720552153\n",
      "Linear model: C = 0.005 score = -3140.8966745125053\n",
      "Linear model: C = 0.01 score = -2886.980321744354\n",
      "Linear model: C = 0.05 score = -2524.301315517728\n",
      "Linear model: C = 0.1 score = -2417.1421767895795\n",
      "Linear model: C = 0.5 score = -2243.0883188783178\n",
      "Linear model: C = 1 score = -2243.0878512626\n",
      "Linear model: C = 5 score = -2157.469245572723\n",
      "Linear model: C = 10 score = -2157.4692858605918\n",
      "Linear model: C = 50 score = -2157.4694734233535\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n",
      "Linear model: C = 1e-05 score = -3732.9174674925657\n",
      "Linear model: C = 5e-05 score = -3725.4865167680205\n",
      "Linear model: C = 0.0001 score = -3716.0849573446317\n",
      "Linear model: C = 0.0005 score = -3644.7300361407656\n",
      "Linear model: C = 0.001 score = -3564.010095750286\n",
      "Linear model: C = 0.005 score = -3139.6985454578403\n",
      "Linear model: C = 0.01 score = -2880.296757486722\n",
      "Linear model: C = 0.05 score = -2517.169003467966\n",
      "Linear model: C = 0.1 score = -2412.141335871206\n",
      "Linear model: C = 0.5 score = -2254.2334902578464\n",
      "Linear model: C = 1 score = -2225.4185862496915\n",
      "Linear model: C = 5 score = -2225.4185862496915\n",
      "Linear model: C = 10 score = -2194.244947068026\n",
      "Linear model: C = 50 score = -2194.244342915142\n",
      "Linear model: C = 100 score = -2194.244176985349\n",
      "Linear model: C = 500 score = -2194.2440107001935\n",
      "Linear model: C = 1000 score = -2194.2436464295793\n",
      "Linear model: C = 5000 score = -2194.2436464295793\n",
      "Linear model: C = 10000 score = -2194.2436464295793\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_0_Mod_0_LinearL2 =====\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model: C = 1e-05 score = -3701.1227827091225\n",
      "Linear model: C = 5e-05 score = -3693.7696803578924\n",
      "Linear model: C = 0.0001 score = -3684.510002648636\n",
      "Linear model: C = 0.0005 score = -3614.1023885591194\n",
      "Linear model: C = 0.001 score = -3535.455317206981\n",
      "Linear model: C = 0.005 score = -3115.7721692221817\n",
      "Linear model: C = 0.01 score = -2861.127550351344\n",
      "Linear model: C = 0.05 score = -2512.6664976799752\n",
      "Linear model: C = 0.1 score = -2408.6926321851147\n",
      "Linear model: C = 0.5 score = -2238.6922403222734\n",
      "Linear model: C = 1 score = -2204.1556283678797\n",
      "Linear model: C = 5 score = -2204.1556283678797\n",
      "Linear model: C = 10 score = -2204.1555988096993\n",
      "Linear model: C = 50 score = -2156.7383784719045\n",
      "Linear model: C = 100 score = -2156.738384866074\n",
      "Linear model: C = 500 score = -2156.7383522105647\n",
      "Linear model: C = 1000 score = -2156.7383289953136\n",
      "Linear model: C = 5000 score = -2156.7381453556345\n",
      "Linear model: C = 10000 score = -2156.738072777176\n",
      "Linear model: C = 50000 score = -2156.7380223095706\n",
      "Linear model: C = 100000 score = -2156.7379043984665\n",
      "Lvl_0_Pipe_0_Mod_0_LinearL2 fitting and predicting completed\n",
      "Time left 949.57892537117\n",
      "Start fitting Selector_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Selector_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2092.9\n",
      "[200]\tvalid's l1: 1926.41\n",
      "[300]\tvalid's l1: 1872.2\n",
      "[400]\tvalid's l1: 1848.68\n",
      "[500]\tvalid's l1: 1828.72\n",
      "[600]\tvalid's l1: 1813.74\n",
      "[700]\tvalid's l1: 1804.46\n",
      "[800]\tvalid's l1: 1794.01\n",
      "[900]\tvalid's l1: 1781.87\n",
      "[1000]\tvalid's l1: 1771.26\n",
      "[1100]\tvalid's l1: 1758.68\n",
      "[1200]\tvalid's l1: 1750.5\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1750.5\n",
      "Selector_LightGBM fitting and predicting completed\n",
      "Start fitting Lvl_0_Pipe_1_Mod_0_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1763.05\n",
      "[200]\tvalid's l1: 1639.69\n",
      "[300]\tvalid's l1: 1612.19\n",
      "[400]\tvalid's l1: 1600.3\n",
      "[500]\tvalid's l1: 1596.03\n",
      "[600]\tvalid's l1: 1591.59\n",
      "[700]\tvalid's l1: 1587.31\n",
      "[800]\tvalid's l1: 1583.02\n",
      "[900]\tvalid's l1: 1580.75\n",
      "[1000]\tvalid's l1: 1576.02\n",
      "[1100]\tvalid's l1: 1571.31\n",
      "[1200]\tvalid's l1: 1569.39\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1569.39\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1761.96\n",
      "[200]\tvalid's l1: 1640.62\n",
      "[300]\tvalid's l1: 1605.19\n",
      "[400]\tvalid's l1: 1593.5\n",
      "[500]\tvalid's l1: 1587.64\n",
      "[600]\tvalid's l1: 1580.76\n",
      "[700]\tvalid's l1: 1575.81\n",
      "[800]\tvalid's l1: 1572.58\n",
      "[900]\tvalid's l1: 1571.27\n",
      "[1000]\tvalid's l1: 1569.06\n",
      "[1100]\tvalid's l1: 1564.85\n",
      "[1200]\tvalid's l1: 1562.33\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1562.32\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1747.24\n",
      "[200]\tvalid's l1: 1633.24\n",
      "[300]\tvalid's l1: 1603.24\n",
      "[400]\tvalid's l1: 1592.72\n",
      "[500]\tvalid's l1: 1584.19\n",
      "[600]\tvalid's l1: 1577.38\n",
      "[700]\tvalid's l1: 1572.65\n",
      "[800]\tvalid's l1: 1570.85\n",
      "[900]\tvalid's l1: 1568.46\n",
      "[1000]\tvalid's l1: 1563.44\n",
      "[1100]\tvalid's l1: 1561.33\n",
      "[1200]\tvalid's l1: 1560.95\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1190]\tvalid's l1: 1560.95\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1737.8\n",
      "[200]\tvalid's l1: 1614.44\n",
      "[300]\tvalid's l1: 1584.3\n",
      "[400]\tvalid's l1: 1566.86\n",
      "[500]\tvalid's l1: 1557.75\n",
      "[600]\tvalid's l1: 1553.9\n",
      "[700]\tvalid's l1: 1548.89\n",
      "[800]\tvalid's l1: 1546.46\n",
      "[900]\tvalid's l1: 1545.29\n",
      "[1000]\tvalid's l1: 1543.67\n",
      "[1100]\tvalid's l1: 1540.85\n",
      "[1200]\tvalid's l1: 1540.14\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1184]\tvalid's l1: 1540.1\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_0_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1802.02\n",
      "[200]\tvalid's l1: 1684.85\n",
      "[300]\tvalid's l1: 1656.43\n",
      "[400]\tvalid's l1: 1645.93\n",
      "[500]\tvalid's l1: 1635.02\n",
      "[600]\tvalid's l1: 1632.01\n",
      "[700]\tvalid's l1: 1629.17\n",
      "[800]\tvalid's l1: 1628.46\n",
      "[900]\tvalid's l1: 1624.88\n",
      "[1000]\tvalid's l1: 1621.65\n",
      "[1100]\tvalid's l1: 1620.31\n",
      "[1200]\tvalid's l1: 1616.95\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1616.93\n",
      "Lvl_0_Pipe_1_Mod_0_LightGBM fitting and predicting completed\n",
      "Optuna may run 736.0109295606613 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:56:19,536] (INFO): A new study created in memory with name: no-name-780a6d09-44fd-46b9-acdc-de9ae593efd7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1618.9\n",
      "[200]\tvalid's l1: 1489.49\n",
      "[300]\tvalid's l1: 1467.25\n",
      "[400]\tvalid's l1: 1453.04\n",
      "[500]\tvalid's l1: 1447.18\n",
      "[600]\tvalid's l1: 1440.49\n",
      "[700]\tvalid's l1: 1437.01\n",
      "[800]\tvalid's l1: 1432.38\n",
      "[900]\tvalid's l1: 1427.6\n",
      "[1000]\tvalid's l1: 1424.13\n",
      "[1100]\tvalid's l1: 1421.29\n",
      "[1200]\tvalid's l1: 1417.66\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1417.58\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1618.86\n",
      "[200]\tvalid's l1: 1487.45\n",
      "[300]\tvalid's l1: 1463.22\n",
      "[400]\tvalid's l1: 1452.98\n",
      "[500]\tvalid's l1: 1443.84\n",
      "[600]\tvalid's l1: 1438.79\n",
      "[700]\tvalid's l1: 1432.99\n",
      "[800]\tvalid's l1: 1429.87\n",
      "[900]\tvalid's l1: 1426.85\n",
      "[1000]\tvalid's l1: 1424.45\n",
      "[1100]\tvalid's l1: 1422.16\n",
      "[1200]\tvalid's l1: 1419.43\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1419.43\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1606.32\n",
      "[200]\tvalid's l1: 1474.03\n",
      "[300]\tvalid's l1: 1451.35\n",
      "[400]\tvalid's l1: 1437.52\n",
      "[500]\tvalid's l1: 1429.75\n",
      "[600]\tvalid's l1: 1424.55\n",
      "[700]\tvalid's l1: 1420.44\n",
      "[800]\tvalid's l1: 1416.73\n",
      "[900]\tvalid's l1: 1413.47\n",
      "[1000]\tvalid's l1: 1410.64\n",
      "[1100]\tvalid's l1: 1408.31\n",
      "[1200]\tvalid's l1: 1406.18\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1406.18\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1589.88\n",
      "[200]\tvalid's l1: 1447.53\n",
      "[300]\tvalid's l1: 1425.17\n",
      "[400]\tvalid's l1: 1412.08\n",
      "[500]\tvalid's l1: 1403.45\n",
      "[600]\tvalid's l1: 1397.42\n",
      "[700]\tvalid's l1: 1392.95\n",
      "[800]\tvalid's l1: 1390.39\n",
      "[900]\tvalid's l1: 1387.47\n",
      "[1000]\tvalid's l1: 1384.74\n",
      "[1100]\tvalid's l1: 1382.16\n",
      "[1200]\tvalid's l1: 1380.21\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1380.21\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1680.89\n",
      "[200]\tvalid's l1: 1553.37\n",
      "[300]\tvalid's l1: 1529.28\n",
      "[400]\tvalid's l1: 1515.13\n",
      "[500]\tvalid's l1: 1505.91\n",
      "[600]\tvalid's l1: 1500.67\n",
      "[700]\tvalid's l1: 1494.93\n",
      "[800]\tvalid's l1: 1491.84\n",
      "[900]\tvalid's l1: 1487.97\n",
      "[1000]\tvalid's l1: 1484.69\n",
      "[1100]\tvalid's l1: 1482.35\n",
      "[1200]\tvalid's l1: 1480.42\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1480.42\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:57:06,013] (INFO): Trial 0 finished with value: -1420.7634840336311 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 108, 'bagging_fraction': 0.5917173949330818, 'min_sum_hessian_in_leaf': 1.3145103232150122, 'reg_alpha': 0.0023531598052637494, 'reg_lambda': 0.00010291881465670109}. Best is trial 0 with value: -1420.7634840336311.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1569.06\n",
      "[200]\tvalid's l1: 1437.37\n",
      "[300]\tvalid's l1: 1419.11\n",
      "[400]\tvalid's l1: 1411.92\n",
      "[500]\tvalid's l1: 1405.18\n",
      "[600]\tvalid's l1: 1400.57\n",
      "[700]\tvalid's l1: 1395.41\n",
      "[800]\tvalid's l1: 1391.68\n",
      "[900]\tvalid's l1: 1387.79\n",
      "[1000]\tvalid's l1: 1386.06\n",
      "[1100]\tvalid's l1: 1382.58\n",
      "[1200]\tvalid's l1: 1380.9\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1380.9\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1569.9\n",
      "[200]\tvalid's l1: 1425.89\n",
      "[300]\tvalid's l1: 1408.63\n",
      "[400]\tvalid's l1: 1400.02\n",
      "[500]\tvalid's l1: 1395.45\n",
      "[600]\tvalid's l1: 1391.48\n",
      "[700]\tvalid's l1: 1389.24\n",
      "[800]\tvalid's l1: 1385.58\n",
      "[900]\tvalid's l1: 1381.76\n",
      "[1000]\tvalid's l1: 1379\n",
      "[1100]\tvalid's l1: 1377.49\n",
      "[1200]\tvalid's l1: 1375.4\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1194]\tvalid's l1: 1375.22\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1564\n",
      "[200]\tvalid's l1: 1429.74\n",
      "[300]\tvalid's l1: 1414.38\n",
      "[400]\tvalid's l1: 1410.2\n",
      "[500]\tvalid's l1: 1407.07\n",
      "[600]\tvalid's l1: 1403.17\n",
      "[700]\tvalid's l1: 1400.61\n",
      "[800]\tvalid's l1: 1396.28\n",
      "[900]\tvalid's l1: 1394.23\n",
      "[1000]\tvalid's l1: 1389.28\n",
      "[1100]\tvalid's l1: 1386.78\n",
      "[1200]\tvalid's l1: 1385.4\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1385.4\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1536.06\n",
      "[200]\tvalid's l1: 1386.86\n",
      "[300]\tvalid's l1: 1371.52\n",
      "[400]\tvalid's l1: 1364.87\n",
      "[500]\tvalid's l1: 1359.35\n",
      "[600]\tvalid's l1: 1355.4\n",
      "[700]\tvalid's l1: 1351.26\n",
      "[800]\tvalid's l1: 1349.24\n",
      "[900]\tvalid's l1: 1346.94\n",
      "[1000]\tvalid's l1: 1345.31\n",
      "[1100]\tvalid's l1: 1344.26\n",
      "[1200]\tvalid's l1: 1342.86\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1342.86\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1646.28\n",
      "[200]\tvalid's l1: 1512.63\n",
      "[300]\tvalid's l1: 1492.56\n",
      "[400]\tvalid's l1: 1484.3\n",
      "[500]\tvalid's l1: 1479.51\n",
      "[600]\tvalid's l1: 1474.41\n",
      "[700]\tvalid's l1: 1470.55\n",
      "[800]\tvalid's l1: 1467.94\n",
      "[900]\tvalid's l1: 1466.27\n",
      "[1000]\tvalid's l1: 1463.19\n",
      "[1100]\tvalid's l1: 1461.1\n",
      "[1200]\tvalid's l1: 1458.68\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1458.66\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:58:15,439] (INFO): Trial 1 finished with value: -1388.6067361226137 and parameters: {'feature_fraction': 0.5499874579090014, 'num_leaves': 218, 'bagging_fraction': 0.9330880728874675, 'min_sum_hessian_in_leaf': 0.2537815508265665, 'reg_alpha': 0.023585940584142682, 'reg_lambda': 1.5320059381854043e-08}. Best is trial 1 with value: -1388.6067361226137.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1586.46\n",
      "[200]\tvalid's l1: 1441.14\n",
      "[300]\tvalid's l1: 1416.68\n",
      "[400]\tvalid's l1: 1405.74\n",
      "[500]\tvalid's l1: 1398.36\n",
      "[600]\tvalid's l1: 1393.63\n",
      "[700]\tvalid's l1: 1390.33\n",
      "[800]\tvalid's l1: 1388.03\n",
      "[900]\tvalid's l1: 1385.25\n",
      "[1000]\tvalid's l1: 1383.01\n",
      "[1100]\tvalid's l1: 1381.41\n",
      "[1200]\tvalid's l1: 1379.94\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1379.94\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1591.93\n",
      "[200]\tvalid's l1: 1447.24\n",
      "[300]\tvalid's l1: 1420.72\n",
      "[400]\tvalid's l1: 1409.03\n",
      "[500]\tvalid's l1: 1403.22\n",
      "[600]\tvalid's l1: 1399.12\n",
      "[700]\tvalid's l1: 1394.16\n",
      "[800]\tvalid's l1: 1391.27\n",
      "[900]\tvalid's l1: 1388.38\n",
      "[1000]\tvalid's l1: 1386.66\n",
      "[1100]\tvalid's l1: 1384.64\n",
      "[1200]\tvalid's l1: 1382.83\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1382.83\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1575.19\n",
      "[200]\tvalid's l1: 1434.05\n",
      "[300]\tvalid's l1: 1410.47\n",
      "[400]\tvalid's l1: 1402.17\n",
      "[500]\tvalid's l1: 1396.68\n",
      "[600]\tvalid's l1: 1391.09\n",
      "[700]\tvalid's l1: 1387.42\n",
      "[800]\tvalid's l1: 1385.15\n",
      "[900]\tvalid's l1: 1382.78\n",
      "[1000]\tvalid's l1: 1380.5\n",
      "[1100]\tvalid's l1: 1378.85\n",
      "[1200]\tvalid's l1: 1378\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1191]\tvalid's l1: 1377.93\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1557.59\n",
      "[200]\tvalid's l1: 1410.22\n",
      "[300]\tvalid's l1: 1382.4\n",
      "[400]\tvalid's l1: 1373.55\n",
      "[500]\tvalid's l1: 1370.02\n",
      "[600]\tvalid's l1: 1366.21\n",
      "[700]\tvalid's l1: 1363.38\n",
      "[800]\tvalid's l1: 1357.22\n",
      "[900]\tvalid's l1: 1354.74\n",
      "[1000]\tvalid's l1: 1353.21\n",
      "[1100]\tvalid's l1: 1351.71\n",
      "[1200]\tvalid's l1: 1350.59\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1350.59\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1653.32\n",
      "[200]\tvalid's l1: 1504.64\n",
      "[300]\tvalid's l1: 1481\n",
      "[400]\tvalid's l1: 1467.88\n",
      "[500]\tvalid's l1: 1462.26\n",
      "[600]\tvalid's l1: 1458.35\n",
      "[700]\tvalid's l1: 1454.91\n",
      "[800]\tvalid's l1: 1450.38\n",
      "[900]\tvalid's l1: 1447.5\n",
      "[1000]\tvalid's l1: 1443.68\n",
      "[1100]\tvalid's l1: 1441.66\n",
      "[1200]\tvalid's l1: 1440.08\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1190]\tvalid's l1: 1440.01\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 19:59:55,787] (INFO): Trial 2 finished with value: -1386.2580640466954 and parameters: {'feature_fraction': 0.9849549260809971, 'num_leaves': 251, 'bagging_fraction': 0.9692763545078751, 'min_sum_hessian_in_leaf': 0.0010071984838809194, 'reg_alpha': 8.509499823666633, 'reg_lambda': 0.0036085571407386235}. Best is trial 2 with value: -1386.2580640466954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1571.01\n",
      "[200]\tvalid's l1: 1450.12\n",
      "[300]\tvalid's l1: 1428.48\n",
      "[400]\tvalid's l1: 1417.92\n",
      "[500]\tvalid's l1: 1411.28\n",
      "[600]\tvalid's l1: 1406.41\n",
      "[700]\tvalid's l1: 1401.81\n",
      "[800]\tvalid's l1: 1399.14\n",
      "[900]\tvalid's l1: 1395.88\n",
      "[1000]\tvalid's l1: 1394.27\n",
      "[1100]\tvalid's l1: 1392.03\n",
      "[1200]\tvalid's l1: 1390.65\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1184]\tvalid's l1: 1390.59\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1565.41\n",
      "[200]\tvalid's l1: 1433.1\n",
      "[300]\tvalid's l1: 1413.31\n",
      "[400]\tvalid's l1: 1404.46\n",
      "[500]\tvalid's l1: 1398.96\n",
      "[600]\tvalid's l1: 1391.66\n",
      "[700]\tvalid's l1: 1388.22\n",
      "[800]\tvalid's l1: 1385.02\n",
      "[900]\tvalid's l1: 1382.5\n",
      "[1000]\tvalid's l1: 1381.12\n",
      "[1100]\tvalid's l1: 1379.48\n",
      "[1200]\tvalid's l1: 1378.06\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1378\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1557.83\n",
      "[200]\tvalid's l1: 1430.98\n",
      "[300]\tvalid's l1: 1407.4\n",
      "[400]\tvalid's l1: 1397.14\n",
      "[500]\tvalid's l1: 1390.02\n",
      "[600]\tvalid's l1: 1384.72\n",
      "[700]\tvalid's l1: 1380.93\n",
      "[800]\tvalid's l1: 1378.23\n",
      "[900]\tvalid's l1: 1375.48\n",
      "[1000]\tvalid's l1: 1373.44\n",
      "[1100]\tvalid's l1: 1371.23\n",
      "[1200]\tvalid's l1: 1369.38\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1188]\tvalid's l1: 1369.23\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1539.09\n",
      "[200]\tvalid's l1: 1406.59\n",
      "[300]\tvalid's l1: 1380.46\n",
      "[400]\tvalid's l1: 1370.14\n",
      "[500]\tvalid's l1: 1363.74\n",
      "[600]\tvalid's l1: 1358.23\n",
      "[700]\tvalid's l1: 1355.36\n",
      "[800]\tvalid's l1: 1353.32\n",
      "[900]\tvalid's l1: 1349.41\n",
      "[1000]\tvalid's l1: 1347.34\n",
      "[1100]\tvalid's l1: 1347.18\n",
      "[1200]\tvalid's l1: 1345.07\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1345.05\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1656.52\n",
      "[200]\tvalid's l1: 1525.51\n",
      "[300]\tvalid's l1: 1497\n",
      "[400]\tvalid's l1: 1483.91\n",
      "[500]\tvalid's l1: 1476.06\n",
      "[600]\tvalid's l1: 1470.07\n",
      "[700]\tvalid's l1: 1466.44\n",
      "[800]\tvalid's l1: 1462.27\n",
      "[900]\tvalid's l1: 1459.97\n",
      "[1000]\tvalid's l1: 1457.64\n",
      "[1100]\tvalid's l1: 1455.17\n",
      "[1200]\tvalid's l1: 1453.32\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1453.32\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 20:01:22,627] (INFO): Trial 3 finished with value: -1387.2364157114396 and parameters: {'feature_fraction': 0.8058265802441404, 'num_leaves': 251, 'bagging_fraction': 0.5115312125207079, 'min_sum_hessian_in_leaf': 0.12563152773938666, 'reg_alpha': 3.9696182670988566e-05, 'reg_lambda': 2.630213296503227e-08}. Best is trial 2 with value: -1386.2580640466954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1467.15\n",
      "[200]\tvalid's l1: 1420.58\n",
      "[300]\tvalid's l1: 1409.25\n",
      "[400]\tvalid's l1: 1401.27\n",
      "[500]\tvalid's l1: 1395.76\n",
      "[600]\tvalid's l1: 1392.47\n",
      "[700]\tvalid's l1: 1390.14\n",
      "[800]\tvalid's l1: 1386.1\n",
      "[900]\tvalid's l1: 1383.88\n",
      "[1000]\tvalid's l1: 1381.75\n",
      "[1100]\tvalid's l1: 1380.48\n",
      "[1200]\tvalid's l1: 1379.85\n",
      "[1300]\tvalid's l1: 1379.16\n",
      "[1400]\tvalid's l1: 1377.93\n",
      "[1500]\tvalid's l1: 1376.75\n",
      "[1600]\tvalid's l1: 1375.53\n",
      "[1700]\tvalid's l1: 1375.22\n",
      "[1800]\tvalid's l1: 1374.59\n",
      "[1900]\tvalid's l1: 1373.85\n",
      "[2000]\tvalid's l1: 1373.31\n",
      "[2100]\tvalid's l1: 1372.79\n",
      "[2200]\tvalid's l1: 1371.66\n",
      "[2300]\tvalid's l1: 1371.24\n",
      "[2400]\tvalid's l1: 1370.95\n",
      "[2500]\tvalid's l1: 1370.46\n",
      "[2600]\tvalid's l1: 1369.99\n",
      "[2700]\tvalid's l1: 1369.44\n",
      "[2800]\tvalid's l1: 1369.17\n",
      "[2900]\tvalid's l1: 1368.8\n",
      "[3000]\tvalid's l1: 1368.43\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2999]\tvalid's l1: 1368.42\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1473.89\n",
      "[200]\tvalid's l1: 1419.65\n",
      "[300]\tvalid's l1: 1407.36\n",
      "[400]\tvalid's l1: 1400.17\n",
      "[500]\tvalid's l1: 1395.17\n",
      "[600]\tvalid's l1: 1391.33\n",
      "[700]\tvalid's l1: 1390.03\n",
      "[800]\tvalid's l1: 1388.44\n",
      "[900]\tvalid's l1: 1386.14\n",
      "[1000]\tvalid's l1: 1384.5\n",
      "[1100]\tvalid's l1: 1383.85\n",
      "[1200]\tvalid's l1: 1381.99\n",
      "[1300]\tvalid's l1: 1380.72\n",
      "[1400]\tvalid's l1: 1379.81\n",
      "[1500]\tvalid's l1: 1379.16\n",
      "[1600]\tvalid's l1: 1378.58\n",
      "[1700]\tvalid's l1: 1377.16\n",
      "[1800]\tvalid's l1: 1376.74\n",
      "[1900]\tvalid's l1: 1376.12\n",
      "[2000]\tvalid's l1: 1375.87\n",
      "[2100]\tvalid's l1: 1376.07\n",
      "Early stopping, best iteration is:\n",
      "[2038]\tvalid's l1: 1375.77\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1450.11\n",
      "[200]\tvalid's l1: 1407.26\n",
      "[300]\tvalid's l1: 1395.66\n",
      "[400]\tvalid's l1: 1389.95\n",
      "[500]\tvalid's l1: 1386.27\n",
      "[600]\tvalid's l1: 1382.93\n",
      "[700]\tvalid's l1: 1380.84\n",
      "[800]\tvalid's l1: 1377.32\n",
      "[900]\tvalid's l1: 1375.24\n",
      "[1000]\tvalid's l1: 1373.49\n",
      "[1100]\tvalid's l1: 1371.87\n",
      "[1200]\tvalid's l1: 1371.83\n",
      "[1300]\tvalid's l1: 1371.3\n",
      "[1400]\tvalid's l1: 1371.09\n",
      "[1500]\tvalid's l1: 1370.72\n",
      "[1600]\tvalid's l1: 1370.12\n",
      "[1700]\tvalid's l1: 1369.78\n",
      "[1800]\tvalid's l1: 1369.32\n",
      "[1900]\tvalid's l1: 1368.92\n",
      "Early stopping, best iteration is:\n",
      "[1876]\tvalid's l1: 1368.67\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1428.27\n",
      "[200]\tvalid's l1: 1380.62\n",
      "[300]\tvalid's l1: 1372.46\n",
      "[400]\tvalid's l1: 1365.12\n",
      "[500]\tvalid's l1: 1358.46\n",
      "[600]\tvalid's l1: 1355.62\n",
      "[700]\tvalid's l1: 1353.44\n",
      "[800]\tvalid's l1: 1352.37\n",
      "[900]\tvalid's l1: 1350.91\n",
      "[1000]\tvalid's l1: 1349.24\n",
      "[1100]\tvalid's l1: 1348.67\n",
      "[1200]\tvalid's l1: 1347.76\n",
      "[1300]\tvalid's l1: 1346.33\n",
      "[1400]\tvalid's l1: 1345.98\n",
      "[1500]\tvalid's l1: 1345.75\n",
      "[1600]\tvalid's l1: 1344.9\n",
      "[1700]\tvalid's l1: 1344.69\n",
      "[1800]\tvalid's l1: 1343.9\n",
      "[1900]\tvalid's l1: 1343.5\n",
      "[2000]\tvalid's l1: 1343.09\n",
      "[2100]\tvalid's l1: 1342.63\n",
      "[2200]\tvalid's l1: 1342.2\n",
      "[2300]\tvalid's l1: 1341.88\n",
      "[2400]\tvalid's l1: 1341.64\n",
      "[2500]\tvalid's l1: 1341.31\n",
      "[2600]\tvalid's l1: 1341.27\n",
      "Early stopping, best iteration is:\n",
      "[2507]\tvalid's l1: 1341.25\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1542.41\n",
      "[200]\tvalid's l1: 1488.96\n",
      "[300]\tvalid's l1: 1476.62\n",
      "[400]\tvalid's l1: 1468\n",
      "[500]\tvalid's l1: 1463.1\n",
      "[600]\tvalid's l1: 1459.89\n",
      "[700]\tvalid's l1: 1456.1\n",
      "[800]\tvalid's l1: 1454.05\n",
      "[900]\tvalid's l1: 1451.68\n",
      "[1000]\tvalid's l1: 1450.19\n",
      "[1100]\tvalid's l1: 1448.32\n",
      "[1200]\tvalid's l1: 1447.64\n",
      "[1300]\tvalid's l1: 1446.54\n",
      "[1400]\tvalid's l1: 1445.32\n",
      "[1500]\tvalid's l1: 1444.16\n",
      "[1600]\tvalid's l1: 1443.56\n",
      "[1700]\tvalid's l1: 1442.4\n",
      "[1800]\tvalid's l1: 1441.95\n",
      "[1900]\tvalid's l1: 1441.41\n",
      "[2000]\tvalid's l1: 1440.66\n",
      "[2100]\tvalid's l1: 1440.41\n",
      "[2200]\tvalid's l1: 1440.17\n",
      "[2300]\tvalid's l1: 1439.4\n",
      "[2400]\tvalid's l1: 1438.94\n",
      "[2500]\tvalid's l1: 1438.37\n",
      "[2600]\tvalid's l1: 1437.85\n",
      "[2700]\tvalid's l1: 1437.58\n",
      "[2800]\tvalid's l1: 1437.45\n",
      "[2900]\tvalid's l1: 1437.3\n",
      "[3000]\tvalid's l1: 1437.04\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2942]\tvalid's l1: 1436.93\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 397.76975536346436\n",
      "Blending: Optimization starts with equal weights and score -1614.4269380584174\n",
      "Blending, iter 0: score = -1378.206730768913, weights = [0. 0. 1.]\n",
      "Blending, iter 1: score = -1378.206730768913, weights = [0. 0. 1.]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 608.90 seconds.\n",
      "Blending: Optimization starts with equal weights and score -1329.341766634682\n",
      "Blending, iter 0: score = -1317.2824253284261, weights = [0.         0.10958933 0.46807492 0.         0.17216219 0.2501735 ]\n",
      "Blending, iter 1: score = -1317.131169326947, weights = [0.         0.14000559 0.4473465  0.         0.17364438 0.23900355]\n",
      "Blending, iter 2: score = -1317.127844939833, weights = [0.         0.14568813 0.44466817 0.         0.17162853 0.23801517]\n",
      "Blending, iter 3: score = -1317.1278416649602, weights = [0.         0.1456219  0.44492066 0.         0.17155051 0.23790696]\n",
      "Blending, iter 4: score = -1317.1278416649602, weights = [0.         0.14562188 0.44492063 0.         0.1715505  0.23790695]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-17 20:04:58,829] (INFO): oof_pred:\n",
      "array([[ 4133.3574],\n",
      "       [ 6898.6133],\n",
      "       [ 9228.006 ],\n",
      "       ...,\n",
      "       [24408.234 ],\n",
      "       [12443.025 ],\n",
      "       [ 2838.9717]], dtype=float32)\n",
      "Shape = (34994, 1)\n"
     ]
    }
   ],
   "source": [
    "test_pred, auto_ml = make_final_prediction(g1, s2, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57\n",
      "[800]\tvalid's l1: 1441.47\n",
      "[900]\tvalid's l1: 1440.08\n",
      "[1000]\tvalid's l1: 1435.61\n",
      "[1100]\tvalid's l1: 1432.65\n",
      "[1200]\tvalid's l1: 1431.74\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1197]\tvalid's l1: 1431.74\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:46:30,793] (INFO): Trial 18 finished with value: -1431.7361488367237 and parameters: {'feature_fraction': 0.6893430769303299, 'num_leaves': 120, 'bagging_fraction': 0.9577428884953455, 'min_sum_hessian_in_leaf': 2.231825828506587, 'reg_alpha': 0.144676552472792, 'reg_lambda': 3.1991608138192272e-06}. Best is trial 15 with value: -1362.927442336733.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1597.21\n",
      "[200]\tvalid's l1: 1460.2\n",
      "[300]\tvalid's l1: 1444.13\n",
      "[400]\tvalid's l1: 1429.3\n",
      "[500]\tvalid's l1: 1421.99\n",
      "[600]\tvalid's l1: 1416.87\n",
      "[700]\tvalid's l1: 1413.44\n",
      "[800]\tvalid's l1: 1409.48\n",
      "[900]\tvalid's l1: 1406.66\n",
      "[1000]\tvalid's l1: 1403.63\n",
      "[1100]\tvalid's l1: 1402.01\n",
      "[1200]\tvalid's l1: 1399.95\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1399.91\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:46:38,316] (INFO): Trial 19 finished with value: -1399.9066847303047 and parameters: {'feature_fraction': 0.6097067946507622, 'num_leaves': 166, 'bagging_fraction': 0.827258985355741, 'min_sum_hessian_in_leaf': 0.29969891897063444, 'reg_alpha': 4.112488504094535e-05, 'reg_lambda': 5.626152145751747e-08}. Best is trial 15 with value: -1362.927442336733.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1580.55\n",
      "[200]\tvalid's l1: 1445.87\n",
      "[300]\tvalid's l1: 1423.24\n",
      "[400]\tvalid's l1: 1412.17\n",
      "[500]\tvalid's l1: 1403.91\n",
      "[600]\tvalid's l1: 1399.15\n",
      "[700]\tvalid's l1: 1396.33\n",
      "[800]\tvalid's l1: 1393.22\n",
      "[900]\tvalid's l1: 1389.78\n",
      "[1000]\tvalid's l1: 1388.41\n",
      "[1100]\tvalid's l1: 1386.6\n",
      "[1200]\tvalid's l1: 1384.66\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1384.66\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:46:46,980] (INFO): Trial 20 finished with value: -1384.6567567991417 and parameters: {'feature_fraction': 0.5714428838391212, 'num_leaves': 215, 'bagging_fraction': 0.7573678193838399, 'min_sum_hessian_in_leaf': 1.0442954926920647, 'reg_alpha': 0.0005804598156189121, 'reg_lambda': 7.2929052309252e-05}. Best is trial 15 with value: -1362.927442336733.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1536.75\n",
      "[200]\tvalid's l1: 1414.67\n",
      "[300]\tvalid's l1: 1397.02\n",
      "[400]\tvalid's l1: 1390.1\n",
      "[500]\tvalid's l1: 1385.59\n",
      "[600]\tvalid's l1: 1382.75\n",
      "[700]\tvalid's l1: 1380.33\n",
      "[800]\tvalid's l1: 1377.06\n",
      "[900]\tvalid's l1: 1373.81\n",
      "[1000]\tvalid's l1: 1372.49\n",
      "[1100]\tvalid's l1: 1369.78\n",
      "[1200]\tvalid's l1: 1367.69\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1367.69\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:47:00,055] (INFO): Trial 21 finished with value: -1367.689288963027 and parameters: {'feature_fraction': 0.9944393519949526, 'num_leaves': 252, 'bagging_fraction': 0.9086765569725617, 'min_sum_hessian_in_leaf': 9.824074302574049, 'reg_alpha': 0.04781588056986592, 'reg_lambda': 0.031419515987898876}. Best is trial 15 with value: -1362.927442336733.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1541.82\n",
      "[200]\tvalid's l1: 1417.08\n",
      "[300]\tvalid's l1: 1399.78\n",
      "[400]\tvalid's l1: 1390.3\n",
      "[500]\tvalid's l1: 1385.85\n",
      "[600]\tvalid's l1: 1379.25\n",
      "[700]\tvalid's l1: 1375.14\n",
      "[800]\tvalid's l1: 1370.53\n",
      "[900]\tvalid's l1: 1366.52\n",
      "[1000]\tvalid's l1: 1364.57\n",
      "[1100]\tvalid's l1: 1363.17\n",
      "[1200]\tvalid's l1: 1361.65\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1361.65\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:47:12,819] (INFO): Trial 22 finished with value: -1361.6548778866509 and parameters: {'feature_fraction': 0.9399021705668631, 'num_leaves': 255, 'bagging_fraction': 0.8678812626539572, 'min_sum_hessian_in_leaf': 9.221973715643681, 'reg_alpha': 0.28131492089970056, 'reg_lambda': 0.01088059893243174}. Best is trial 22 with value: -1361.6548778866509.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1544.24\n",
      "[200]\tvalid's l1: 1418.17\n",
      "[300]\tvalid's l1: 1398.36\n",
      "[400]\tvalid's l1: 1385.73\n",
      "[500]\tvalid's l1: 1379.67\n",
      "[600]\tvalid's l1: 1375.1\n",
      "[700]\tvalid's l1: 1371.28\n",
      "[800]\tvalid's l1: 1368.9\n",
      "[900]\tvalid's l1: 1365.64\n",
      "[1000]\tvalid's l1: 1362.7\n",
      "[1100]\tvalid's l1: 1361.27\n",
      "[1200]\tvalid's l1: 1359.74\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1359.74\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:47:25,388] (INFO): Trial 23 finished with value: -1359.7427064491385 and parameters: {'feature_fraction': 0.9388975998867859, 'num_leaves': 252, 'bagging_fraction': 0.8487607186753479, 'min_sum_hessian_in_leaf': 3.7846351598458594, 'reg_alpha': 1.3833845362223385, 'reg_lambda': 0.006080931125046489}. Best is trial 23 with value: -1359.7427064491385.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1546.71\n",
      "[200]\tvalid's l1: 1427.85\n",
      "[300]\tvalid's l1: 1408.29\n",
      "[400]\tvalid's l1: 1397.82\n",
      "[500]\tvalid's l1: 1389.67\n",
      "[600]\tvalid's l1: 1384.89\n",
      "[700]\tvalid's l1: 1382.17\n",
      "[800]\tvalid's l1: 1379.98\n",
      "[900]\tvalid's l1: 1377.2\n",
      "[1000]\tvalid's l1: 1374.67\n",
      "[1100]\tvalid's l1: 1372.78\n",
      "[1200]\tvalid's l1: 1371.38\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1371.37\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:47:38,133] (INFO): Trial 24 finished with value: -1371.3748804347347 and parameters: {'feature_fraction': 0.9401639615283344, 'num_leaves': 255, 'bagging_fraction': 0.7710884748015688, 'min_sum_hessian_in_leaf': 4.4307528112368075, 'reg_alpha': 1.2519143860516742, 'reg_lambda': 0.0051994714838299256}. Best is trial 23 with value: -1359.7427064491385.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1543.83\n",
      "[200]\tvalid's l1: 1418.18\n",
      "[300]\tvalid's l1: 1408.65\n",
      "[400]\tvalid's l1: 1404.71\n",
      "[500]\tvalid's l1: 1399.27\n",
      "[600]\tvalid's l1: 1392.69\n",
      "[700]\tvalid's l1: 1387.41\n",
      "[800]\tvalid's l1: 1384.6\n",
      "[900]\tvalid's l1: 1382.37\n",
      "[1000]\tvalid's l1: 1380.35\n",
      "[1100]\tvalid's l1: 1378.81\n",
      "[1200]\tvalid's l1: 1377.63\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1377.63\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:47:49,164] (INFO): Trial 25 finished with value: -1377.6279038973137 and parameters: {'feature_fraction': 0.8694396204015441, 'num_leaves': 223, 'bagging_fraction': 0.9955535815435829, 'min_sum_hessian_in_leaf': 1.9296099768020487, 'reg_alpha': 0.4431076685304143, 'reg_lambda': 0.17062056989118826}. Best is trial 23 with value: -1359.7427064491385.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1554.48\n",
      "[200]\tvalid's l1: 1432.52\n",
      "[300]\tvalid's l1: 1422.8\n",
      "[400]\tvalid's l1: 1416.34\n",
      "[500]\tvalid's l1: 1409.81\n",
      "[600]\tvalid's l1: 1407.03\n",
      "[700]\tvalid's l1: 1405.68\n",
      "[800]\tvalid's l1: 1404.77\n",
      "[900]\tvalid's l1: 1402.13\n",
      "[1000]\tvalid's l1: 1400.18\n",
      "[1100]\tvalid's l1: 1398.18\n",
      "[1200]\tvalid's l1: 1396.8\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1396.8\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:47:58,804] (INFO): Trial 26 finished with value: -1396.7966902204914 and parameters: {'feature_fraction': 0.8735957948070029, 'num_leaves': 186, 'bagging_fraction': 0.9441429384658206, 'min_sum_hessian_in_leaf': 9.642556049940898, 'reg_alpha': 0.005233274283526533, 'reg_lambda': 0.006488184441964868}. Best is trial 23 with value: -1359.7427064491385.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1584.41\n",
      "[200]\tvalid's l1: 1450.4\n",
      "[300]\tvalid's l1: 1423.16\n",
      "[400]\tvalid's l1: 1411.65\n",
      "[500]\tvalid's l1: 1404.3\n",
      "[600]\tvalid's l1: 1398.58\n",
      "[700]\tvalid's l1: 1394.64\n",
      "[800]\tvalid's l1: 1391.49\n",
      "[900]\tvalid's l1: 1387.77\n",
      "[1000]\tvalid's l1: 1385.47\n",
      "[1100]\tvalid's l1: 1383.82\n",
      "[1200]\tvalid's l1: 1382.38\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1382.38\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:48:10,135] (INFO): Trial 27 finished with value: -1382.383631301686 and parameters: {'feature_fraction': 0.9614101251003746, 'num_leaves': 214, 'bagging_fraction': 0.860369983938797, 'min_sum_hessian_in_leaf': 4.3176662800583845, 'reg_alpha': 9.191236210993653, 'reg_lambda': 0.00190958503714263}. Best is trial 23 with value: -1359.7427064491385.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1540.05\n",
      "[200]\tvalid's l1: 1418.05\n",
      "[300]\tvalid's l1: 1400.3\n",
      "[400]\tvalid's l1: 1391.44\n",
      "[500]\tvalid's l1: 1384.64\n",
      "[600]\tvalid's l1: 1379.32\n",
      "[700]\tvalid's l1: 1375.64\n",
      "[800]\tvalid's l1: 1372.06\n",
      "[900]\tvalid's l1: 1369.41\n",
      "[1000]\tvalid's l1: 1366.99\n",
      "[1100]\tvalid's l1: 1365.38\n",
      "[1200]\tvalid's l1: 1364.13\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1364.13\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:48:21,578] (INFO): Trial 28 finished with value: -1364.1267236112049 and parameters: {'feature_fraction': 0.8943504000195563, 'num_leaves': 231, 'bagging_fraction': 0.7960076546745789, 'min_sum_hessian_in_leaf': 2.531600166229428, 'reg_alpha': 0.01881472659326267, 'reg_lambda': 0.0001314646096485106}. Best is trial 23 with value: -1359.7427064491385.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1539.21\n",
      "[200]\tvalid's l1: 1414.31\n",
      "[300]\tvalid's l1: 1396.8\n",
      "[400]\tvalid's l1: 1387.68\n",
      "[500]\tvalid's l1: 1380.51\n",
      "[600]\tvalid's l1: 1376.28\n",
      "[700]\tvalid's l1: 1373.49\n",
      "[800]\tvalid's l1: 1369.99\n",
      "[900]\tvalid's l1: 1364.2\n",
      "[1000]\tvalid's l1: 1361.04\n",
      "[1100]\tvalid's l1: 1359.35\n",
      "[1200]\tvalid's l1: 1358.24\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1358.24\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:48:34,492] (INFO): Trial 29 finished with value: -1358.2428367842706 and parameters: {'feature_fraction': 0.9624523110033287, 'num_leaves': 254, 'bagging_fraction': 0.8560986931605412, 'min_sum_hessian_in_leaf': 1.0276572226679843, 'reg_alpha': 0.4971524187469681, 'reg_lambda': 0.08264557180760178}. Best is trial 29 with value: -1358.2428367842706.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1890.64\n",
      "[200]\tvalid's l1: 1761.03\n",
      "[300]\tvalid's l1: 1731.84\n",
      "[400]\tvalid's l1: 1703.57\n",
      "[500]\tvalid's l1: 1687.76\n",
      "[600]\tvalid's l1: 1677.8\n",
      "[700]\tvalid's l1: 1672.93\n",
      "[800]\tvalid's l1: 1671.03\n",
      "[900]\tvalid's l1: 1663.76\n",
      "[1000]\tvalid's l1: 1659.27\n",
      "[1100]\tvalid's l1: 1656.22\n",
      "[1200]\tvalid's l1: 1653.38\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1196]\tvalid's l1: 1653.38\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:48:37,698] (INFO): Trial 30 finished with value: -1653.376602802077 and parameters: {'feature_fraction': 0.9577100287107765, 'num_leaves': 16, 'bagging_fraction': 0.8663745095631051, 'min_sum_hessian_in_leaf': 1.0713897012985278, 'reg_alpha': 0.5038086389695502, 'reg_lambda': 0.07976413220968338}. Best is trial 29 with value: -1358.2428367842706.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1542.29\n",
      "[200]\tvalid's l1: 1416.06\n",
      "[300]\tvalid's l1: 1401.07\n",
      "[400]\tvalid's l1: 1390.11\n",
      "[500]\tvalid's l1: 1381.97\n",
      "[600]\tvalid's l1: 1377.55\n",
      "[700]\tvalid's l1: 1373.46\n",
      "[800]\tvalid's l1: 1370.61\n",
      "[900]\tvalid's l1: 1367.84\n",
      "[1000]\tvalid's l1: 1365.94\n",
      "[1100]\tvalid's l1: 1364.87\n",
      "[1200]\tvalid's l1: 1363.6\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1363.6\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:48:49,628] (INFO): Trial 31 finished with value: -1363.5957964778772 and parameters: {'feature_fraction': 0.8442562489159376, 'num_leaves': 255, 'bagging_fraction': 0.9282098859211424, 'min_sum_hessian_in_leaf': 6.5706515152113605, 'reg_alpha': 0.4085337049460908, 'reg_lambda': 0.6723347371078289}. Best is trial 29 with value: -1358.2428367842706.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1545.07\n",
      "[200]\tvalid's l1: 1418.49\n",
      "[300]\tvalid's l1: 1400.9\n",
      "[400]\tvalid's l1: 1390.58\n",
      "[500]\tvalid's l1: 1384.69\n",
      "[600]\tvalid's l1: 1377.98\n",
      "[700]\tvalid's l1: 1375.88\n",
      "[800]\tvalid's l1: 1372.8\n",
      "[900]\tvalid's l1: 1369.87\n",
      "[1000]\tvalid's l1: 1367.7\n",
      "[1100]\tvalid's l1: 1366.05\n",
      "[1200]\tvalid's l1: 1365.27\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1199]\tvalid's l1: 1365.25\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-18 03:49:01,419] (INFO): Trial 32 finished with value: -1365.253604271528 and parameters: {'feature_fraction': 0.9089101584274509, 'num_leaves': 241, 'bagging_fraction': 0.8294230174292722, 'min_sum_hessian_in_leaf': 0.7495624141296902, 'reg_alpha': 0.0010550503372463232, 'reg_lambda': 0.002722374446492213}. Best is trial 29 with value: -1358.2428367842706.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1440.4\n",
      "[200]\tvalid's l1: 1407.46\n",
      "[300]\tvalid's l1: 1396.32\n",
      "[400]\tvalid's l1: 1387.97\n",
      "[500]\tvalid's l1: 1384.96\n",
      "[600]\tvalid's l1: 1381.3\n",
      "[700]\tvalid's l1: 1377.9\n",
      "[800]\tvalid's l1: 1376.03\n",
      "[900]\tvalid's l1: 1373.67\n",
      "[1000]\tvalid's l1: 1372.04\n",
      "[1100]\tvalid's l1: 1369.55\n",
      "[1200]\tvalid's l1: 1368.86\n",
      "[1300]\tvalid's l1: 1368.99\n",
      "Early stopping, best iteration is:\n",
      "[1250]\tvalid's l1: 1368.54\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1483.22\n",
      "[200]\tvalid's l1: 1439.94\n",
      "[300]\tvalid's l1: 1428.15\n",
      "[400]\tvalid's l1: 1422.03\n",
      "[500]\tvalid's l1: 1416.34\n",
      "[600]\tvalid's l1: 1413.48\n",
      "[700]\tvalid's l1: 1411.25\n",
      "[800]\tvalid's l1: 1409.17\n",
      "[900]\tvalid's l1: 1407.78\n",
      "[1000]\tvalid's l1: 1406.91\n",
      "[1100]\tvalid's l1: 1404.76\n",
      "[1200]\tvalid's l1: 1403.7\n",
      "[1300]\tvalid's l1: 1402.81\n",
      "[1400]\tvalid's l1: 1402.15\n",
      "[1500]\tvalid's l1: 1401.66\n",
      "[1600]\tvalid's l1: 1400.82\n",
      "[1700]\tvalid's l1: 1400.58\n",
      "[1800]\tvalid's l1: 1400.05\n",
      "[1900]\tvalid's l1: 1399.66\n",
      "[2000]\tvalid's l1: 1399.73\n",
      "[2100]\tvalid's l1: 1398.92\n",
      "[2200]\tvalid's l1: 1398.63\n",
      "[2300]\tvalid's l1: 1398.48\n",
      "[2400]\tvalid's l1: 1397.97\n",
      "[2500]\tvalid's l1: 1397.77\n",
      "[2600]\tvalid's l1: 1397.88\n",
      "Early stopping, best iteration is:\n",
      "[2523]\tvalid's l1: 1397.65\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1479.33\n",
      "[200]\tvalid's l1: 1440.21\n",
      "[300]\tvalid's l1: 1428\n",
      "[400]\tvalid's l1: 1421.69\n",
      "[500]\tvalid's l1: 1415.69\n",
      "[600]\tvalid's l1: 1411.08\n",
      "[700]\tvalid's l1: 1407.98\n",
      "[800]\tvalid's l1: 1406.68\n",
      "[900]\tvalid's l1: 1405.4\n",
      "[1000]\tvalid's l1: 1403.94\n",
      "[1100]\tvalid's l1: 1402.18\n",
      "[1200]\tvalid's l1: 1401.37\n",
      "[1300]\tvalid's l1: 1400.56\n",
      "[1400]\tvalid's l1: 1399.57\n",
      "[1500]\tvalid's l1: 1398.09\n",
      "[1600]\tvalid's l1: 1397.74\n",
      "[1700]\tvalid's l1: 1397.05\n",
      "[1800]\tvalid's l1: 1396.88\n",
      "[1900]\tvalid's l1: 1396.21\n",
      "[2000]\tvalid's l1: 1395.75\n",
      "[2100]\tvalid's l1: 1395.32\n",
      "[2200]\tvalid's l1: 1394.91\n",
      "[2300]\tvalid's l1: 1394.51\n",
      "[2400]\tvalid's l1: 1394.1\n",
      "[2500]\tvalid's l1: 1393.54\n",
      "[2600]\tvalid's l1: 1393.68\n",
      "Early stopping, best iteration is:\n",
      "[2500]\tvalid's l1: 1393.54\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1536.55\n",
      "[200]\tvalid's l1: 1507.07\n",
      "[300]\tvalid's l1: 1497.21\n",
      "[400]\tvalid's l1: 1491.41\n",
      "[500]\tvalid's l1: 1485.02\n",
      "[600]\tvalid's l1: 1480.37\n",
      "[700]\tvalid's l1: 1476.19\n",
      "[800]\tvalid's l1: 1475.21\n",
      "[900]\tvalid's l1: 1474.83\n",
      "[1000]\tvalid's l1: 1473.65\n",
      "[1100]\tvalid's l1: 1473.14\n",
      "[1200]\tvalid's l1: 1471.93\n",
      "[1300]\tvalid's l1: 1470.76\n",
      "[1400]\tvalid's l1: 1470.14\n",
      "[1500]\tvalid's l1: 1469.6\n",
      "[1600]\tvalid's l1: 1468.91\n",
      "[1700]\tvalid's l1: 1468.62\n",
      "[1800]\tvalid's l1: 1468.67\n",
      "[1900]\tvalid's l1: 1467.83\n",
      "[2000]\tvalid's l1: 1467.2\n",
      "[2100]\tvalid's l1: 1466.42\n",
      "[2200]\tvalid's l1: 1466.12\n",
      "[2300]\tvalid's l1: 1466.2\n",
      "Early stopping, best iteration is:\n",
      "[2202]\tvalid's l1: 1466.11\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1406.77\n",
      "[200]\tvalid's l1: 1366.89\n",
      "[300]\tvalid's l1: 1356.5\n",
      "[400]\tvalid's l1: 1350.76\n",
      "[500]\tvalid's l1: 1347.03\n",
      "[600]\tvalid's l1: 1343.8\n",
      "[700]\tvalid's l1: 1339.97\n",
      "[800]\tvalid's l1: 1338.36\n",
      "[900]\tvalid's l1: 1336.43\n",
      "[1000]\tvalid's l1: 1334.77\n",
      "[1100]\tvalid's l1: 1333.27\n",
      "[1200]\tvalid's l1: 1332.18\n",
      "[1300]\tvalid's l1: 1330.13\n",
      "[1400]\tvalid's l1: 1328.42\n",
      "[1500]\tvalid's l1: 1327.57\n",
      "[1600]\tvalid's l1: 1326.78\n",
      "[1700]\tvalid's l1: 1325.8\n",
      "[1800]\tvalid's l1: 1325.41\n",
      "[1900]\tvalid's l1: 1324.86\n",
      "[2000]\tvalid's l1: 1324.29\n",
      "[2100]\tvalid's l1: 1323.87\n",
      "[2200]\tvalid's l1: 1323.41\n",
      "[2300]\tvalid's l1: 1323.11\n",
      "[2400]\tvalid's l1: 1322.73\n",
      "[2500]\tvalid's l1: 1322.67\n",
      "[2600]\tvalid's l1: 1321.91\n",
      "[2700]\tvalid's l1: 1321.54\n",
      "[2800]\tvalid's l1: 1321.05\n",
      "[2900]\tvalid's l1: 1320.37\n",
      "[3000]\tvalid's l1: 1319.69\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2990]\tvalid's l1: 1319.5\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 317.17612409591675\n",
      "Blending: Optimization starts with equal weights and score -1629.8667926692674\n",
      "Blending, iter 0: score = -1389.0679409142804, weights = [0. 0. 1.]\n",
      "Blending, iter 1: score = -1389.0679409142804, weights = [0. 0. 1.]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 496.81 seconds.\n",
      "Blending: Optimization starts with equal weights and score -1326.6058975224387\n",
      "Blending, iter 0: score = -1315.2218864404344, weights = [0.         0.07301982 0.38519228 0.         0.10302441 0.27252734\n",
      " 0.16623622]\n",
      "Blending, iter 1: score = -1315.195807107961, weights = [0.         0.08184683 0.37290058 0.         0.0954669  0.28378022\n",
      " 0.16600554]\n",
      "Blending, iter 2: score = -1315.195218758603, weights = [0.         0.07902145 0.3736348  0.         0.09583303 0.28486857\n",
      " 0.1666422 ]\n",
      "Blending, iter 3: score = -1315.195218758603, weights = [0.         0.07902145 0.3736348  0.         0.09583303 0.28486857\n",
      " 0.1666422 ]\n",
      "No score update. Terminated\n",
      "[2021-05-18 03:51:08,695] (INFO): oof_pred:\n",
      "array([[ 4161.126 ],\n",
      "       [ 6421.159 ],\n",
      "       [ 9586.28  ],\n",
      "       ...,\n",
      "       [25530.557 ],\n",
      "       [12625.917 ],\n",
      "       [ 2834.0552]], dtype=float32)\n",
      "Shape = (34994, 1)\n"
     ]
    }
   ],
   "source": [
    "test_pred, auto_ml = make_final_prediction(g1, s2, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_mae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c183a0d46829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_mae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_mae' is not defined"
     ]
    }
   ],
   "source": [
    "val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6652.256714781655"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[TARGET_NAME].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866      31500.0\n",
       "9729     11268.0\n",
       "11204    11160.0\n",
       "11501    12112.0\n",
       "14305    14748.0\n",
       "          ...   \n",
       "3147     16949.0\n",
       "11123    25500.0\n",
       "19740    21700.0\n",
       "26816    12720.0\n",
       "11550    17000.0\n",
       "Name: final_price, Length: 982, dtype: float64"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[val_data[TARGET_NAME]>10000][TARGET_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.501e+03, 8.050e+02, 1.130e+02, 2.900e+01, 1.300e+01, 2.000e+00,\n",
       "        5.000e+00, 0.000e+00, 4.000e+00, 1.000e+00]),\n",
       " array([ 1020., 10118., 19216., 28314., 37412., 46510., 55608., 64706.,\n",
       "        73804., 82902., 92000.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 381.65 248.518125\" width=\"381.65pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-05-17T02:27:36.134627</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 248.518125 \n",
       "L 381.65 248.518125 \n",
       "L 381.65 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 39.65 224.64 \n",
       "L 374.45 224.64 \n",
       "L 374.45 7.2 \n",
       "L 39.65 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path clip-path=\"url(#pf5995e4544)\" d=\"M 54.868182 224.64 \n",
       "L 85.304545 224.64 \n",
       "L 85.304545 17.554286 \n",
       "L 54.868182 17.554286 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path clip-path=\"url(#pf5995e4544)\" d=\"M 85.304545 224.64 \n",
       "L 115.740909 224.64 \n",
       "L 115.740909 187.602897 \n",
       "L 85.304545 187.602897 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path clip-path=\"url(#pf5995e4544)\" d=\"M 115.740909 224.64 \n",
       "L 146.177273 224.64 \n",
       "L 146.177273 219.441003 \n",
       "L 115.740909 219.441003 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path clip-path=\"url(#pf5995e4544)\" d=\"M 146.177273 224.64 \n",
       "L 176.613636 224.64 \n",
       "L 176.613636 223.305744 \n",
       "L 146.177273 223.305744 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_7\">\n",
       "    <path clip-path=\"url(#pf5995e4544)\" d=\"M 176.613636 224.64 \n",
       "L 207.05 224.64 \n",
       "L 207.05 224.041885 \n",
       "L 176.613636 224.041885 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path clip-path=\"url(#pf5995e4544)\" d=\"M 207.05 224.64 \n",
       "L 237.486364 224.64 \n",
       "L 237.486364 224.547982 \n",
       "L 207.05 224.547982 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path clip-path=\"url(#pf5995e4544)\" d=\"M 237.486364 224.64 \n",
       "L 267.922727 224.64 \n",
       "L 267.922727 224.409956 \n",
       "L 237.486364 224.409956 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path clip-path=\"url(#pf5995e4544)\" d=\"M 267.922727 224.64 \n",
       "L 298.359091 224.64 \n",
       "L 298.359091 224.64 \n",
       "L 267.922727 224.64 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path clip-path=\"url(#pf5995e4544)\" d=\"M 298.359091 224.64 \n",
       "L 328.795455 224.64 \n",
       "L 328.795455 224.455965 \n",
       "L 298.359091 224.455965 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path clip-path=\"url(#pf5995e4544)\" d=\"M 328.795455 224.64 \n",
       "L 359.231818 224.64 \n",
       "L 359.231818 224.593991 \n",
       "L 328.795455 224.593991 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m71da08c910\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.455883\" xlink:href=\"#m71da08c910\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(48.274633 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"118.363695\" xlink:href=\"#m71da08c910\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20000 -->\n",
       "      <g transform=\"translate(102.457445 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"185.271507\" xlink:href=\"#m71da08c910\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40000 -->\n",
       "      <g transform=\"translate(169.365257 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"252.179319\" xlink:href=\"#m71da08c910\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60000 -->\n",
       "      <g transform=\"translate(236.273069 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.087131\" xlink:href=\"#m71da08c910\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80000 -->\n",
       "      <g transform=\"translate(303.180881 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m0c8ce865c0\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0c8ce865c0\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(26.2875 228.439219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0c8ce865c0\" y=\"178.631177\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(7.2 182.430395)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0c8ce865c0\" y=\"132.622353\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 2000 -->\n",
       "      <g transform=\"translate(7.2 136.421572)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0c8ce865c0\" y=\"86.61353\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 3000 -->\n",
       "      <g transform=\"translate(7.2 90.412748)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 40.578125 39.3125 \n",
       "Q 47.65625 37.796875 51.625 33 \n",
       "Q 55.609375 28.21875 55.609375 21.1875 \n",
       "Q 55.609375 10.40625 48.1875 4.484375 \n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \n",
       "Q 12.796875 0.390625 7.625 2.203125 \n",
       "L 7.625 11.71875 \n",
       "Q 11.71875 9.328125 16.59375 8.109375 \n",
       "Q 21.484375 6.890625 26.8125 6.890625 \n",
       "Q 36.078125 6.890625 40.9375 10.546875 \n",
       "Q 45.796875 14.203125 45.796875 21.1875 \n",
       "Q 45.796875 27.640625 41.28125 31.265625 \n",
       "Q 36.765625 34.90625 28.71875 34.90625 \n",
       "L 20.21875 34.90625 \n",
       "L 20.21875 43.015625 \n",
       "L 29.109375 43.015625 \n",
       "Q 36.375 43.015625 40.234375 45.921875 \n",
       "Q 44.09375 48.828125 44.09375 54.296875 \n",
       "Q 44.09375 59.90625 40.109375 62.90625 \n",
       "Q 36.140625 65.921875 28.71875 65.921875 \n",
       "Q 24.65625 65.921875 20.015625 65.03125 \n",
       "Q 15.375 64.15625 9.8125 62.3125 \n",
       "L 9.8125 71.09375 \n",
       "Q 15.4375 72.65625 20.34375 73.4375 \n",
       "Q 25.25 74.21875 29.59375 74.21875 \n",
       "Q 40.828125 74.21875 47.359375 69.109375 \n",
       "Q 53.90625 64.015625 53.90625 55.328125 \n",
       "Q 53.90625 49.265625 50.4375 45.09375 \n",
       "Q 46.96875 40.921875 40.578125 39.3125 \n",
       "z\n",
       "\" id=\"DejaVuSans-51\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-51\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0c8ce865c0\" y=\"40.604706\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 4000 -->\n",
       "      <g transform=\"translate(7.2 44.403925)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path d=\"M 39.65 224.64 \n",
       "L 39.65 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 374.45 224.64 \n",
       "L 374.45 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 39.65 224.64 \n",
       "L 374.45 224.64 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 39.65 7.2 \n",
       "L 374.45 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pf5995e4544\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"39.65\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(val_data[TARGET_NAME].values, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.6676e+04, 5.9600e+02, 6.6000e+01, 1.6000e+01, 7.0000e+00,\n",
       "        0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([  1004. ,  20903.6,  40803.2,  60702.8,  80602.4, 100502. ,\n",
       "        120401.6, 140301.2, 160200.8, 180100.4, 200000. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 391.881818 248.518125\" width=\"391.881818pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-05-17T02:27:41.076353</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 248.518125 \n",
       "L 391.881818 248.518125 \n",
       "L 391.881818 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 46.0125 224.64 \n",
       "L 380.8125 224.64 \n",
       "L 380.8125 7.2 \n",
       "L 46.0125 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path clip-path=\"url(#p1202385893)\" d=\"M 61.230682 224.64 \n",
       "L 91.667045 224.64 \n",
       "L 91.667045 17.554286 \n",
       "L 61.230682 17.554286 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path clip-path=\"url(#p1202385893)\" d=\"M 91.667045 224.64 \n",
       "L 122.103409 224.64 \n",
       "L 122.103409 220.013254 \n",
       "L 91.667045 220.013254 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path clip-path=\"url(#p1202385893)\" d=\"M 122.103409 224.64 \n",
       "L 152.539773 224.64 \n",
       "L 152.539773 224.127642 \n",
       "L 122.103409 224.127642 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path clip-path=\"url(#p1202385893)\" d=\"M 152.539773 224.64 \n",
       "L 182.976136 224.64 \n",
       "L 182.976136 224.515792 \n",
       "L 152.539773 224.515792 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_7\">\n",
       "    <path clip-path=\"url(#p1202385893)\" d=\"M 182.976136 224.64 \n",
       "L 213.4125 224.64 \n",
       "L 213.4125 224.585659 \n",
       "L 182.976136 224.585659 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path clip-path=\"url(#p1202385893)\" d=\"M 213.4125 224.64 \n",
       "L 243.848864 224.64 \n",
       "L 243.848864 224.64 \n",
       "L 213.4125 224.64 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path clip-path=\"url(#p1202385893)\" d=\"M 243.848864 224.64 \n",
       "L 274.285227 224.64 \n",
       "L 274.285227 224.624474 \n",
       "L 243.848864 224.624474 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path clip-path=\"url(#p1202385893)\" d=\"M 274.285227 224.64 \n",
       "L 304.721591 224.64 \n",
       "L 304.721591 224.64 \n",
       "L 274.285227 224.64 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path clip-path=\"url(#p1202385893)\" d=\"M 304.721591 224.64 \n",
       "L 335.157955 224.64 \n",
       "L 335.157955 224.64 \n",
       "L 304.721591 224.64 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path clip-path=\"url(#p1202385893)\" d=\"M 335.157955 224.64 \n",
       "L 365.594318 224.64 \n",
       "L 365.594318 224.632237 \n",
       "L 335.157955 224.632237 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"mb47860cb4f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.695068\" xlink:href=\"#mb47860cb4f\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(56.513818 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"97.932474\" xlink:href=\"#mb47860cb4f\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 25000 -->\n",
       "      <g transform=\"translate(82.026224 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "        <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"136.16988\" xlink:href=\"#mb47860cb4f\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 50000 -->\n",
       "      <g transform=\"translate(120.26363 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"174.407287\" xlink:href=\"#mb47860cb4f\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 75000 -->\n",
       "      <g transform=\"translate(158.501037 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 8.203125 72.90625 \n",
       "L 55.078125 72.90625 \n",
       "L 55.078125 68.703125 \n",
       "L 28.609375 0 \n",
       "L 18.3125 0 \n",
       "L 43.21875 64.59375 \n",
       "L 8.203125 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-55\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"212.644693\" xlink:href=\"#mb47860cb4f\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 100000 -->\n",
       "      <g transform=\"translate(193.557193 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"250.882099\" xlink:href=\"#mb47860cb4f\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 125000 -->\n",
       "      <g transform=\"translate(231.794599 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"289.119506\" xlink:href=\"#mb47860cb4f\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 150000 -->\n",
       "      <g transform=\"translate(270.032006 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"327.356912\" xlink:href=\"#mb47860cb4f\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 175000 -->\n",
       "      <g transform=\"translate(308.269412 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"365.594318\" xlink:href=\"#mb47860cb4f\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 200000 -->\n",
       "      <g transform=\"translate(346.506818 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m8fbe86849e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m8fbe86849e\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(32.65 228.439219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m8fbe86849e\" y=\"185.825014\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 5000 -->\n",
       "      <g transform=\"translate(13.5625 189.624233)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m8fbe86849e\" y=\"147.010028\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 10000 -->\n",
       "      <g transform=\"translate(7.2 150.809246)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m8fbe86849e\" y=\"108.195041\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 15000 -->\n",
       "      <g transform=\"translate(7.2 111.99426)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m8fbe86849e\" y=\"69.380055\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 20000 -->\n",
       "      <g transform=\"translate(7.2 73.179274)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m8fbe86849e\" y=\"30.565069\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 25000 -->\n",
       "      <g transform=\"translate(7.2 34.364288)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path d=\"M 46.0125 224.64 \n",
       "L 46.0125 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 380.8125 224.64 \n",
       "L 380.8125 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 46.0125 224.64 \n",
       "L 380.8125 224.64 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 46.0125 7.2 \n",
       "L 380.8125 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p1202385893\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"46.0125\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_data[TARGET_NAME].values, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = auto_ml.predict(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_pred2 = val_pred.data*6652.25671478165/val_pred.data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_pred = val_pred.data - val_pred.data.mean() + 6652.25671478165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6652.256714781655"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[TARGET_NAME].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6652.2563"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_val_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6652.2573"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_val_pred2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1369.0000341475695"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(val_data[TARGET_NAME], val_pred.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1382.75950337345"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(val_data[TARGET_NAME], new_val_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1389.3212220609983"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(val_data[TARGET_NAME], new_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2407.8258371229854,\n",
       "  \"{'use_algos': ['lgb', 'lgb_tuned', 'linear_l2', 'cb', 'cb_tuned']}\",\n",
       "  \"[('mean', <function mean at 0x7f7d88043048>), ('min', <function nanmin at 0x7f7d780e5840>), ('max', <function nanmax at 0x7f7d780e59d8>), ('median', <function median at 0x7f7d780d5d90>)]\"),\n",
       " (2352.0691284305367,\n",
       "  \"{'use_algos': [['lgb', 'lgb_tuned', 'linear_l2', 'cb', 'cb_tuned'], ['lgb', 'linear_l2']]}\",\n",
       "  \"[('mean', <function mean at 0x7f7d88043048>), ('min', <function nanmin at 0x7f7d780e5840>), ('max', <function nanmax at 0x7f7d780e59d8>), ('median', <function median at 0x7f7d780d5d90>)]\")]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2301.5487437540464,\n",
       "  \"{'use_algos': ['linear_l2', 'lgb', 'lgb_tuned']}\",\n",
       "  \"[('mean', <function mean at 0x7f7d88043048>), ('min', <function nanmin at 0x7f7d780e5840>), ('max', <function nanmax at 0x7f7d780e59d8>)]\"),\n",
       " (2294.0690331959045,\n",
       "  \"{'use_algos': ['linear_l2', 'lgb', 'lgb_tuned']}\",\n",
       "  \"[('mean', <function mean at 0x7f7d88043048>), ('min', <function nanmin at 0x7f7d780e5840>), ('max', <function nanmax at 0x7f7d780e59d8>), ('median', <function median at 0x7f7d780d5d90>)]\"),\n",
       " (2368.170090152536,\n",
       "  \"{'use_algos': 'auto'}\",\n",
       "  \"[('mean', <function mean at 0x7f7d88043048>), ('min', <function nanmin at 0x7f7d780e5840>), ('max', <function nanmax at 0x7f7d780e59d8>)]\"),\n",
       " (2352.0691284305367,\n",
       "  \"{'use_algos': 'auto'}\",\n",
       "  \"[('mean', <function mean at 0x7f7d88043048>), ('min', <function nanmin at 0x7f7d780e5840>), ('max', <function nanmax at 0x7f7d780e59d8>), ('median', <function median at 0x7f7d780d5d90>)]\")]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'use_algos':'auto'}: 2816.1962\n",
    "# {'use_algos': ['linear_l2', 'lgb', 'lgb_tuned']},:2813.14070621923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_fi = automl.get_feature_scores('fast')\n",
    "# fast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (20, 10), grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['FIXED_median_current_mileage_by_vehicle_category', 'FIXED_median_vehicle_year_by_vehicle_manufacturer', 'FIXED_median_current_mileage_by_deal_type', 'FIXED_median_vehicle_year_by_vehicle_model', 'FIXED_median_vehicle_year_by_deal_type', 'FIXED_median_car_leather_interior_by_vehicle_model', 'FIXED_median_vehicle_year_by_doors_cnt', 'FIXED_median_current_mileage_by_wheels', 'FIXED_median_car_leather_interior_by_vehicle_interior_color', 'FIXED_median_current_mileage_by_doors_cnt', 'FIXED_median_vehicle_year_by_vehicle_category', 'FIXED_median_vehicle_year_by_wheels', 'FIXED_median_current_mileage_by_vehicle_manufacturer', 'FIXED_median_current_mileage_by_vehicle_model', 'FIXED_median_vehicle_year_by_vehicle_color', 'FIXED_median_car_leather_interior_by_deal_type', 'FIXED_median_car_leather_interior_by_vehicle_color', 'FIXED_median_current_mileage_by_vehicle_color', 'FIXED_median_car_leather_interior_by_doors_cnt', 'FIXED_median_current_mileage_by_vehicle_gearbox_type', 'FIXED_median_car_leather_interior_by_vehicle_manufacturer', 'FIXED_median_car_leather_interior_by_vehicle_category', 'FIXED_median_vehicle_year_by_vehicle_gearbox_type', 'FIXED_median_car_leather_interior_by_vehicle_gearbox_type', 'FIXED_median_vehicle_year_by_vehicle_interior_color', 'FIXED_median_current_mileage_by_vehicle_interior_color', 'FIXED_median_car_leather_interior_by_wheels'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-3d8374715d9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/log_calls/log_calls.py\u001b[0m in \u001b[0;36m_deco_base_f_wrapper_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m                 \u001b[0;31m# (_xxx variables set, ok to call f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging_state_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled_too\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/lightautoml/addons/utilization/utilization.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, features_names, return_all_predictions, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# TODO: Maybe refactor?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mautoml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mamls_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml_algos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 \u001b[0minner_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                 \u001b[0minner_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/log_calls/log_calls.py\u001b[0m in \u001b[0;36m_deco_base_f_wrapper_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m                 \u001b[0;31m# (_xxx variables set, ok to call f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging_state_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled_too\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/lightautoml/automl/presets/tabular_presets.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, features_names, batch_size, n_jobs, return_all_predictions)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_csv_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNumpyDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/log_calls/log_calls.py\u001b[0m in \u001b[0;36m_deco_base_f_wrapper_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m                 \u001b[0;31m# (_xxx variables set, ok to call f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging_state_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled_too\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/lightautoml/automl/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, features_names, return_all_predictions)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_array_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/log_calls/log_calls.py\u001b[0m in \u001b[0;36m_deco_base_f_wrapper_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m                 \u001b[0;31m# (_xxx variables set, ok to call f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging_state_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled_too\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/lightautoml/reader/base.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, data, features_names, add_array_attrs)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marray_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPandasDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1552\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m         )\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['FIXED_median_current_mileage_by_vehicle_category', 'FIXED_median_vehicle_year_by_vehicle_manufacturer', 'FIXED_median_current_mileage_by_deal_type', 'FIXED_median_vehicle_year_by_vehicle_model', 'FIXED_median_vehicle_year_by_deal_type', 'FIXED_median_car_leather_interior_by_vehicle_model', 'FIXED_median_vehicle_year_by_doors_cnt', 'FIXED_median_current_mileage_by_wheels', 'FIXED_median_car_leather_interior_by_vehicle_interior_color', 'FIXED_median_current_mileage_by_doors_cnt', 'FIXED_median_vehicle_year_by_vehicle_category', 'FIXED_median_vehicle_year_by_wheels', 'FIXED_median_current_mileage_by_vehicle_manufacturer', 'FIXED_median_current_mileage_by_vehicle_model', 'FIXED_median_vehicle_year_by_vehicle_color', 'FIXED_median_car_leather_interior_by_deal_type', 'FIXED_median_car_leather_interior_by_vehicle_color', 'FIXED_median_current_mileage_by_vehicle_color', 'FIXED_median_car_leather_interior_by_doors_cnt', 'FIXED_median_current_mileage_by_vehicle_gearbox_type', 'FIXED_median_car_leather_interior_by_vehicle_manufacturer', 'FIXED_median_car_leather_interior_by_vehicle_category', 'FIXED_median_vehicle_year_by_vehicle_gearbox_type', 'FIXED_median_car_leather_interior_by_vehicle_gearbox_type', 'FIXED_median_vehicle_year_by_vehicle_interior_color', 'FIXED_median_current_mileage_by_vehicle_interior_color', 'FIXED_median_car_leather_interior_by_wheels'] not in index\""
     ]
    }
   ],
   "source": [
    "automl.predict(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['FIXED_median_current_mileage_by_vehicle_category', 'FIXED_median_vehicle_year_by_vehicle_manufacturer', 'FIXED_median_current_mileage_by_deal_type', 'FIXED_median_vehicle_year_by_vehicle_model', 'FIXED_median_vehicle_year_by_deal_type', 'FIXED_median_car_leather_interior_by_vehicle_model', 'FIXED_median_vehicle_year_by_doors_cnt', 'FIXED_median_current_mileage_by_wheels', 'FIXED_median_car_leather_interior_by_vehicle_interior_color', 'FIXED_median_current_mileage_by_doors_cnt', 'FIXED_median_vehicle_year_by_vehicle_category', 'FIXED_median_vehicle_year_by_wheels', 'FIXED_median_current_mileage_by_vehicle_manufacturer', 'FIXED_median_current_mileage_by_vehicle_model', 'FIXED_median_vehicle_year_by_vehicle_color', 'FIXED_median_car_leather_interior_by_deal_type', 'FIXED_median_car_leather_interior_by_vehicle_color', 'FIXED_median_current_mileage_by_vehicle_color', 'FIXED_median_car_leather_interior_by_doors_cnt', 'FIXED_median_current_mileage_by_vehicle_gearbox_type', 'FIXED_median_car_leather_interior_by_vehicle_manufacturer', 'FIXED_median_car_leather_interior_by_vehicle_category', 'FIXED_median_vehicle_year_by_vehicle_gearbox_type', 'FIXED_median_car_leather_interior_by_vehicle_gearbox_type', 'FIXED_median_vehicle_year_by_vehicle_interior_color', 'FIXED_median_current_mileage_by_vehicle_interior_color', 'FIXED_median_car_leather_interior_by_wheels'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-354-9784ba995887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m logging.info('Prediction for test data:\\n{}\\nShape = {}'\n\u001b[1;32m      3\u001b[0m               .format(test_pred2, test_pred2.shape))\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Check scores...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/log_calls/log_calls.py\u001b[0m in \u001b[0;36m_deco_base_f_wrapper_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m                 \u001b[0;31m# (_xxx variables set, ok to call f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging_state_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled_too\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/lightautoml/addons/utilization/utilization.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, features_names, return_all_predictions, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# TODO: Maybe refactor?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mautoml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mamls_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml_algos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 \u001b[0minner_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                 \u001b[0minner_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/log_calls/log_calls.py\u001b[0m in \u001b[0;36m_deco_base_f_wrapper_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m                 \u001b[0;31m# (_xxx variables set, ok to call f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging_state_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled_too\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/lightautoml/automl/presets/tabular_presets.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, features_names, batch_size, n_jobs, return_all_predictions)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_csv_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNumpyDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/log_calls/log_calls.py\u001b[0m in \u001b[0;36m_deco_base_f_wrapper_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m                 \u001b[0;31m# (_xxx variables set, ok to call f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging_state_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled_too\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/lightautoml/automl/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, features_names, return_all_predictions)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_array_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/log_calls/log_calls.py\u001b[0m in \u001b[0;36m_deco_base_f_wrapper_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m                 \u001b[0;31m# (_xxx variables set, ok to call f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging_state_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled_too\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/lightautoml/reader/base.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, data, features_names, add_array_attrs)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marray_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPandasDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1552\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m         )\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coursera/Samsung.CV/venv/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['FIXED_median_current_mileage_by_vehicle_category', 'FIXED_median_vehicle_year_by_vehicle_manufacturer', 'FIXED_median_current_mileage_by_deal_type', 'FIXED_median_vehicle_year_by_vehicle_model', 'FIXED_median_vehicle_year_by_deal_type', 'FIXED_median_car_leather_interior_by_vehicle_model', 'FIXED_median_vehicle_year_by_doors_cnt', 'FIXED_median_current_mileage_by_wheels', 'FIXED_median_car_leather_interior_by_vehicle_interior_color', 'FIXED_median_current_mileage_by_doors_cnt', 'FIXED_median_vehicle_year_by_vehicle_category', 'FIXED_median_vehicle_year_by_wheels', 'FIXED_median_current_mileage_by_vehicle_manufacturer', 'FIXED_median_current_mileage_by_vehicle_model', 'FIXED_median_vehicle_year_by_vehicle_color', 'FIXED_median_car_leather_interior_by_deal_type', 'FIXED_median_car_leather_interior_by_vehicle_color', 'FIXED_median_current_mileage_by_vehicle_color', 'FIXED_median_car_leather_interior_by_doors_cnt', 'FIXED_median_current_mileage_by_vehicle_gearbox_type', 'FIXED_median_car_leather_interior_by_vehicle_manufacturer', 'FIXED_median_car_leather_interior_by_vehicle_category', 'FIXED_median_vehicle_year_by_vehicle_gearbox_type', 'FIXED_median_car_leather_interior_by_vehicle_gearbox_type', 'FIXED_median_vehicle_year_by_vehicle_interior_color', 'FIXED_median_current_mileage_by_vehicle_interior_color', 'FIXED_median_car_leather_interior_by_wheels'] not in index\""
     ]
    }
   ],
   "source": [
    "test_pred2 = automl.predict(test_data)\n",
    "logging.info('Prediction for test data:\\n{}\\nShape = {}'\n",
    "              .format(test_pred2, test_pred2.shape))\n",
    "\n",
    "logging.info('Check scores...')\n",
    "logging.info('OOF score: {}'.format(mean_absolute_error(train_data[TARGET_NAME].values, oof_pred.data[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2830.348 ],\n",
       "       [ 5533.204 ],\n",
       "       [ 2791.081 ],\n",
       "       ...,\n",
       "       [16834.004 ],\n",
       "       [ 5083.2964],\n",
       "       [ 6373.706 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred.data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = test_pred.data[:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tt = test_pred.data*5454.77075/tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2978.3877,  5903.131 ,  3481.8857, ..., 19628.518 ,  5418.863 ,\n",
       "        6909.247 ], dtype=float32)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tt[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2822.7456,  5594.65  ,  3299.9324, ..., 18602.787 ,  5135.6885,\n",
       "        6548.1895], dtype=float32)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_ID</th>\n",
       "      <th>final_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35000</td>\n",
       "      <td>2843.389160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35001</td>\n",
       "      <td>5495.755371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35002</td>\n",
       "      <td>2903.427979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35003</td>\n",
       "      <td>6769.987793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35004</td>\n",
       "      <td>4283.917969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_ID  final_price\n",
       "0   35000  2843.389160\n",
       "1   35001  5495.755371\n",
       "2   35002  2903.427979\n",
       "3   35003  6769.987793\n",
       "4   35004  4283.917969"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[TARGET_NAME] = test_pred.data[:, 0]\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2978.3877,  5903.131 ,  3481.886 , ..., 19628.518 ,  5418.8633,\n",
       "        6909.2476], dtype=float32)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/submission_10_3600.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['final_price'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/submission_all_zeros.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission4 = pd.read_csv('submissions/submission_4.csv')\n",
    "np.mean(submission4['final_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission4['final_price'] = submission4['final_price'] - np.mean(submission4['final_price']) + 5454.77075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission4.to_csv('submissions/submission_4_mae_hack.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all zeros gives 5454.77075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
