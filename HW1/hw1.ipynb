{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd0a799a57f5d5eb66727322ff69a70804dc1f4dea27767e24a1805767e14b149ef",
   "display_name": "Python 3.6.9 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "logging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 4 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 600 # Time in seconds for automl run\n",
    "TARGET_NAME = 'final_price' # Target column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(35000, 118) (10697, 118)\n"
     ]
    }
   ],
   "source": [
    "def create_extra_features(data):\n",
    "    data['NANs_cnt'] = data.isnull().sum(axis = 1) \n",
    "    \n",
    "def create_col_with_min_freq(data, col, min_freq = 10):\n",
    "    # replace rare values (less than min_freq rows) in feature by RARE_VALUE\n",
    "    data[col + '_fixed'] = data[col].astype(str)\n",
    "    data.loc[data[col + '_fixed'].value_counts()[data[col + '_fixed']].values < min_freq, col + '_fixed'] = \"RARE_VALUE\"\n",
    "    data.replace({'nan': np.nan}, inplace = True)\n",
    "\n",
    "def create_gr_feats(data):\n",
    "    # create aggregation feats for numeric features based on categorical ones\n",
    "    for cat_col in ['vehicle_manufacturer', 'vehicle_model', 'vehicle_category',\n",
    "                   'vehicle_gearbox_type', 'doors_cnt', 'wheels', 'vehicle_color', \n",
    "                   'vehicle_interior_color', 'deal_type']:\n",
    "        create_col_with_min_freq(data, cat_col, 15)\n",
    "        for num_col in ['current_mileage', 'vehicle_year', 'car_leather_interior']:\n",
    "            for n, f in [('mean', np.mean), ('min', np.nanmin), ('max', np.nanmax)]:\n",
    "                data['FIXED_' + n + '_' + num_col + '_by_' + cat_col] = data.groupby(cat_col + '_fixed')[num_col].transform(f)\n",
    "                \n",
    "    # create features with counts\n",
    "    for col in ['vehicle_manufacturer', 'vehicle_model', 'vehicle_category',\n",
    "               'current_mileage', 'vehicle_year', 'vehicle_gearbox_type', 'doors_cnt',\n",
    "               'wheels', 'vehicle_color', 'vehicle_interior_color', 'car_vin', 'deal_type']:\n",
    "        data[col + '_cnt'] = data[col].map(data[col].value_counts(dropna = False))\n",
    "    \n",
    "        \n",
    "\n",
    "create_extra_features(train_data)\n",
    "create_extra_features(test_data)\n",
    "\n",
    "all_df = pd.concat([train_data, test_data]).reset_index(drop = True)\n",
    "create_gr_feats(all_df)\n",
    "train_data, test_data = all_df[:len(train_data)], all_df[len(train_data):]\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "sklearn doesn't support in general case mae and will not be used.\n"
     ]
    }
   ],
   "source": [
    "task = Task('reg', loss='mae', metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {'target': TARGET_NAME,\n",
    "         'drop': ['row_ID'] # to drop or not to drop?\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "automl = TabularUtilizedAutoML(task = task, \n",
    "                       timeout = TIMEOUT,\n",
    "                       cpu_limit = N_THREADS,\n",
    "                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "                       reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2377.0867245772906 and parameters: {'feature_fraction': 0.9984425384731308, 'num_leaves': 184, 'bagging_fraction': 0.7175028997728397, 'min_sum_hessian_in_leaf': 5.8348881212509305, 'reg_alpha': 6.934704918794148e-07, 'reg_lambda': 2.523795366811073e-07}. Best is trial 0 with value: -2374.662029323527.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2603.32\n",
      "[200]\tvalid's l1: 2467.15\n",
      "[300]\tvalid's l1: 2445.63\n",
      "[400]\tvalid's l1: 2439.53\n",
      "[500]\tvalid's l1: 2433.31\n",
      "[600]\tvalid's l1: 2428.98\n",
      "[700]\tvalid's l1: 2426.53\n",
      "[800]\tvalid's l1: 2422.52\n",
      "[900]\tvalid's l1: 2419.61\n",
      "[1000]\tvalid's l1: 2416.2\n",
      "[1100]\tvalid's l1: 2413.45\n",
      "[1200]\tvalid's l1: 2411.47\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1196]\tvalid's l1: 2411.41\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:23:30,668] (INFO): Trial 14 finished with value: -2411.410657527719 and parameters: {'feature_fraction': 0.6170707425003907, 'num_leaves': 110, 'bagging_fraction': 0.7117206067342454, 'min_sum_hessian_in_leaf': 9.035869746645261, 'reg_alpha': 7.259776972850799e-05, 'reg_lambda': 1.0124721161588752e-07}. Best is trial 0 with value: -2374.662029323527.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2555.39\n",
      "[200]\tvalid's l1: 2419.98\n",
      "[300]\tvalid's l1: 2399.51\n",
      "[400]\tvalid's l1: 2392.42\n",
      "[500]\tvalid's l1: 2385.11\n",
      "[600]\tvalid's l1: 2382.48\n",
      "[700]\tvalid's l1: 2380.43\n",
      "[800]\tvalid's l1: 2378.59\n",
      "[900]\tvalid's l1: 2378.74\n",
      "[1000]\tvalid's l1: 2377.76\n",
      "[1100]\tvalid's l1: 2376.63\n",
      "[1200]\tvalid's l1: 2375.95\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1194]\tvalid's l1: 2375.78\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:23:42,746] (INFO): Trial 15 finished with value: -2375.7846634601697 and parameters: {'feature_fraction': 0.9916971778758862, 'num_leaves': 199, 'bagging_fraction': 0.7096345095399013, 'min_sum_hessian_in_leaf': 2.34432144597243, 'reg_alpha': 7.19772599765254e-07, 'reg_lambda': 2.3962423476270073e-06}. Best is trial 0 with value: -2374.662029323527.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2550.54\n",
      "[200]\tvalid's l1: 2425.98\n",
      "[300]\tvalid's l1: 2407.34\n",
      "[400]\tvalid's l1: 2399.85\n",
      "[500]\tvalid's l1: 2393.34\n",
      "[600]\tvalid's l1: 2387.55\n",
      "[700]\tvalid's l1: 2384.09\n",
      "[800]\tvalid's l1: 2382.82\n",
      "[900]\tvalid's l1: 2381.83\n",
      "[1000]\tvalid's l1: 2380.69\n",
      "[1100]\tvalid's l1: 2380\n",
      "[1200]\tvalid's l1: 2380.76\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1083]\tvalid's l1: 2379.69\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:23:54,403] (INFO): Trial 16 finished with value: -2379.6874399943367 and parameters: {'feature_fraction': 0.677804515675406, 'num_leaves': 254, 'bagging_fraction': 0.675760829066606, 'min_sum_hessian_in_leaf': 1.8468412040796418, 'reg_alpha': 0.00013586179381094287, 'reg_lambda': 1.1051258640647187e-05}. Best is trial 0 with value: -2374.662029323527.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2563.83\n",
      "[200]\tvalid's l1: 2436.42\n",
      "[300]\tvalid's l1: 2416.81\n",
      "[400]\tvalid's l1: 2408.26\n",
      "[500]\tvalid's l1: 2401.93\n",
      "[600]\tvalid's l1: 2397.71\n",
      "[700]\tvalid's l1: 2394.72\n",
      "[800]\tvalid's l1: 2392.29\n",
      "[900]\tvalid's l1: 2389.9\n",
      "[1000]\tvalid's l1: 2389.26\n",
      "[1100]\tvalid's l1: 2390.1\n",
      "[1200]\tvalid's l1: 2388.72\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1189]\tvalid's l1: 2388.68\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:24:05,660] (INFO): Trial 17 finished with value: -2388.677725399392 and parameters: {'feature_fraction': 0.5811609150247976, 'num_leaves': 253, 'bagging_fraction': 0.7708177398784898, 'min_sum_hessian_in_leaf': 0.19590056523920157, 'reg_alpha': 0.12401782219141134, 'reg_lambda': 1.419090795562104e-06}. Best is trial 0 with value: -2374.662029323527.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2544.13\n",
      "[200]\tvalid's l1: 2409.4\n",
      "[300]\tvalid's l1: 2391.9\n",
      "[400]\tvalid's l1: 2382.47\n",
      "[500]\tvalid's l1: 2379.71\n",
      "[600]\tvalid's l1: 2377.11\n",
      "[700]\tvalid's l1: 2374.69\n",
      "[800]\tvalid's l1: 2369.79\n",
      "[900]\tvalid's l1: 2368.31\n",
      "[1000]\tvalid's l1: 2367.4\n",
      "[1100]\tvalid's l1: 2366.06\n",
      "[1200]\tvalid's l1: 2366.24\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1176]\tvalid's l1: 2365.39\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:24:18,268] (INFO): Trial 18 finished with value: -2365.392681379527 and parameters: {'feature_fraction': 0.9834131838511287, 'num_leaves': 207, 'bagging_fraction': 0.8995749562695302, 'min_sum_hessian_in_leaf': 2.3188996206715693, 'reg_alpha': 9.081436631827625e-07, 'reg_lambda': 0.006861106304921606}. Best is trial 18 with value: -2365.392681379527.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2562.19\n",
      "[200]\tvalid's l1: 2425.27\n",
      "[300]\tvalid's l1: 2415.36\n",
      "[400]\tvalid's l1: 2408.16\n",
      "[500]\tvalid's l1: 2404.53\n",
      "[600]\tvalid's l1: 2401.18\n",
      "[700]\tvalid's l1: 2397.75\n",
      "[800]\tvalid's l1: 2395.1\n",
      "[900]\tvalid's l1: 2393.64\n",
      "[1000]\tvalid's l1: 2393.22\n",
      "[1100]\tvalid's l1: 2391.84\n",
      "[1200]\tvalid's l1: 2389.31\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 2389.31\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:24:27,223] (INFO): Trial 19 finished with value: -2389.307918643883 and parameters: {'feature_fraction': 0.870259207297395, 'num_leaves': 129, 'bagging_fraction': 0.9310319761488337, 'min_sum_hessian_in_leaf': 0.31974160484021613, 'reg_alpha': 1.9016962057812015e-05, 'reg_lambda': 0.02942627753970113}. Best is trial 18 with value: -2365.392681379527.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2536.03\n",
      "[200]\tvalid's l1: 2405.22\n",
      "[300]\tvalid's l1: 2388.77\n",
      "[400]\tvalid's l1: 2381.63\n",
      "[500]\tvalid's l1: 2378.13\n",
      "[600]\tvalid's l1: 2375.16\n",
      "[700]\tvalid's l1: 2372.97\n",
      "[800]\tvalid's l1: 2371.01\n",
      "[900]\tvalid's l1: 2369.39\n",
      "[1000]\tvalid's l1: 2368.16\n",
      "[1100]\tvalid's l1: 2367.49\n",
      "[1200]\tvalid's l1: 2366.04\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 2366.04\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:24:39,156] (INFO): Trial 20 finished with value: -2366.041899222442 and parameters: {'feature_fraction': 0.8299314693102106, 'num_leaves': 215, 'bagging_fraction': 0.878018504806143, 'min_sum_hessian_in_leaf': 0.0391767351895238, 'reg_alpha': 8.972810217620108e-08, 'reg_lambda': 0.007760340738866628}. Best is trial 18 with value: -2365.392681379527.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2541\n",
      "[200]\tvalid's l1: 2416.42\n",
      "[300]\tvalid's l1: 2398.78\n",
      "[400]\tvalid's l1: 2389.37\n",
      "[500]\tvalid's l1: 2383.62\n",
      "[600]\tvalid's l1: 2379.8\n",
      "[700]\tvalid's l1: 2375.21\n",
      "[800]\tvalid's l1: 2373.82\n",
      "[900]\tvalid's l1: 2371.27\n",
      "[1000]\tvalid's l1: 2371.61\n",
      "[1100]\tvalid's l1: 2370.26\n",
      "[1200]\tvalid's l1: 2369.86\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 2369.86\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:24:51,161] (INFO): Trial 21 finished with value: -2369.855661659411 and parameters: {'feature_fraction': 0.8352080075821378, 'num_leaves': 216, 'bagging_fraction': 0.8847096058698981, 'min_sum_hessian_in_leaf': 0.020702651422268317, 'reg_alpha': 1.0300966160489059e-07, 'reg_lambda': 0.0069505893150651685}. Best is trial 18 with value: -2365.392681379527.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2522.88\n",
      "[200]\tvalid's l1: 2399.52\n",
      "[300]\tvalid's l1: 2383.61\n",
      "[400]\tvalid's l1: 2376.7\n",
      "[500]\tvalid's l1: 2372.91\n",
      "[600]\tvalid's l1: 2370.2\n",
      "[700]\tvalid's l1: 2368.16\n",
      "[800]\tvalid's l1: 2365.71\n",
      "[900]\tvalid's l1: 2364.05\n",
      "[1000]\tvalid's l1: 2363.24\n",
      "[1100]\tvalid's l1: 2362.46\n",
      "[1200]\tvalid's l1: 2362.21\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1169]\tvalid's l1: 2362.13\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:25:03,121] (INFO): Trial 22 finished with value: -2362.133025796226 and parameters: {'feature_fraction': 0.8495103268187053, 'num_leaves': 215, 'bagging_fraction': 0.9203520605086303, 'min_sum_hessian_in_leaf': 0.02095669185413472, 'reg_alpha': 5.157315696278627e-08, 'reg_lambda': 0.011163926339373647}. Best is trial 22 with value: -2362.133025796226.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2542.6\n",
      "[200]\tvalid's l1: 2414.3\n",
      "[300]\tvalid's l1: 2406.01\n",
      "[400]\tvalid's l1: 2400.23\n",
      "[500]\tvalid's l1: 2396.98\n",
      "[600]\tvalid's l1: 2394.9\n",
      "[700]\tvalid's l1: 2389.89\n",
      "[800]\tvalid's l1: 2387.17\n",
      "[900]\tvalid's l1: 2384.63\n",
      "[1000]\tvalid's l1: 2384.05\n",
      "[1100]\tvalid's l1: 2383.79\n",
      "[1200]\tvalid's l1: 2383.39\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1177]\tvalid's l1: 2383.23\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:25:15,064] (INFO): Trial 23 finished with value: -2383.229839474814 and parameters: {'feature_fraction': 0.9408444373601136, 'num_leaves': 196, 'bagging_fraction': 0.9956611986395436, 'min_sum_hessian_in_leaf': 0.013256951584367217, 'reg_alpha': 1.6313371733157167e-08, 'reg_lambda': 0.0062193792325474515}. Best is trial 22 with value: -2362.133025796226.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2556.94\n",
      "[200]\tvalid's l1: 2434.01\n",
      "[300]\tvalid's l1: 2422.27\n",
      "[400]\tvalid's l1: 2415.02\n",
      "[500]\tvalid's l1: 2408.43\n",
      "[600]\tvalid's l1: 2401.89\n",
      "[700]\tvalid's l1: 2398.58\n",
      "[800]\tvalid's l1: 2395.49\n",
      "[900]\tvalid's l1: 2394.27\n",
      "[1000]\tvalid's l1: 2392.95\n",
      "[1100]\tvalid's l1: 2392.2\n",
      "[1200]\tvalid's l1: 2389.87\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1195]\tvalid's l1: 2389.86\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:25:24,755] (INFO): Trial 24 finished with value: -2389.8646428340503 and parameters: {'feature_fraction': 0.8781555258596664, 'num_leaves': 148, 'bagging_fraction': 0.9268310322654585, 'min_sum_hessian_in_leaf': 0.06368869531780563, 'reg_alpha': 1.2721875892658856e-06, 'reg_lambda': 0.06543843363179286}. Best is trial 22 with value: -2362.133025796226.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2548.37\n",
      "[200]\tvalid's l1: 2419.4\n",
      "[300]\tvalid's l1: 2402.85\n",
      "[400]\tvalid's l1: 2395.87\n",
      "[500]\tvalid's l1: 2392.97\n",
      "[600]\tvalid's l1: 2391.26\n",
      "[700]\tvalid's l1: 2389.77\n",
      "[800]\tvalid's l1: 2387.48\n",
      "[900]\tvalid's l1: 2386\n",
      "[1000]\tvalid's l1: 2383.16\n",
      "[1100]\tvalid's l1: 2381.42\n",
      "[1200]\tvalid's l1: 2379.38\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1188]\tvalid's l1: 2379.37\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:25:36,848] (INFO): Trial 25 finished with value: -2379.372022262969 and parameters: {'feature_fraction': 0.8349759784283555, 'num_leaves': 218, 'bagging_fraction': 0.9401755944660785, 'min_sum_hessian_in_leaf': 0.012806582667279529, 'reg_alpha': 8.481883034668737e-08, 'reg_lambda': 0.0019955917123189106}. Best is trial 22 with value: -2362.133025796226.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2553.83\n",
      "[200]\tvalid's l1: 2422.96\n",
      "[300]\tvalid's l1: 2406.74\n",
      "[400]\tvalid's l1: 2396.87\n",
      "[500]\tvalid's l1: 2391.31\n",
      "[600]\tvalid's l1: 2386.9\n",
      "[700]\tvalid's l1: 2382.62\n",
      "[800]\tvalid's l1: 2379.73\n",
      "[900]\tvalid's l1: 2377.38\n",
      "[1000]\tvalid's l1: 2377.76\n",
      "[1100]\tvalid's l1: 2375.78\n",
      "[1200]\tvalid's l1: 2374.19\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 2374.17\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:25:47,561] (INFO): Trial 26 finished with value: -2374.1721500053063 and parameters: {'feature_fraction': 0.9214446555440828, 'num_leaves': 167, 'bagging_fraction': 0.8353780069079342, 'min_sum_hessian_in_leaf': 0.03557841894248176, 'reg_alpha': 4.0685141341652564e-08, 'reg_lambda': 0.5236897158608103}. Best is trial 22 with value: -2362.133025796226.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2535.85\n",
      "[200]\tvalid's l1: 2408.34\n",
      "[300]\tvalid's l1: 2399.26\n",
      "[400]\tvalid's l1: 2391.51\n",
      "[500]\tvalid's l1: 2389.48\n",
      "[600]\tvalid's l1: 2387.61\n",
      "[700]\tvalid's l1: 2384.09\n",
      "[800]\tvalid's l1: 2382.9\n",
      "[900]\tvalid's l1: 2379.72\n",
      "[1000]\tvalid's l1: 2376.95\n",
      "[1100]\tvalid's l1: 2375.13\n",
      "[1200]\tvalid's l1: 2374.94\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 2374.94\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:25:59,798] (INFO): Trial 27 finished with value: -2374.9414754790578 and parameters: {'feature_fraction': 0.9782562912109674, 'num_leaves': 196, 'bagging_fraction': 0.9954888318934104, 'min_sum_hessian_in_leaf': 0.11420497755680885, 'reg_alpha': 0.0005987297024112107, 'reg_lambda': 0.00010946143785581877}. Best is trial 22 with value: -2362.133025796226.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2538.53\n",
      "[200]\tvalid's l1: 2413.14\n",
      "[300]\tvalid's l1: 2394.85\n",
      "[400]\tvalid's l1: 2387.71\n",
      "[500]\tvalid's l1: 2382.92\n",
      "[600]\tvalid's l1: 2377.79\n",
      "[700]\tvalid's l1: 2373.87\n",
      "[800]\tvalid's l1: 2371.64\n",
      "[900]\tvalid's l1: 2371.16\n",
      "[1000]\tvalid's l1: 2369.17\n",
      "[1100]\tvalid's l1: 2369.07\n",
      "[1200]\tvalid's l1: 2367.24\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 2367.24\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:26:11,781] (INFO): Trial 28 finished with value: -2367.2361035532613 and parameters: {'feature_fraction': 0.7754541822128138, 'num_leaves': 226, 'bagging_fraction': 0.9140350179550091, 'min_sum_hessian_in_leaf': 0.0025605962416143852, 'reg_alpha': 3.1175236381083285e-05, 'reg_lambda': 0.009201585794800618}. Best is trial 22 with value: -2362.133025796226.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2530.04\n",
      "[200]\tvalid's l1: 2399.87\n",
      "[300]\tvalid's l1: 2381.74\n",
      "[400]\tvalid's l1: 2374.18\n",
      "[500]\tvalid's l1: 2370.24\n",
      "[600]\tvalid's l1: 2367.36\n",
      "[700]\tvalid's l1: 2366.39\n",
      "[800]\tvalid's l1: 2364.25\n",
      "[900]\tvalid's l1: 2363.71\n",
      "[1000]\tvalid's l1: 2362.48\n",
      "[1100]\tvalid's l1: 2361.27\n",
      "[1200]\tvalid's l1: 2360.66\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 2360.66\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:26:25,141] (INFO): Trial 29 finished with value: -2360.66074956366 and parameters: {'feature_fraction': 0.8369989935566657, 'num_leaves': 253, 'bagging_fraction': 0.8587970916073544, 'min_sum_hessian_in_leaf': 0.011242763697888623, 'reg_alpha': 1.4050261969096328e-06, 'reg_lambda': 0.05097919634273484}. Best is trial 29 with value: -2360.66074956366.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 2426.72\n",
      "[200]\tvalid's l1: 2389.29\n",
      "[300]\tvalid's l1: 2379.19\n",
      "[400]\tvalid's l1: 2375.93\n",
      "[500]\tvalid's l1: 2373.82\n",
      "[600]\tvalid's l1: 2379.54\n",
      "Early stopping, best iteration is:\n",
      "[543]\tvalid's l1: 2372.06\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 4189.86\n",
      "[200]\tvalid's l1: 4167.34\n",
      "[300]\tvalid's l1: 4160.06\n",
      "[400]\tvalid's l1: 4157.29\n",
      "[500]\tvalid's l1: 4152.69\n",
      "[600]\tvalid's l1: 4148.52\n",
      "[700]\tvalid's l1: 4147.57\n",
      "[800]\tvalid's l1: 4146.08\n",
      "[900]\tvalid's l1: 4143.98\n",
      "[1000]\tvalid's l1: 4142.98\n",
      "[1100]\tvalid's l1: 4141.63\n",
      "[1200]\tvalid's l1: 4140.76\n",
      "[1300]\tvalid's l1: 4139.26\n",
      "[1400]\tvalid's l1: 4138.91\n",
      "[1500]\tvalid's l1: 4138.25\n",
      "[1600]\tvalid's l1: 4138.25\n",
      "[1700]\tvalid's l1: 4137.8\n",
      "Early stopping, best iteration is:\n",
      "[1665]\tvalid's l1: 4137.69\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1626.44\n",
      "[200]\tvalid's l1: 1587.67\n",
      "[300]\tvalid's l1: 1580.52\n",
      "[400]\tvalid's l1: 1576.41\n",
      "[500]\tvalid's l1: 1573.29\n",
      "[600]\tvalid's l1: 1570.98\n",
      "[700]\tvalid's l1: 1568.04\n",
      "[800]\tvalid's l1: 1566.16\n",
      "[900]\tvalid's l1: 1565.32\n",
      "[1000]\tvalid's l1: 1564.51\n",
      "[1100]\tvalid's l1: 1564.39\n",
      "[1200]\tvalid's l1: 1563.6\n",
      "[1300]\tvalid's l1: 1562.78\n",
      "[1400]\tvalid's l1: 1562.01\n",
      "[1500]\tvalid's l1: 1562.13\n",
      "[1600]\tvalid's l1: 1561.16\n",
      "[1700]\tvalid's l1: 1560.5\n",
      "[1800]\tvalid's l1: 1559.53\n",
      "[1900]\tvalid's l1: 1559.31\n",
      "[2000]\tvalid's l1: 1558.63\n",
      "[2100]\tvalid's l1: 1558.34\n",
      "[2200]\tvalid's l1: 1557.74\n",
      "[2300]\tvalid's l1: 1557.31\n",
      "[2400]\tvalid's l1: 1557.02\n",
      "[2500]\tvalid's l1: 1556.41\n",
      "[2600]\tvalid's l1: 1555.86\n",
      "[2700]\tvalid's l1: 1555.92\n",
      "Early stopping, best iteration is:\n",
      "[2613]\tvalid's l1: 1555.76\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1660.69\n",
      "[200]\tvalid's l1: 1626.72\n",
      "[300]\tvalid's l1: 1614.98\n",
      "[400]\tvalid's l1: 1606.63\n",
      "[500]\tvalid's l1: 1601.65\n",
      "[600]\tvalid's l1: 1599.03\n",
      "[700]\tvalid's l1: 1594.26\n",
      "[800]\tvalid's l1: 1592.67\n",
      "[900]\tvalid's l1: 1590.83\n",
      "[1000]\tvalid's l1: 1589.25\n",
      "[1100]\tvalid's l1: 1587.84\n",
      "[1200]\tvalid's l1: 1587.45\n",
      "[1300]\tvalid's l1: 1586.34\n",
      "[1400]\tvalid's l1: 1585.33\n",
      "[1500]\tvalid's l1: 1584.79\n",
      "[1600]\tvalid's l1: 1583.19\n",
      "[1700]\tvalid's l1: 1582.54\n",
      "[1800]\tvalid's l1: 1582.16\n",
      "[1900]\tvalid's l1: 1581.69\n",
      "[2000]\tvalid's l1: 1581.08\n",
      "[2100]\tvalid's l1: 1580.38\n",
      "[2200]\tvalid's l1: 1579.65\n",
      "[2300]\tvalid's l1: 1579.99\n",
      "Early stopping, best iteration is:\n",
      "[2222]\tvalid's l1: 1579.61\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1576.54\n",
      "[200]\tvalid's l1: 1553.74\n",
      "[300]\tvalid's l1: 1548.4\n",
      "[400]\tvalid's l1: 1543.56\n",
      "[500]\tvalid's l1: 1540.74\n",
      "[600]\tvalid's l1: 1540.79\n",
      "Early stopping, best iteration is:\n",
      "[568]\tvalid's l1: 1539.63\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 155.66707801818848\n",
      "Blending: Optimization starts with equal weights and score -2492.572337889726\n",
      "Blending, iter 0: score = -2236.9500419658625, weights = [0. 0. 1.]\n",
      "Blending, iter 1: score = -2236.9500419658625, weights = [0. 0. 1.]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 444.40 seconds.\n",
      "[2021-05-16 08:27:54,005] (INFO): oof_pred:\n",
      "array([[ 4572.2036],\n",
      "       [ 5726.701 ],\n",
      "       [ 9171.424 ],\n",
      "       ...,\n",
      "       [17206.2   ],\n",
      "       [12248.599 ],\n",
      "       [ 2825.06  ]], dtype=float32)\n",
      "Shape = (35000, 1)\n"
     ]
    }
   ],
   "source": [
    "oof_pred = automl.fit_predict(train_data, roles = roles)\n",
    "logging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_fi = automl.get_feature_scores('fast')\n",
    "# fast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (20, 10), grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-05-16 08:35:28,150] (INFO): Prediction for test data:\n",
      "array([[ 2787.2134],\n",
      "       [ 5875.6006],\n",
      "       [ 2455.132 ],\n",
      "       ...,\n",
      "       [16068.514 ],\n",
      "       [ 5263.795 ],\n",
      "       [ 6188.896 ]], dtype=float32)\n",
      "Shape = (10697, 1)\n",
      "[2021-05-16 08:35:28,151] (INFO): Check scores...\n",
      "[2021-05-16 08:35:28,152] (INFO): OOF score: 2236.9500419658625\n"
     ]
    }
   ],
   "source": [
    "test_pred = automl.predict(test_data)\n",
    "logging.info('Prediction for test data:\\n{}\\nShape = {}'\n",
    "              .format(test_pred, test_pred.shape))\n",
    "\n",
    "logging.info('Check scores...')\n",
    "logging.info('OOF score: {}'.format(mean_absolute_error(train_data[TARGET_NAME].values, oof_pred.data[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   row_ID  final_price\n",
       "0   35000  2787.213379\n",
       "1   35001  5875.600586\n",
       "2   35002  2455.132080\n",
       "3   35003  6830.846680\n",
       "4   35004  4655.221680"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_ID</th>\n      <th>final_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35000</td>\n      <td>2787.213379</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35001</td>\n      <td>5875.600586</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35002</td>\n      <td>2455.132080</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35003</td>\n      <td>6830.846680</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35004</td>\n      <td>4655.221680</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "submission[TARGET_NAME] = test_pred.data[:, 0]\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/submission_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}