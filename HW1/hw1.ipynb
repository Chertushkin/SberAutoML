{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd0a799a57f5d5eb66727322ff69a70804dc1f4dea27767e24a1805767e14b149ef",
   "display_name": "Python 3.6.9 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "logging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 4 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 1800 # Time in seconds for automl run\n",
    "TARGET_NAME = 'final_price' # Target column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(35000, 118) (10697, 118)\n"
     ]
    }
   ],
   "source": [
    "def create_extra_features(data):\n",
    "    data['NANs_cnt'] = data.isnull().sum(axis = 1) \n",
    "    \n",
    "def create_col_with_min_freq(data, col, min_freq = 10):\n",
    "    # replace rare values (less than min_freq rows) in feature by RARE_VALUE\n",
    "    data[col + '_fixed'] = data[col].astype(str)\n",
    "    data.loc[data[col + '_fixed'].value_counts()[data[col + '_fixed']].values < min_freq, col + '_fixed'] = \"RARE_VALUE\"\n",
    "    data.replace({'nan': np.nan}, inplace = True)\n",
    "\n",
    "def create_gr_feats(data):\n",
    "    # create aggregation feats for numeric features based on categorical ones\n",
    "    for cat_col in ['vehicle_manufacturer', 'vehicle_model', 'vehicle_category',\n",
    "                   'vehicle_gearbox_type', 'doors_cnt', 'wheels', 'vehicle_color', \n",
    "                   'vehicle_interior_color', 'deal_type']:\n",
    "        create_col_with_min_freq(data, cat_col, 15)\n",
    "        for num_col in ['current_mileage', 'vehicle_year', 'car_leather_interior']:\n",
    "            for n, f in [('mean', np.mean), ('min', np.nanmin), ('max', np.nanmax)]:\n",
    "                data['FIXED_' + n + '_' + num_col + '_by_' + cat_col] = data.groupby(cat_col + '_fixed')[num_col].transform(f)\n",
    "                \n",
    "    # create features with counts\n",
    "    for col in ['vehicle_manufacturer', 'vehicle_model', 'vehicle_category',\n",
    "               'current_mileage', 'vehicle_year', 'vehicle_gearbox_type', 'doors_cnt',\n",
    "               'wheels', 'vehicle_color', 'vehicle_interior_color', 'car_vin', 'deal_type']:\n",
    "        data[col + '_cnt'] = data[col].map(data[col].value_counts(dropna = False))\n",
    "    \n",
    "        \n",
    "\n",
    "create_extra_features(train_data)\n",
    "create_extra_features(test_data)\n",
    "\n",
    "all_df = pd.concat([train_data, test_data]).reset_index(drop = True)\n",
    "create_gr_feats(all_df)\n",
    "train_data, test_data = all_df[:len(train_data)], all_df[len(train_data):]\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "sklearn doesn't support in general case mae and will not be used.\n"
     ]
    }
   ],
   "source": [
    "task = Task('reg', loss='mae', metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {'target': TARGET_NAME,\n",
    "         'drop': ['row_ID'] # to drop or not to drop?\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "automl = TabularUtilizedAutoML(task = task, \n",
    "                       timeout = TIMEOUT,\n",
    "                       cpu_limit = N_THREADS,\n",
    "                       general_params = {'use_algos': [['linear_l1', 'linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "                       reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dicting completed\n",
      "[2021-05-16 09:30:09,670] (INFO): Trial 22 finished with value: -1404.810675295734 and parameters: {'feature_fraction': 0.8590191983118689, 'num_leaves': 191, 'bagging_fraction': 0.6779134591332523, 'min_sum_hessian_in_leaf': 0.05018957571767482, 'reg_alpha': 7.409195089916165e-05, 'reg_lambda': 2.151383707426102e-07}. Best is trial 19 with value: -1381.8345686140551.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1555.27\n",
      "[200]\tvalid's l1: 1439.94\n",
      "[300]\tvalid's l1: 1424.89\n",
      "[400]\tvalid's l1: 1414.79\n",
      "[500]\tvalid's l1: 1414.06\n",
      "[600]\tvalid's l1: 1411.39\n",
      "[700]\tvalid's l1: 1409.07\n",
      "[800]\tvalid's l1: 1408.28\n",
      "[900]\tvalid's l1: 1405.05\n",
      "[1000]\tvalid's l1: 1403.09\n",
      "[1100]\tvalid's l1: 1401.27\n",
      "[1200]\tvalid's l1: 1399.68\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 1399.68\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:30:18,680] (INFO): Trial 23 finished with value: -1399.6801745089804 and parameters: {'feature_fraction': 0.8338121506969163, 'num_leaves': 195, 'bagging_fraction': 0.6546440167546027, 'min_sum_hessian_in_leaf': 2.8755917848831793, 'reg_alpha': 4.958919121974418e-05, 'reg_lambda': 4.150240881092655e-06}. Best is trial 19 with value: -1381.8345686140551.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1544.85\n",
      "[200]\tvalid's l1: 1437.11\n",
      "[300]\tvalid's l1: 1422.08\n",
      "[400]\tvalid's l1: 1419.78\n",
      "[500]\tvalid's l1: 1414.39\n",
      "[600]\tvalid's l1: 1411.87\n",
      "[700]\tvalid's l1: 1409.8\n",
      "[800]\tvalid's l1: 1408.55\n",
      "[900]\tvalid's l1: 1407.61\n",
      "[1000]\tvalid's l1: 1406.19\n",
      "[1100]\tvalid's l1: 1405.31\n",
      "[1200]\tvalid's l1: 1403.89\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tvalid's l1: 1403.87\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:30:29,024] (INFO): Trial 24 finished with value: -1403.8719073308537 and parameters: {'feature_fraction': 0.9527272700526042, 'num_leaves': 218, 'bagging_fraction': 0.637719458426995, 'min_sum_hessian_in_leaf': 2.9264337561605545, 'reg_alpha': 3.4887863246459897e-05, 'reg_lambda': 4.930436601729722e-06}. Best is trial 19 with value: -1381.8345686140551.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1593.22\n",
      "[200]\tvalid's l1: 1476.09\n",
      "[300]\tvalid's l1: 1463.78\n",
      "[400]\tvalid's l1: 1454.49\n",
      "[500]\tvalid's l1: 1449.84\n",
      "[600]\tvalid's l1: 1448.56\n",
      "[700]\tvalid's l1: 1445.85\n",
      "[800]\tvalid's l1: 1441.19\n",
      "[900]\tvalid's l1: 1441.43\n",
      "[1000]\tvalid's l1: 1439.71\n",
      "[1100]\tvalid's l1: 1438.66\n",
      "[1200]\tvalid's l1: 1439.64\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1118]\tvalid's l1: 1438.2\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:30:37,345] (INFO): Trial 25 finished with value: -1438.1986980370793 and parameters: {'feature_fraction': 0.8231457696809779, 'num_leaves': 179, 'bagging_fraction': 0.5766001857150824, 'min_sum_hessian_in_leaf': 2.192736149090832, 'reg_alpha': 0.0006345092312590102, 'reg_lambda': 8.506500372806113e-05}. Best is trial 19 with value: -1381.8345686140551.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1532.37\n",
      "[200]\tvalid's l1: 1422.75\n",
      "[300]\tvalid's l1: 1408.85\n",
      "[400]\tvalid's l1: 1402.04\n",
      "[500]\tvalid's l1: 1403.17\n",
      "[600]\tvalid's l1: 1400.93\n",
      "[700]\tvalid's l1: 1397.02\n",
      "[800]\tvalid's l1: 1394.51\n",
      "[900]\tvalid's l1: 1392.56\n",
      "[1000]\tvalid's l1: 1393.23\n",
      "[1100]\tvalid's l1: 1392.28\n",
      "[1200]\tvalid's l1: 1390.84\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1172]\tvalid's l1: 1390.57\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:30:47,627] (INFO): Trial 26 finished with value: -1390.5691203468868 and parameters: {'feature_fraction': 0.9762953022551051, 'num_leaves': 211, 'bagging_fraction': 0.6761501054154123, 'min_sum_hessian_in_leaf': 9.405660698532111, 'reg_alpha': 1.8733623498616223e-05, 'reg_lambda': 1.7089442484095235e-06}. Best is trial 19 with value: -1381.8345686140551.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1537.32\n",
      "[200]\tvalid's l1: 1432.23\n",
      "[300]\tvalid's l1: 1423.09\n",
      "[400]\tvalid's l1: 1416.8\n",
      "[500]\tvalid's l1: 1411.93\n",
      "[600]\tvalid's l1: 1407.3\n",
      "[700]\tvalid's l1: 1405.29\n",
      "[800]\tvalid's l1: 1403.05\n",
      "[900]\tvalid's l1: 1407.05\n",
      "[1000]\tvalid's l1: 1406.11\n",
      "Early stopping, best iteration is:\n",
      "[846]\tvalid's l1: 1401.89\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:30:56,207] (INFO): Trial 27 finished with value: -1401.8920409863676 and parameters: {'feature_fraction': 0.9038670128582061, 'num_leaves': 212, 'bagging_fraction': 0.6412567987776845, 'min_sum_hessian_in_leaf': 6.5023971433750285, 'reg_alpha': 6.538347982682588e-07, 'reg_lambda': 6.990074553705404e-05}. Best is trial 19 with value: -1381.8345686140551.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1557.63\n",
      "[200]\tvalid's l1: 1444.1\n",
      "[300]\tvalid's l1: 1427.24\n",
      "[400]\tvalid's l1: 1422.32\n",
      "[500]\tvalid's l1: 1417.72\n",
      "[600]\tvalid's l1: 1414.44\n",
      "[700]\tvalid's l1: 1410.55\n",
      "[800]\tvalid's l1: 1409.86\n",
      "[900]\tvalid's l1: 1406.79\n",
      "[1000]\tvalid's l1: 1404.85\n",
      "[1100]\tvalid's l1: 1405.61\n",
      "[1200]\tvalid's l1: 1409.07\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1042]\tvalid's l1: 1403.6\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:31:04,843] (INFO): Trial 28 finished with value: -1403.5993546310876 and parameters: {'feature_fraction': 0.8371709573874391, 'num_leaves': 183, 'bagging_fraction': 0.6844895321239367, 'min_sum_hessian_in_leaf': 9.66264741614862, 'reg_alpha': 2.333698591684149e-05, 'reg_lambda': 0.006812321463706572}. Best is trial 19 with value: -1381.8345686140551.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1595.9\n",
      "[200]\tvalid's l1: 1491.86\n",
      "[300]\tvalid's l1: 1479.79\n",
      "[400]\tvalid's l1: 1478.41\n",
      "[500]\tvalid's l1: 1472.75\n",
      "[600]\tvalid's l1: 1467\n",
      "[700]\tvalid's l1: 1464.04\n",
      "[800]\tvalid's l1: 1461.41\n",
      "[900]\tvalid's l1: 1460.68\n",
      "[1000]\tvalid's l1: 1460.44\n",
      "[1100]\tvalid's l1: 1460.64\n",
      "[1200]\tvalid's l1: 1460.2\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1144]\tvalid's l1: 1459.17\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:31:14,905] (INFO): Trial 29 finished with value: -1459.1728402144738 and parameters: {'feature_fraction': 0.7781783249912221, 'num_leaves': 251, 'bagging_fraction': 0.5001887061840973, 'min_sum_hessian_in_leaf': 1.0276572226679843, 'reg_alpha': 4.5519985574633476e-07, 'reg_lambda': 2.993678707378971e-08}. Best is trial 19 with value: -1381.8345686140551.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1520.69\n",
      "[200]\tvalid's l1: 1422.58\n",
      "[300]\tvalid's l1: 1409.69\n",
      "[400]\tvalid's l1: 1401.66\n",
      "[500]\tvalid's l1: 1401.04\n",
      "[600]\tvalid's l1: 1400.94\n",
      "Early stopping, best iteration is:\n",
      "[466]\tvalid's l1: 1398.61\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:31:21,369] (INFO): Trial 30 finished with value: -1398.6081626023195 and parameters: {'feature_fraction': 0.9509244503639147, 'num_leaves': 247, 'bagging_fraction': 0.8323162283900277, 'min_sum_hessian_in_leaf': 3.109191097979893, 'reg_alpha': 1.6139897339376774e-06, 'reg_lambda': 4.6528556860008353e-07}. Best is trial 19 with value: -1381.8345686140551.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1512.69\n",
      "[200]\tvalid's l1: 1411.6\n",
      "[300]\tvalid's l1: 1409.75\n",
      "[400]\tvalid's l1: 1402.95\n",
      "[500]\tvalid's l1: 1397.49\n",
      "[600]\tvalid's l1: 1395.88\n",
      "[700]\tvalid's l1: 1393.29\n",
      "[800]\tvalid's l1: 1392.12\n",
      "[900]\tvalid's l1: 1392.23\n",
      "[1000]\tvalid's l1: 1392.73\n",
      "Early stopping, best iteration is:\n",
      "[850]\tvalid's l1: 1391.3\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:31:31,635] (INFO): Trial 31 finished with value: -1391.295165298151 and parameters: {'feature_fraction': 0.9471703069638526, 'num_leaves': 255, 'bagging_fraction': 0.8700411239306658, 'min_sum_hessian_in_leaf': 3.4792244964606143, 'reg_alpha': 1.5074945246440798e-06, 'reg_lambda': 4.3475989876019466e-07}. Best is trial 19 with value: -1381.8345686140551.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1509.47\n",
      "[200]\tvalid's l1: 1414.13\n",
      "[300]\tvalid's l1: 1408.45\n",
      "[400]\tvalid's l1: 1406.58\n",
      "[500]\tvalid's l1: 1402.06\n",
      "[600]\tvalid's l1: 1400.89\n",
      "[700]\tvalid's l1: 1402.27\n",
      "[800]\tvalid's l1: 1399.55\n",
      "[900]\tvalid's l1: 1400.27\n",
      "[1000]\tvalid's l1: 1400.6\n",
      "Early stopping, best iteration is:\n",
      "[838]\tvalid's l1: 1399.12\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:31:41,584] (INFO): Trial 32 finished with value: -1399.1164066691995 and parameters: {'feature_fraction': 0.9512143527352407, 'num_leaves': 253, 'bagging_fraction': 0.8774328280714112, 'min_sum_hessian_in_leaf': 9.824304738210127, 'reg_alpha': 1.279401279131113e-06, 'reg_lambda': 5.039832610620387e-07}. Best is trial 19 with value: -1381.8345686140551.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1507.57\n",
      "[200]\tvalid's l1: 1408.67\n",
      "[300]\tvalid's l1: 1396.2\n",
      "[400]\tvalid's l1: 1398.18\n",
      "[500]\tvalid's l1: 1393.59\n",
      "[600]\tvalid's l1: 1391.97\n",
      "[700]\tvalid's l1: 1392.23\n",
      "[800]\tvalid's l1: 1390.67\n",
      "[900]\tvalid's l1: 1389.64\n",
      "[1000]\tvalid's l1: 1389.44\n",
      "[1100]\tvalid's l1: 1390.16\n",
      "[1200]\tvalid's l1: 1388.49\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1185]\tvalid's l1: 1388.05\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:31:52,403] (INFO): Trial 33 finished with value: -1388.0536160961326 and parameters: {'feature_fraction': 0.9679988485300954, 'num_leaves': 228, 'bagging_fraction': 0.8254597737261581, 'min_sum_hessian_in_leaf': 4.270994038651388, 'reg_alpha': 1.207770357942506e-07, 'reg_lambda': 1.1333202094797351e-07}. Best is trial 19 with value: -1381.8345686140551.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1502.34\n",
      "[200]\tvalid's l1: 1405.3\n",
      "[300]\tvalid's l1: 1393.57\n",
      "[400]\tvalid's l1: 1386.64\n",
      "[500]\tvalid's l1: 1383.12\n",
      "[600]\tvalid's l1: 1383.14\n",
      "[700]\tvalid's l1: 1379.84\n",
      "[800]\tvalid's l1: 1379.03\n",
      "[900]\tvalid's l1: 1378.99\n",
      "[1000]\tvalid's l1: 1378.37\n",
      "[1100]\tvalid's l1: 1376.57\n",
      "[1200]\tvalid's l1: 1380.46\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1118]\tvalid's l1: 1376.27\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:32:03,351] (INFO): Trial 34 finished with value: -1376.2712262412394 and parameters: {'feature_fraction': 0.998778080763761, 'num_leaves': 226, 'bagging_fraction': 0.9257297958400481, 'min_sum_hessian_in_leaf': 0.31126385872304074, 'reg_alpha': 1.1560778496610547e-07, 'reg_lambda': 7.227471962667603e-08}. Best is trial 34 with value: -1376.2712262412394.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1510.37\n",
      "[200]\tvalid's l1: 1412.42\n",
      "[300]\tvalid's l1: 1405.12\n",
      "[400]\tvalid's l1: 1400.47\n",
      "[500]\tvalid's l1: 1399.09\n",
      "[600]\tvalid's l1: 1398.74\n",
      "[700]\tvalid's l1: 1401.01\n",
      "Early stopping, best iteration is:\n",
      "[566]\tvalid's l1: 1396.89\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:32:10,378] (INFO): Trial 35 finished with value: -1396.891905591471 and parameters: {'feature_fraction': 0.9924088081849424, 'num_leaves': 227, 'bagging_fraction': 0.9072186801413051, 'min_sum_hessian_in_leaf': 0.4649776495463676, 'reg_alpha': 9.596472818930442e-08, 'reg_lambda': 1.024701561447786e-08}. Best is trial 34 with value: -1376.2712262412394.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1531.8\n",
      "[200]\tvalid's l1: 1424.33\n",
      "[300]\tvalid's l1: 1423.81\n",
      "[400]\tvalid's l1: 1416.27\n",
      "[500]\tvalid's l1: 1410.04\n",
      "[600]\tvalid's l1: 1407.24\n",
      "[700]\tvalid's l1: 1406.2\n",
      "[800]\tvalid's l1: 1403.59\n",
      "[900]\tvalid's l1: 1401.08\n",
      "[1000]\tvalid's l1: 1399.78\n",
      "[1100]\tvalid's l1: 1401.13\n",
      "[1200]\tvalid's l1: 1402.76\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1030]\tvalid's l1: 1399.57\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:32:20,317] (INFO): Trial 36 finished with value: -1399.5665537414382 and parameters: {'feature_fraction': 0.9192761762483124, 'num_leaves': 209, 'bagging_fraction': 0.7851828202950316, 'min_sum_hessian_in_leaf': 1.3506628739408588, 'reg_alpha': 1.0466755612781832e-08, 'reg_lambda': 7.232820456402349e-08}. Best is trial 34 with value: -1376.2712262412394.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 1523.59\n",
      "[200]\tvalid's l1: 1413.73\n",
      "[300]\tvalid's l1: 1402.91\n",
      "[400]\tvalid's l1: 1403.63\n",
      "[500]\tvalid's l1: 1397.39\n",
      "[600]\tvalid's l1: 1393.12\n",
      "[700]\tvalid's l1: 1389.45\n",
      "[800]\tvalid's l1: 1386.74\n",
      "[900]\tvalid's l1: 1384.53\n",
      "[1000]\tvalid's l1: 1383.5\n",
      "[1100]\tvalid's l1: 1385.5\n",
      "[1200]\tvalid's l1: 1384.52\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1034]\tvalid's l1: 1383.17\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 09:32:30,949] (INFO): Trial 37 finished with value: -1383.173216882791 and parameters: {'feature_fraction': 0.9731585593153106, 'num_leaves': 222, 'bagging_fraction': 0.8178752729943226, 'min_sum_hessian_in_leaf': 0.25431218502123304, 'reg_alpha': 3.748412746036123e-08, 'reg_lambda': 2.9039193942841107e-08}. Best is trial 34 with value: -1376.2712262412394.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1411.68\n",
      "[200]\tvalid's l1: 1391.23\n",
      "[300]\tvalid's l1: 1387.51\n",
      "[400]\tvalid's l1: 1384.9\n",
      "[500]\tvalid's l1: 1380.47\n",
      "[600]\tvalid's l1: 1376.63\n",
      "[700]\tvalid's l1: 1374.19\n",
      "[800]\tvalid's l1: 1373.6\n",
      "[900]\tvalid's l1: 1372.95\n",
      "[1000]\tvalid's l1: 1371.53\n",
      "[1100]\tvalid's l1: 1372.46\n",
      "Early stopping, best iteration is:\n",
      "[1025]\tvalid's l1: 1370.81\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1503.48\n",
      "[200]\tvalid's l1: 1467.46\n",
      "[300]\tvalid's l1: 1455.19\n",
      "[400]\tvalid's l1: 1449.54\n",
      "[500]\tvalid's l1: 1444.84\n",
      "[600]\tvalid's l1: 1441.75\n",
      "[700]\tvalid's l1: 1437.97\n",
      "[800]\tvalid's l1: 1435.17\n",
      "[900]\tvalid's l1: 1433.22\n",
      "[1000]\tvalid's l1: 1430.26\n",
      "[1100]\tvalid's l1: 1427.42\n",
      "[1200]\tvalid's l1: 1425.17\n",
      "[1300]\tvalid's l1: 1424.12\n",
      "[1400]\tvalid's l1: 1423.56\n",
      "[1500]\tvalid's l1: 1423.19\n",
      "[1600]\tvalid's l1: 1421.78\n",
      "[1700]\tvalid's l1: 1420.76\n",
      "[1800]\tvalid's l1: 1418.79\n",
      "[1900]\tvalid's l1: 1417.27\n",
      "[2000]\tvalid's l1: 1416.46\n",
      "[2100]\tvalid's l1: 1415.63\n",
      "[2200]\tvalid's l1: 1415.13\n",
      "[2300]\tvalid's l1: 1414.57\n",
      "[2400]\tvalid's l1: 1414.08\n",
      "[2500]\tvalid's l1: 1413.76\n",
      "[2600]\tvalid's l1: 1413.61\n",
      "[2700]\tvalid's l1: 1413.23\n",
      "[2800]\tvalid's l1: 1412.81\n",
      "[2900]\tvalid's l1: 1412.1\n",
      "[3000]\tvalid's l1: 1412.03\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2993]\tvalid's l1: 1412\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1485.42\n",
      "[200]\tvalid's l1: 1457.82\n",
      "[300]\tvalid's l1: 1450.34\n",
      "[400]\tvalid's l1: 1445.26\n",
      "[500]\tvalid's l1: 1441.21\n",
      "[600]\tvalid's l1: 1436.07\n",
      "[700]\tvalid's l1: 1431.64\n",
      "[800]\tvalid's l1: 1429.85\n",
      "[900]\tvalid's l1: 1428.01\n",
      "[1000]\tvalid's l1: 1425.89\n",
      "[1100]\tvalid's l1: 1424.09\n",
      "[1200]\tvalid's l1: 1422.76\n",
      "[1300]\tvalid's l1: 1421.73\n",
      "[1400]\tvalid's l1: 1420.36\n",
      "[1500]\tvalid's l1: 1420.01\n",
      "[1600]\tvalid's l1: 1419.31\n",
      "[1700]\tvalid's l1: 1417.99\n",
      "[1800]\tvalid's l1: 1417.73\n",
      "[1900]\tvalid's l1: 1416.01\n",
      "[2000]\tvalid's l1: 1415.23\n",
      "[2100]\tvalid's l1: 1414.54\n",
      "[2200]\tvalid's l1: 1413.91\n",
      "[2300]\tvalid's l1: 1413.05\n",
      "[2400]\tvalid's l1: 1412.17\n",
      "[2500]\tvalid's l1: 1411.67\n",
      "[2600]\tvalid's l1: 1411.14\n",
      "[2700]\tvalid's l1: 1410.64\n",
      "[2800]\tvalid's l1: 1410.57\n",
      "[2900]\tvalid's l1: 1410.02\n",
      "[3000]\tvalid's l1: 1409.71\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid's l1: 1409.71\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 4093.38\n",
      "[200]\tvalid's l1: 4055.46\n",
      "[300]\tvalid's l1: 4046.89\n",
      "[400]\tvalid's l1: 4038.3\n",
      "[500]\tvalid's l1: 4032.61\n",
      "[600]\tvalid's l1: 4027.83\n",
      "[700]\tvalid's l1: 4024.24\n",
      "[800]\tvalid's l1: 4018.51\n",
      "[900]\tvalid's l1: 4015.1\n",
      "[1000]\tvalid's l1: 4013.12\n",
      "[1100]\tvalid's l1: 4010.62\n",
      "[1200]\tvalid's l1: 4009.18\n",
      "[1300]\tvalid's l1: 4008.3\n",
      "[1400]\tvalid's l1: 4007.64\n",
      "[1500]\tvalid's l1: 4006.84\n",
      "[1600]\tvalid's l1: 4005.09\n",
      "[1700]\tvalid's l1: 4003.86\n",
      "[1800]\tvalid's l1: 4003.07\n",
      "Early stopping, best iteration is:\n",
      "[1738]\tvalid's l1: 4003\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 2713.01\n",
      "[200]\tvalid's l1: 2678.29\n",
      "[300]\tvalid's l1: 2666.91\n",
      "[400]\tvalid's l1: 2659.82\n",
      "[500]\tvalid's l1: 2655.24\n",
      "[600]\tvalid's l1: 2650.74\n",
      "[700]\tvalid's l1: 2647.52\n",
      "[800]\tvalid's l1: 2646.8\n",
      "[900]\tvalid's l1: 2645.33\n",
      "[1000]\tvalid's l1: 2644.42\n",
      "[1100]\tvalid's l1: 2643.8\n",
      "[1200]\tvalid's l1: 2642.94\n",
      "[1300]\tvalid's l1: 2642.16\n",
      "[1400]\tvalid's l1: 2640.84\n",
      "[1500]\tvalid's l1: 2639.93\n",
      "[1600]\tvalid's l1: 2639.66\n",
      "[1700]\tvalid's l1: 2638.57\n",
      "[1800]\tvalid's l1: 2638.19\n",
      "[1900]\tvalid's l1: 2637.41\n",
      "[2000]\tvalid's l1: 2636.86\n",
      "[2100]\tvalid's l1: 2636.7\n",
      "Early stopping, best iteration is:\n",
      "[2057]\tvalid's l1: 2636.11\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 445.94302463531494\n",
      "Blending: Optimization starts with equal weights and score -2453.222439889908\n",
      "Blending, iter 0: score = -2166.3242679110986, weights = [0. 0. 1.]\n",
      "Blending, iter 1: score = -2166.3242679110986, weights = [0. 0. 1.]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 443.68 seconds.\n",
      "Blending: Optimization starts with equal weights and score -2148.29409559521\n",
      "Blending, iter 0: score = -2135.642088098199, weights = [0.24194539 0.14622891 0.6118257 ]\n",
      "Blending, iter 1: score = -2135.419053593159, weights = [0.21500126 0.1769553  0.60804343]\n",
      "Blending, iter 2: score = -2135.414619893987, weights = [0.21134046 0.18161865 0.60704094]\n",
      "Blending, iter 3: score = -2135.414425690869, weights = [0.21034685 0.18230177 0.6073514 ]\n",
      "Blending, iter 4: score = -2135.414430476938, weights = [0.21034685 0.18230177 0.6073514 ]\n",
      "No score update. Terminated\n",
      "[2021-05-16 09:34:09,412] (INFO): oof_pred:\n",
      "array([[ 4654.957 ],\n",
      "       [ 6393.5947],\n",
      "       [ 9008.29  ],\n",
      "       ...,\n",
      "       [17446.021 ],\n",
      "       [12166.459 ],\n",
      "       [ 2886.6516]], dtype=float32)\n",
      "Shape = (35000, 1)\n"
     ]
    }
   ],
   "source": [
    "oof_pred = automl.fit_predict(train_data, roles = roles)\n",
    "logging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_fi = automl.get_feature_scores('fast')\n",
    "# fast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (20, 10), grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-05-16 09:44:27,073] (INFO): Prediction for test data:\n",
      "array([[ 2823.994 ],\n",
      "       [ 5678.8164],\n",
      "       [ 2958.0315],\n",
      "       ...,\n",
      "       [15944.335 ],\n",
      "       [ 5074.4644],\n",
      "       [ 6318.3574]], dtype=float32)\n",
      "Shape = (10697, 1)\n",
      "[2021-05-16 09:44:27,074] (INFO): Check scores...\n",
      "[2021-05-16 09:44:27,075] (INFO): OOF score: 2135.414425690869\n"
     ]
    }
   ],
   "source": [
    "test_pred = automl.predict(test_data)\n",
    "logging.info('Prediction for test data:\\n{}\\nShape = {}'\n",
    "              .format(test_pred, test_pred.shape))\n",
    "\n",
    "logging.info('Check scores...')\n",
    "logging.info('OOF score: {}'.format(mean_absolute_error(train_data[TARGET_NAME].values, oof_pred.data[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   row_ID  final_price\n",
       "0   35000  2823.993896\n",
       "1   35001  5678.816406\n",
       "2   35002  2958.031494\n",
       "3   35003  5301.563477\n",
       "4   35004  4528.917480"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_ID</th>\n      <th>final_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35000</td>\n      <td>2823.993896</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35001</td>\n      <td>5678.816406</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35002</td>\n      <td>2958.031494</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35003</td>\n      <td>5301.563477</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35004</td>\n      <td>4528.917480</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "submission[TARGET_NAME] = test_pred.data[:, 0]\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/submission_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['final_price'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/submission_all_zeros.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}