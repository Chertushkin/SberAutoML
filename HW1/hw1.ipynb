{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd0a799a57f5d5eb66727322ff69a70804dc1f4dea27767e24a1805767e14b149ef",
   "display_name": "Python 3.6.9 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "logging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 4 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 600 # Time in seconds for automl run\n",
    "TARGET_NAME = 'final_price' # Target column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_expert_feats(data):\n",
    "    pass\n",
    "\n",
    "create_expert_feats(train_data)\n",
    "create_expert_feats(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "sklearn doesn't support in general case mae and will not be used.\n"
     ]
    }
   ],
   "source": [
    "task = Task('reg', loss='mae', metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {'target': TARGET_NAME,\n",
    "         'drop': ['row_ID'] # to drop or not to drop?\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "automl = TabularUtilizedAutoML(task = task, \n",
    "                       timeout = TIMEOUT,\n",
    "                       cpu_limit = N_THREADS,\n",
    "                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "                       reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "93\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:07:13,473] (INFO): Trial 48 finished with value: -2542.934914622358 and parameters: {'feature_fraction': 0.8820454371237115, 'num_leaves': 192, 'bagging_fraction': 0.9666452831759725, 'min_sum_hessian_in_leaf': 0.3418221858888605, 'reg_alpha': 1.6222917424639427e-08, 'reg_lambda': 5.648198888942089e-08}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2675.84\n",
      "[200]\tvalid's l1: 2573.51\n",
      "[300]\tvalid's l1: 2560.46\n",
      "[400]\tvalid's l1: 2555.74\n",
      "[500]\tvalid's l1: 2552.71\n",
      "[600]\tvalid's l1: 2550.72\n",
      "[700]\tvalid's l1: 2550.39\n",
      "[800]\tvalid's l1: 2549.3\n",
      "[900]\tvalid's l1: 2549.38\n",
      "[1000]\tvalid's l1: 2548.95\n",
      "Early stopping, best iteration is:\n",
      "[853]\tvalid's l1: 2548.7\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:07:18,073] (INFO): Trial 49 finished with value: -2548.69837892573 and parameters: {'feature_fraction': 0.7808581578112884, 'num_leaves': 174, 'bagging_fraction': 0.8185929729784561, 'min_sum_hessian_in_leaf': 0.09764337470763089, 'reg_alpha': 0.4961533459315179, 'reg_lambda': 5.762398295658511e-07}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2650.48\n",
      "[200]\tvalid's l1: 2556.32\n",
      "[300]\tvalid's l1: 2549.24\n",
      "[400]\tvalid's l1: 2543.32\n",
      "[500]\tvalid's l1: 2540.54\n",
      "[600]\tvalid's l1: 2539.7\n",
      "[700]\tvalid's l1: 2539.76\n",
      "[800]\tvalid's l1: 2543.13\n",
      "Early stopping, best iteration is:\n",
      "[661]\tvalid's l1: 2539.16\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:07:23,456] (INFO): Trial 50 finished with value: -2539.1558792690594 and parameters: {'feature_fraction': 0.9592424408611435, 'num_leaves': 244, 'bagging_fraction': 0.9344757607833929, 'min_sum_hessian_in_leaf': 0.01125369119391855, 'reg_alpha': 1.660132719022507, 'reg_lambda': 2.49233999699096}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2643.22\n",
      "[200]\tvalid's l1: 2554.05\n",
      "[300]\tvalid's l1: 2548.33\n",
      "[400]\tvalid's l1: 2545.42\n",
      "[500]\tvalid's l1: 2541.55\n",
      "[600]\tvalid's l1: 2539.56\n",
      "[700]\tvalid's l1: 2538.59\n",
      "[800]\tvalid's l1: 2538.12\n",
      "[900]\tvalid's l1: 2538.21\n",
      "Early stopping, best iteration is:\n",
      "[738]\tvalid's l1: 2537.84\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:07:28,440] (INFO): Trial 51 finished with value: -2537.8433210163826 and parameters: {'feature_fraction': 0.9977868129947001, 'num_leaves': 204, 'bagging_fraction': 0.9206412100199923, 'min_sum_hessian_in_leaf': 0.5695649870879764, 'reg_alpha': 1.991431541087979e-06, 'reg_lambda': 1.642674240855962e-07}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2640.92\n",
      "[200]\tvalid's l1: 2559.26\n",
      "[300]\tvalid's l1: 2551.5\n",
      "[400]\tvalid's l1: 2548.46\n",
      "[500]\tvalid's l1: 2545.11\n",
      "[600]\tvalid's l1: 2545.02\n",
      "[700]\tvalid's l1: 2543.97\n",
      "[800]\tvalid's l1: 2544.58\n",
      "Early stopping, best iteration is:\n",
      "[675]\tvalid's l1: 2543.72\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:07:33,175] (INFO): Trial 52 finished with value: -2543.7242111770765 and parameters: {'feature_fraction': 0.9804362550780292, 'num_leaves': 214, 'bagging_fraction': 0.8867653772391078, 'min_sum_hessian_in_leaf': 0.03627010093960276, 'reg_alpha': 7.894268583767078e-05, 'reg_lambda': 2.639072877469096e-07}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2700.02\n",
      "[200]\tvalid's l1: 2592.98\n",
      "[300]\tvalid's l1: 2585.59\n",
      "[400]\tvalid's l1: 2579.26\n",
      "[500]\tvalid's l1: 2575.79\n",
      "[600]\tvalid's l1: 2575.29\n",
      "[700]\tvalid's l1: 2574.82\n",
      "[800]\tvalid's l1: 2572.16\n",
      "[900]\tvalid's l1: 2572.22\n",
      "[1000]\tvalid's l1: 2571.96\n",
      "[1100]\tvalid's l1: 2571.69\n",
      "[1200]\tvalid's l1: 2571.46\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1035]\tvalid's l1: 2571.27\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:07:38,289] (INFO): Trial 53 finished with value: -2571.268730392456 and parameters: {'feature_fraction': 0.6896122889015552, 'num_leaves': 181, 'bagging_fraction': 0.9758372721606844, 'min_sum_hessian_in_leaf': 1.0337140931694058, 'reg_alpha': 3.472001822427428e-06, 'reg_lambda': 1.2182253171433785e-08}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2829.99\n",
      "[200]\tvalid's l1: 2719.9\n",
      "[300]\tvalid's l1: 2695.17\n",
      "[400]\tvalid's l1: 2679.72\n",
      "[500]\tvalid's l1: 2672.59\n",
      "[600]\tvalid's l1: 2666.45\n",
      "[700]\tvalid's l1: 2665.44\n",
      "[800]\tvalid's l1: 2663.75\n",
      "[900]\tvalid's l1: 2663.3\n",
      "[1000]\tvalid's l1: 2660.16\n",
      "[1100]\tvalid's l1: 2656.28\n",
      "[1200]\tvalid's l1: 2654.22\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1188]\tvalid's l1: 2654.21\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:07:39,843] (INFO): Trial 54 finished with value: -2654.20743492019 and parameters: {'feature_fraction': 0.9445007922554944, 'num_leaves': 18, 'bagging_fraction': 0.6716047005793397, 'min_sum_hessian_in_leaf': 6.526856527801629, 'reg_alpha': 4.174339677371774e-07, 'reg_lambda': 1.830357997061604e-06}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2644.94\n",
      "[200]\tvalid's l1: 2552.05\n",
      "[300]\tvalid's l1: 2542.98\n",
      "[400]\tvalid's l1: 2538.81\n",
      "[500]\tvalid's l1: 2537.18\n",
      "[600]\tvalid's l1: 2537.44\n",
      "[700]\tvalid's l1: 2537.56\n",
      "Early stopping, best iteration is:\n",
      "[526]\tvalid's l1: 2536.66\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:07:43,649] (INFO): Trial 55 finished with value: -2536.6613887388194 and parameters: {'feature_fraction': 0.9082739924639783, 'num_leaves': 210, 'bagging_fraction': 0.936727150468569, 'min_sum_hessian_in_leaf': 1.142758787668932, 'reg_alpha': 1.760629596733936e-05, 'reg_lambda': 9.066590191904084e-08}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2650.85\n",
      "[200]\tvalid's l1: 2560.38\n",
      "[300]\tvalid's l1: 2551.24\n",
      "[400]\tvalid's l1: 2547.89\n",
      "[500]\tvalid's l1: 2548.65\n",
      "[600]\tvalid's l1: 2549.85\n",
      "Early stopping, best iteration is:\n",
      "[400]\tvalid's l1: 2547.89\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:07:47,043] (INFO): Trial 56 finished with value: -2547.8941227283476 and parameters: {'feature_fraction': 0.8550466163719722, 'num_leaves': 235, 'bagging_fraction': 0.9470890596439066, 'min_sum_hessian_in_leaf': 0.12321902923714083, 'reg_alpha': 0.0002692814857512568, 'reg_lambda': 5.4245754207655225e-08}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2648.42\n",
      "[200]\tvalid's l1: 2566.02\n",
      "[300]\tvalid's l1: 2559.1\n",
      "[400]\tvalid's l1: 2556\n",
      "[500]\tvalid's l1: 2554.71\n",
      "[600]\tvalid's l1: 2554.15\n",
      "[700]\tvalid's l1: 2551.99\n",
      "[800]\tvalid's l1: 2552.56\n",
      "[900]\tvalid's l1: 2551.3\n",
      "[1000]\tvalid's l1: 2550.6\n",
      "[1100]\tvalid's l1: 2551.56\n",
      "[1200]\tvalid's l1: 2550.3\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1190]\tvalid's l1: 2550.23\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:07:53,146] (INFO): Trial 57 finished with value: -2550.232014558856 and parameters: {'feature_fraction': 0.909775245301404, 'num_leaves': 198, 'bagging_fraction': 0.901540993187417, 'min_sum_hessian_in_leaf': 0.005753413611692942, 'reg_alpha': 0.0022997429321893648, 'reg_lambda': 9.259999492004396e-08}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2654.42\n",
      "[200]\tvalid's l1: 2567.65\n",
      "[300]\tvalid's l1: 2560.39\n",
      "[400]\tvalid's l1: 2559.71\n",
      "[500]\tvalid's l1: 2557.95\n",
      "[600]\tvalid's l1: 2558.2\n",
      "[700]\tvalid's l1: 2554.87\n",
      "[800]\tvalid's l1: 2553.45\n",
      "[900]\tvalid's l1: 2552.47\n",
      "[1000]\tvalid's l1: 2552.53\n",
      "[1100]\tvalid's l1: 2552.01\n",
      "[1200]\tvalid's l1: 2550.91\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1190]\tvalid's l1: 2550.88\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:07:58,472] (INFO): Trial 58 finished with value: -2550.880404829809 and parameters: {'feature_fraction': 0.8762566152111958, 'num_leaves': 167, 'bagging_fraction': 0.9865838029627825, 'min_sum_hessian_in_leaf': 2.0291514053257105, 'reg_alpha': 1.4668619951965524e-07, 'reg_lambda': 8.973247920425287e-06}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2650.93\n",
      "[200]\tvalid's l1: 2552.82\n",
      "[300]\tvalid's l1: 2545.12\n",
      "[400]\tvalid's l1: 2542.4\n",
      "[500]\tvalid's l1: 2538.97\n",
      "[600]\tvalid's l1: 2535.43\n",
      "[700]\tvalid's l1: 2534.27\n",
      "[800]\tvalid's l1: 2533.58\n",
      "[900]\tvalid's l1: 2535.17\n",
      "[1000]\tvalid's l1: 2535.61\n",
      "Early stopping, best iteration is:\n",
      "[815]\tvalid's l1: 2533.4\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:08:02,809] (INFO): Trial 59 finished with value: -2533.397361034717 and parameters: {'feature_fraction': 0.9180455362967187, 'num_leaves': 157, 'bagging_fraction': 0.8602160550796896, 'min_sum_hessian_in_leaf': 0.09178339780526276, 'reg_alpha': 1.9146102375581742e-05, 'reg_lambda': 0.0178842859808344}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2658.42\n",
      "[200]\tvalid's l1: 2573.33\n",
      "[300]\tvalid's l1: 2568.03\n",
      "[400]\tvalid's l1: 2563.44\n",
      "[500]\tvalid's l1: 2560.1\n",
      "[600]\tvalid's l1: 2555.96\n",
      "[700]\tvalid's l1: 2554.97\n",
      "[800]\tvalid's l1: 2553.71\n",
      "[900]\tvalid's l1: 2552.87\n",
      "[1000]\tvalid's l1: 2553.16\n",
      "[1100]\tvalid's l1: 2552.95\n",
      "[1200]\tvalid's l1: 2552.17\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tvalid's l1: 2552.17\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:08:07,941] (INFO): Trial 60 finished with value: -2552.172166832511 and parameters: {'feature_fraction': 0.9213537889762602, 'num_leaves': 152, 'bagging_fraction': 0.8724131675059946, 'min_sum_hessian_in_leaf': 0.18771690212454453, 'reg_alpha': 1.7784700715656422e-05, 'reg_lambda': 0.09365638965355466}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2671.36\n",
      "[200]\tvalid's l1: 2571.02\n",
      "[300]\tvalid's l1: 2562.52\n",
      "[400]\tvalid's l1: 2557.81\n",
      "[500]\tvalid's l1: 2552.58\n",
      "[600]\tvalid's l1: 2551.46\n",
      "[700]\tvalid's l1: 2551.55\n",
      "Early stopping, best iteration is:\n",
      "[578]\tvalid's l1: 2550.49\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:08:11,246] (INFO): Trial 61 finished with value: -2550.494217108539 and parameters: {'feature_fraction': 0.8978949946950214, 'num_leaves': 157, 'bagging_fraction': 0.8479876792748842, 'min_sum_hessian_in_leaf': 0.08979470238998849, 'reg_alpha': 6.722198143325324e-05, 'reg_lambda': 0.012919892344918108}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2637.03\n",
      "[200]\tvalid's l1: 2548.6\n",
      "[300]\tvalid's l1: 2541.17\n",
      "[400]\tvalid's l1: 2541.32\n",
      "[500]\tvalid's l1: 2538.38\n",
      "[600]\tvalid's l1: 2536.23\n",
      "[700]\tvalid's l1: 2535.28\n",
      "[800]\tvalid's l1: 2535.71\n",
      "[900]\tvalid's l1: 2535.49\n",
      "[1000]\tvalid's l1: 2533.37\n",
      "[1100]\tvalid's l1: 2533.7\n",
      "[1200]\tvalid's l1: 2534.78\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1010]\tvalid's l1: 2533.29\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:08:17,086] (INFO): Trial 62 finished with value: -2533.2928724678522 and parameters: {'feature_fraction': 0.9515986578056826, 'num_leaves': 189, 'bagging_fraction': 0.9101694116203025, 'min_sum_hessian_in_leaf': 0.02618088964852634, 'reg_alpha': 0.0001564880615132849, 'reg_lambda': 0.00223700160055592}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2640.22\n",
      "[200]\tvalid's l1: 2555.96\n",
      "[300]\tvalid's l1: 2548.24\n",
      "[400]\tvalid's l1: 2541.56\n",
      "[500]\tvalid's l1: 2539.17\n",
      "[600]\tvalid's l1: 2538.8\n",
      "[700]\tvalid's l1: 2536.99\n",
      "[800]\tvalid's l1: 2536.77\n",
      "[900]\tvalid's l1: 2537.18\n",
      "[1000]\tvalid's l1: 2537.57\n",
      "Early stopping, best iteration is:\n",
      "[848]\tvalid's l1: 2535.91\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:08:22,247] (INFO): Trial 63 finished with value: -2535.9142202306475 and parameters: {'feature_fraction': 0.9548569811795605, 'num_leaves': 187, 'bagging_fraction': 0.9094907923426601, 'min_sum_hessian_in_leaf': 0.025133489972573805, 'reg_alpha': 0.0009819731690637852, 'reg_lambda': 0.0018352496820001152}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2670.18\n",
      "[200]\tvalid's l1: 2568.07\n",
      "[300]\tvalid's l1: 2560.99\n",
      "[400]\tvalid's l1: 2557.76\n",
      "[500]\tvalid's l1: 2554.71\n",
      "[600]\tvalid's l1: 2555.85\n",
      "[700]\tvalid's l1: 2554.55\n",
      "Early stopping, best iteration is:\n",
      "[539]\tvalid's l1: 2552.53\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:08:25,822] (INFO): Trial 64 finished with value: -2552.530201545102 and parameters: {'feature_fraction': 0.9529443063517415, 'num_leaves': 187, 'bagging_fraction': 0.5038579682127703, 'min_sum_hessian_in_leaf': 0.04196619091981183, 'reg_alpha': 0.00042871996614401666, 'reg_lambda': 0.0021484951621660365}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2667.85\n",
      "[200]\tvalid's l1: 2570.19\n",
      "[300]\tvalid's l1: 2563.54\n",
      "[400]\tvalid's l1: 2560.46\n",
      "[500]\tvalid's l1: 2559.67\n",
      "[600]\tvalid's l1: 2557.54\n",
      "[700]\tvalid's l1: 2558.21\n",
      "[800]\tvalid's l1: 2555.83\n",
      "[900]\tvalid's l1: 2554.25\n",
      "[1000]\tvalid's l1: 2554.17\n",
      "[1100]\tvalid's l1: 2552.89\n",
      "[1200]\tvalid's l1: 2552.77\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1165]\tvalid's l1: 2552.72\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:08:30,502] (INFO): Trial 65 finished with value: -2552.7176444035345 and parameters: {'feature_fraction': 0.9889976435885783, 'num_leaves': 129, 'bagging_fraction': 0.8620842628512803, 'min_sum_hessian_in_leaf': 0.02339242952298681, 'reg_alpha': 0.0010179620070123769, 'reg_lambda': 0.00038855145274281145}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2657.93\n",
      "[200]\tvalid's l1: 2564.29\n",
      "[300]\tvalid's l1: 2556.42\n",
      "[400]\tvalid's l1: 2548.26\n",
      "[500]\tvalid's l1: 2544.9\n",
      "[600]\tvalid's l1: 2543.43\n",
      "[700]\tvalid's l1: 2542.23\n",
      "[800]\tvalid's l1: 2539.54\n",
      "[900]\tvalid's l1: 2538.58\n",
      "[1000]\tvalid's l1: 2537.74\n",
      "[1100]\tvalid's l1: 2537.19\n",
      "[1200]\tvalid's l1: 2537.23\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1134]\tvalid's l1: 2536.96\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 08:08:35,381] (INFO): Trial 66 finished with value: -2536.9605326015608 and parameters: {'feature_fraction': 0.951083604864264, 'num_leaves': 142, 'bagging_fraction': 0.9084165627673934, 'min_sum_hessian_in_leaf': 0.05206219309010862, 'reg_alpha': 0.00017623674717651404, 'reg_lambda': 0.05823701321649293}. Best is trial 32 with value: -2528.967141716753.\n",
      "Start fitting Lvl_0_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 2567.39\n",
      "[200]\tvalid's l1: 2555.4\n",
      "[300]\tvalid's l1: 2552.68\n",
      "[400]\tvalid's l1: 2550.11\n",
      "Early stopping, best iteration is:\n",
      "[375]\tvalid's l1: 2549.03\n",
      "\n",
      "===== Start working with fold 1 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 4310.41\n",
      "[200]\tvalid's l1: 4293.06\n",
      "[300]\tvalid's l1: 4283.78\n",
      "[400]\tvalid's l1: 4281.93\n",
      "[500]\tvalid's l1: 4277.92\n",
      "[600]\tvalid's l1: 4275.22\n",
      "[700]\tvalid's l1: 4272.5\n",
      "[800]\tvalid's l1: 4269\n",
      "[900]\tvalid's l1: 4268.93\n",
      "[1000]\tvalid's l1: 4266.02\n",
      "[1100]\tvalid's l1: 4262.06\n",
      "[1200]\tvalid's l1: 4261.3\n",
      "[1300]\tvalid's l1: 4260.83\n",
      "Early stopping, best iteration is:\n",
      "[1282]\tvalid's l1: 4260.46\n",
      "\n",
      "===== Start working with fold 2 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1686.97\n",
      "[200]\tvalid's l1: 1666.34\n",
      "[300]\tvalid's l1: 1659.9\n",
      "[400]\tvalid's l1: 1656.06\n",
      "[500]\tvalid's l1: 1653.56\n",
      "[600]\tvalid's l1: 1651.42\n",
      "[700]\tvalid's l1: 1649.23\n",
      "[800]\tvalid's l1: 1647.46\n",
      "[900]\tvalid's l1: 1647.7\n",
      "Early stopping, best iteration is:\n",
      "[833]\tvalid's l1: 1646.81\n",
      "\n",
      "===== Start working with fold 3 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1741.21\n",
      "[200]\tvalid's l1: 1716.13\n",
      "[300]\tvalid's l1: 1707.81\n",
      "[400]\tvalid's l1: 1702.66\n",
      "[500]\tvalid's l1: 1699.67\n",
      "[600]\tvalid's l1: 1696.11\n",
      "[700]\tvalid's l1: 1692.42\n",
      "[800]\tvalid's l1: 1690.3\n",
      "[900]\tvalid's l1: 1689.58\n",
      "[1000]\tvalid's l1: 1687.01\n",
      "[1100]\tvalid's l1: 1685.71\n",
      "[1200]\tvalid's l1: 1684.43\n",
      "[1300]\tvalid's l1: 1684.64\n",
      "Early stopping, best iteration is:\n",
      "[1290]\tvalid's l1: 1683.58\n",
      "\n",
      "===== Start working with fold 4 for Lvl_0_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1780.48\n",
      "[200]\tvalid's l1: 1761.54\n",
      "[300]\tvalid's l1: 1758.94\n",
      "[400]\tvalid's l1: 1758.68\n",
      "Early stopping, best iteration is:\n",
      "[379]\tvalid's l1: 1757.3\n",
      "Lvl_0_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 238.38564825057983\n",
      "Blending: Optimization starts with equal weights and score -2608.462273131493\n",
      "Blending, iter 0: score = -2379.4363534669264, weights = [0. 0. 1.]\n",
      "Blending, iter 1: score = -2379.4363534669264, weights = [0. 0. 1.]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 361.68 seconds.\n",
      "[2021-05-16 08:09:00,467] (INFO): oof_pred:\n",
      "array([[ 4276.4365],\n",
      "       [ 5939.6426],\n",
      "       [ 9814.721 ],\n",
      "       ...,\n",
      "       [14698.385 ],\n",
      "       [12490.874 ],\n",
      "       [ 4052.9731]], dtype=float32)\n",
      "Shape = (35000, 1)\n"
     ]
    }
   ],
   "source": [
    "oof_pred = automl.fit_predict(train_data, roles = roles)\n",
    "logging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_fi = automl.get_feature_scores('fast')\n",
    "# fast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (20, 10), grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-05-16 08:14:58,178] (INFO): Prediction for test data:\n",
      "array([[ 2781.8127],\n",
      "       [ 6090.3853],\n",
      "       [ 3427.1184],\n",
      "       ...,\n",
      "       [15289.261 ],\n",
      "       [ 5421.962 ],\n",
      "       [ 6472.4697]], dtype=float32)\n",
      "Shape = (10697, 1)\n",
      "[2021-05-16 08:14:58,179] (INFO): Check scores...\n",
      "[2021-05-16 08:14:58,180] (INFO): OOF score: 2379.4363534669264\n"
     ]
    }
   ],
   "source": [
    "test_pred = automl.predict(test_data)\n",
    "logging.info('Prediction for test data:\\n{}\\nShape = {}'\n",
    "              .format(test_pred, test_pred.shape))\n",
    "\n",
    "logging.info('Check scores...')\n",
    "logging.info('OOF score: {}'.format(mean_absolute_error(train_data[TARGET_NAME].values, oof_pred.data[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   row_ID  final_price\n",
       "0   35000  2781.812744\n",
       "1   35001  6090.385254\n",
       "2   35002  3427.118408\n",
       "3   35003  6745.902832\n",
       "4   35004  4674.939453"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_ID</th>\n      <th>final_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35000</td>\n      <td>2781.812744</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35001</td>\n      <td>6090.385254</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35002</td>\n      <td>3427.118408</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35003</td>\n      <td>6745.902832</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35004</td>\n      <td>4674.939453</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "submission[TARGET_NAME] = test_pred.data[:, 0]\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/submission_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}