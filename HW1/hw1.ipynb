{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd0a799a57f5d5eb66727322ff69a70804dc1f4dea27767e24a1805767e14b149ef",
   "display_name": "Python 3.6.9 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "logging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 4 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 1800 # Time in seconds for automl run\n",
    "TARGET_NAME = 'final_price' # Target column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(35000, 145) (10697, 145)\n"
     ]
    }
   ],
   "source": [
    "def create_extra_features(data):\n",
    "    data['NANs_cnt'] = data.isnull().sum(axis = 1) \n",
    "    \n",
    "def create_col_with_min_freq(data, col, min_freq = 10):\n",
    "    # replace rare values (less than min_freq rows) in feature by RARE_VALUE\n",
    "    data[col + '_fixed'] = data[col].astype(str)\n",
    "    data.loc[data[col + '_fixed'].value_counts()[data[col + '_fixed']].values < min_freq, col + '_fixed'] = \"RARE_VALUE\"\n",
    "    data.replace({'nan': np.nan}, inplace = True)\n",
    "\n",
    "def create_gr_feats(data):\n",
    "    # create aggregation feats for numeric features based on categorical ones\n",
    "    for cat_col in ['vehicle_manufacturer', 'vehicle_model', 'vehicle_category',\n",
    "                   'vehicle_gearbox_type', 'doors_cnt', 'wheels', 'vehicle_color', \n",
    "                   'vehicle_interior_color', 'deal_type']:\n",
    "        create_col_with_min_freq(data, cat_col, 15)\n",
    "        for num_col in ['current_mileage', 'vehicle_year', 'car_leather_interior']:\n",
    "            for n, f in [('mean', np.mean), ('min', np.nanmin), ('max', np.nanmax), ('median', np.median)]:\n",
    "                data['FIXED_' + n + '_' + num_col + '_by_' + cat_col] = data.groupby(cat_col + '_fixed')[num_col].transform(f)\n",
    "                \n",
    "    # create features with counts\n",
    "    for col in ['vehicle_manufacturer', 'vehicle_model', 'vehicle_category',\n",
    "               'current_mileage', 'vehicle_year', 'vehicle_gearbox_type', 'doors_cnt',\n",
    "               'wheels', 'vehicle_color', 'vehicle_interior_color', 'car_vin', 'deal_type']:\n",
    "        data[col + '_cnt'] = data[col].map(data[col].value_counts(dropna = False))\n",
    "    \n",
    "        \n",
    "\n",
    "create_extra_features(train_data)\n",
    "create_extra_features(test_data)\n",
    "\n",
    "all_df = pd.concat([train_data, test_data]).reset_index(drop = True)\n",
    "create_gr_feats(all_df)\n",
    "train_data, test_data = all_df[:len(train_data)], all_df[len(train_data):]\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "sklearn doesn't support in general case mae and will not be used.\n"
     ]
    }
   ],
   "source": [
    "task = Task('reg', loss='mae', metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {'target': TARGET_NAME,\n",
    "         'drop': ['row_ID'] # to drop or not to drop?\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "automl = TabularUtilizedAutoML(task = task, \n",
    "                       timeout = TIMEOUT,\n",
    "                       cpu_limit = N_THREADS,\n",
    "                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned', 'cb', 'cb_tuned'], ['lgb', 'linear_l2', 'lgb_tuned']]},\n",
    "                       cb_params = {'default_params': {'task_type':\"GPU\", 'thread_count':100}},\n",
    "                       reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ":\n",
      "[284]\tvalid's l1: 2360.13\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:07:46,259] (INFO): Trial 42 finished with value: -2360.132503605417 and parameters: {'feature_fraction': 0.9692519455114422, 'num_leaves': 71, 'bagging_fraction': 0.8774062604230195, 'min_sum_hessian_in_leaf': 0.008401804267250273, 'reg_alpha': 2.5058435618277523e-08, 'reg_lambda': 0.026484441895812262}. Best is trial 26 with value: -2341.751348306656.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2396.11\n",
      "[200]\tvalid's l1: 2354.09\n",
      "[300]\tvalid's l1: 2353.18\n",
      "[400]\tvalid's l1: 2351.74\n",
      "[500]\tvalid's l1: 2351.63\n",
      "[600]\tvalid's l1: 2351.81\n",
      "[700]\tvalid's l1: 2351.48\n",
      "[800]\tvalid's l1: 2350.83\n",
      "[900]\tvalid's l1: 2351.24\n",
      "[1000]\tvalid's l1: 2351.71\n",
      "Early stopping, best iteration is:\n",
      "[805]\tvalid's l1: 2350.56\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:07:54,277] (INFO): Trial 43 finished with value: -2350.5593266714473 and parameters: {'feature_fraction': 0.9999591196738966, 'num_leaves': 114, 'bagging_fraction': 0.775706376641968, 'min_sum_hessian_in_leaf': 0.14231456881100124, 'reg_alpha': 1.1714798530209178e-08, 'reg_lambda': 0.003786376786718644}. Best is trial 26 with value: -2341.751348306656.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2415.58\n",
      "[200]\tvalid's l1: 2363.98\n",
      "[300]\tvalid's l1: 2363.09\n",
      "[400]\tvalid's l1: 2361.95\n",
      "[500]\tvalid's l1: 2362.41\n",
      "[600]\tvalid's l1: 2362.23\n",
      "Early stopping, best iteration is:\n",
      "[407]\tvalid's l1: 2361.82\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:07:57,065] (INFO): Trial 44 finished with value: -2361.8187549398967 and parameters: {'feature_fraction': 0.8852579753506304, 'num_leaves': 35, 'bagging_fraction': 0.8308397430375293, 'min_sum_hessian_in_leaf': 0.033179050059709, 'reg_alpha': 3.8729652617233397e-08, 'reg_lambda': 0.00020224702641910783}. Best is trial 26 with value: -2341.751348306656.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2410.24\n",
      "[200]\tvalid's l1: 2360.47\n",
      "[300]\tvalid's l1: 2359.37\n",
      "[400]\tvalid's l1: 2358.8\n",
      "[500]\tvalid's l1: 2359\n",
      "[600]\tvalid's l1: 2359.28\n",
      "Early stopping, best iteration is:\n",
      "[454]\tvalid's l1: 2358.34\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:01,483] (INFO): Trial 45 finished with value: -2358.3416496215505 and parameters: {'feature_fraction': 0.7621835163829499, 'num_leaves': 101, 'bagging_fraction': 0.7864262227380749, 'min_sum_hessian_in_leaf': 0.005607059433614888, 'reg_alpha': 4.561855718293914e-07, 'reg_lambda': 0.0007451267629646942}. Best is trial 26 with value: -2341.751348306656.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2411.94\n",
      "[200]\tvalid's l1: 2354.93\n",
      "[300]\tvalid's l1: 2352.67\n",
      "[400]\tvalid's l1: 2350.54\n",
      "[500]\tvalid's l1: 2349.64\n",
      "[600]\tvalid's l1: 2349.52\n",
      "[700]\tvalid's l1: 2349.58\n",
      "[800]\tvalid's l1: 2349.35\n",
      "Early stopping, best iteration is:\n",
      "[641]\tvalid's l1: 2349.13\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:05,405] (INFO): Trial 46 finished with value: -2349.1264182626887 and parameters: {'feature_fraction': 0.9207479048024773, 'num_leaves': 46, 'bagging_fraction': 0.6899156724847758, 'min_sum_hessian_in_leaf': 0.08504693704659134, 'reg_alpha': 1.3185113223477825e-07, 'reg_lambda': 0.2889922246193005}. Best is trial 26 with value: -2341.751348306656.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2398.84\n",
      "[200]\tvalid's l1: 2348.3\n",
      "[300]\tvalid's l1: 2348.56\n",
      "[400]\tvalid's l1: 2350.03\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid's l1: 2348.07\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:09,281] (INFO): Trial 47 finished with value: -2348.0719452995404 and parameters: {'feature_fraction': 0.9598122766732406, 'num_leaves': 154, 'bagging_fraction': 0.6160007603389288, 'min_sum_hessian_in_leaf': 0.0024426821485555544, 'reg_alpha': 4.925208473999406e-06, 'reg_lambda': 0.07110373061620714}. Best is trial 26 with value: -2341.751348306656.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2407.16\n",
      "[200]\tvalid's l1: 2345.25\n",
      "[300]\tvalid's l1: 2343.03\n",
      "[400]\tvalid's l1: 2342.47\n",
      "[500]\tvalid's l1: 2340.97\n",
      "[600]\tvalid's l1: 2341.84\n",
      "[700]\tvalid's l1: 2341.49\n",
      "Early stopping, best iteration is:\n",
      "[511]\tvalid's l1: 2340.86\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:13,387] (INFO): Trial 48 finished with value: -2340.8560846679807 and parameters: {'feature_fraction': 0.7962909068008549, 'num_leaves': 77, 'bagging_fraction': 0.7415103316488098, 'min_sum_hessian_in_leaf': 0.04248250080010712, 'reg_alpha': 2.356965831433453e-08, 'reg_lambda': 4.025527104865449e-05}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2410.16\n",
      "[200]\tvalid's l1: 2355.36\n",
      "[300]\tvalid's l1: 2354.63\n",
      "[400]\tvalid's l1: 2353.64\n",
      "[500]\tvalid's l1: 2353.67\n",
      "[600]\tvalid's l1: 2353.14\n",
      "[700]\tvalid's l1: 2353.1\n",
      "[800]\tvalid's l1: 2352.68\n",
      "[900]\tvalid's l1: 2353.27\n",
      "Early stopping, best iteration is:\n",
      "[765]\tvalid's l1: 2352.51\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:18,500] (INFO): Trial 49 finished with value: -2352.506651943143 and parameters: {'feature_fraction': 0.7989297994228429, 'num_leaves': 70, 'bagging_fraction': 0.7058828092319194, 'min_sum_hessian_in_leaf': 0.36662062561019976, 'reg_alpha': 1.1445827154753123e-05, 'reg_lambda': 3.9046608229805705e-05}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2413.06\n",
      "[200]\tvalid's l1: 2358.56\n",
      "[300]\tvalid's l1: 2357.75\n",
      "[400]\tvalid's l1: 2358.28\n",
      "[500]\tvalid's l1: 2357.84\n",
      "Early stopping, best iteration is:\n",
      "[356]\tvalid's l1: 2356.74\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:22,968] (INFO): Trial 50 finished with value: -2356.7442637856348 and parameters: {'feature_fraction': 0.7826391371796853, 'num_leaves': 139, 'bagging_fraction': 0.6800587491405732, 'min_sum_hessian_in_leaf': 0.05494714128791807, 'reg_alpha': 0.0006577560366659967, 'reg_lambda': 3.6281132815138947e-06}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2404.14\n",
      "[200]\tvalid's l1: 2349.81\n",
      "[300]\tvalid's l1: 2347.21\n",
      "[400]\tvalid's l1: 2345.67\n",
      "[500]\tvalid's l1: 2345.7\n",
      "[600]\tvalid's l1: 2346.03\n",
      "[700]\tvalid's l1: 2347.18\n",
      "Early stopping, best iteration is:\n",
      "[566]\tvalid's l1: 2345.17\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:28,659] (INFO): Trial 51 finished with value: -2345.171361450039 and parameters: {'feature_fraction': 0.8133164695073276, 'num_leaves': 121, 'bagging_fraction': 0.7433856508127927, 'min_sum_hessian_in_leaf': 0.025822189294289814, 'reg_alpha': 2.7700991510807244e-08, 'reg_lambda': 1.5170575489179232e-05}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2405.8\n",
      "[200]\tvalid's l1: 2352.65\n",
      "[300]\tvalid's l1: 2351.01\n",
      "[400]\tvalid's l1: 2349.38\n",
      "[500]\tvalid's l1: 2349.25\n",
      "[600]\tvalid's l1: 2349.41\n",
      "Early stopping, best iteration is:\n",
      "[442]\tvalid's l1: 2348.63\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:33,510] (INFO): Trial 52 finished with value: -2348.626306710856 and parameters: {'feature_fraction': 0.8218283900697785, 'num_leaves': 121, 'bagging_fraction': 0.7377238126435651, 'min_sum_hessian_in_leaf': 0.02303825457181511, 'reg_alpha': 1.336453117658187e-07, 'reg_lambda': 8.484794576573064e-07}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2408.86\n",
      "[200]\tvalid's l1: 2354.83\n",
      "[300]\tvalid's l1: 2353.22\n",
      "[400]\tvalid's l1: 2352.14\n",
      "[500]\tvalid's l1: 2352.47\n",
      "[600]\tvalid's l1: 2352.86\n",
      "Early stopping, best iteration is:\n",
      "[475]\tvalid's l1: 2351.6\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:38,266] (INFO): Trial 53 finished with value: -2351.602346285156 and parameters: {'feature_fraction': 0.8656191136612914, 'num_leaves': 103, 'bagging_fraction': 0.7218511058172439, 'min_sum_hessian_in_leaf': 0.013302650025642177, 'reg_alpha': 4.2972487381310525e-08, 'reg_lambda': 1.7142670651130007e-05}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2406.62\n",
      "[200]\tvalid's l1: 2354.9\n",
      "[300]\tvalid's l1: 2351.95\n",
      "[400]\tvalid's l1: 2352.98\n",
      "[500]\tvalid's l1: 2354.09\n",
      "Early stopping, best iteration is:\n",
      "[349]\tvalid's l1: 2351.04\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:44,059] (INFO): Trial 54 finished with value: -2351.0427002416573 and parameters: {'feature_fraction': 0.7340808257912943, 'num_leaves': 221, 'bagging_fraction': 0.7482386170589184, 'min_sum_hessian_in_leaf': 0.0440487342889859, 'reg_alpha': 2.015661341831286e-08, 'reg_lambda': 3.85364325177317e-05}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2413.48\n",
      "[200]\tvalid's l1: 2365.35\n",
      "[300]\tvalid's l1: 2363.73\n",
      "[400]\tvalid's l1: 2360.87\n",
      "[500]\tvalid's l1: 2360.16\n",
      "[600]\tvalid's l1: 2360.9\n",
      "[700]\tvalid's l1: 2360.78\n",
      "Early stopping, best iteration is:\n",
      "[518]\tvalid's l1: 2359.96\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:49,645] (INFO): Trial 55 finished with value: -2359.956378026907 and parameters: {'feature_fraction': 0.8294187169473449, 'num_leaves': 132, 'bagging_fraction': 0.6436935988123784, 'min_sum_hessian_in_leaf': 0.12273430096365694, 'reg_alpha': 5.492595737903947e-07, 'reg_lambda': 5.584616581075911e-06}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2410.97\n",
      "[200]\tvalid's l1: 2353.05\n",
      "[300]\tvalid's l1: 2350.01\n",
      "[400]\tvalid's l1: 2350.84\n",
      "Early stopping, best iteration is:\n",
      "[291]\tvalid's l1: 2349.95\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:52,791] (INFO): Trial 56 finished with value: -2349.9491610090563 and parameters: {'feature_fraction': 0.7899847776534964, 'num_leaves': 92, 'bagging_fraction': 0.6773963718360801, 'min_sum_hessian_in_leaf': 0.021859617161944143, 'reg_alpha': 8.390039386340897e-08, 'reg_lambda': 9.103744992790507e-08}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2403.84\n",
      "[200]\tvalid's l1: 2348.05\n",
      "[300]\tvalid's l1: 2347.01\n",
      "[400]\tvalid's l1: 2345.96\n",
      "Early stopping, best iteration is:\n",
      "[264]\tvalid's l1: 2345.32\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:56,107] (INFO): Trial 57 finished with value: -2345.3171440234014 and parameters: {'feature_fraction': 0.8102959597833097, 'num_leaves': 108, 'bagging_fraction': 0.7074654415091854, 'min_sum_hessian_in_leaf': 0.04210287030044179, 'reg_alpha': 3.223287565220801e-05, 'reg_lambda': 3.631557809355642e-05}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2408.17\n",
      "[200]\tvalid's l1: 2357.5\n",
      "[300]\tvalid's l1: 2357.12\n",
      "[400]\tvalid's l1: 2356.19\n",
      "[500]\tvalid's l1: 2357.29\n",
      "Early stopping, best iteration is:\n",
      "[365]\tvalid's l1: 2355.79\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:08:59,991] (INFO): Trial 58 finished with value: -2355.790289003304 and parameters: {'feature_fraction': 0.7640953447208807, 'num_leaves': 109, 'bagging_fraction': 0.7168396433721623, 'min_sum_hessian_in_leaf': 0.085855814440759, 'reg_alpha': 6.379386200021855e-05, 'reg_lambda': 9.72131323230515e-07}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2416.58\n",
      "[200]\tvalid's l1: 2354.59\n",
      "[300]\tvalid's l1: 2354.49\n",
      "[400]\tvalid's l1: 2353.86\n",
      "[500]\tvalid's l1: 2354.95\n",
      "Early stopping, best iteration is:\n",
      "[378]\tvalid's l1: 2353.06\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:09:03,862] (INFO): Trial 59 finished with value: -2353.0616898513777 and parameters: {'feature_fraction': 0.6710006194962304, 'num_leaves': 117, 'bagging_fraction': 0.7061353407826297, 'min_sum_hessian_in_leaf': 0.2233952285850346, 'reg_alpha': 2.2225731288029638e-05, 'reg_lambda': 3.1186431427117124e-05}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2413.73\n",
      "[200]\tvalid's l1: 2354.57\n",
      "[300]\tvalid's l1: 2351.28\n",
      "[400]\tvalid's l1: 2351.39\n",
      "[500]\tvalid's l1: 2351.83\n",
      "Early stopping, best iteration is:\n",
      "[348]\tvalid's l1: 2350.82\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:09:06,615] (INFO): Trial 60 finished with value: -2350.8227820702878 and parameters: {'feature_fraction': 0.810711094412576, 'num_leaves': 59, 'bagging_fraction': 0.6369739935743074, 'min_sum_hessian_in_leaf': 0.013053496989154008, 'reg_alpha': 0.005312301253320117, 'reg_lambda': 1.016468314261445e-05}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2403.75\n",
      "[200]\tvalid's l1: 2354\n",
      "[300]\tvalid's l1: 2351.3\n",
      "[400]\tvalid's l1: 2349.73\n",
      "[500]\tvalid's l1: 2351.07\n",
      "[600]\tvalid's l1: 2351.03\n",
      "Early stopping, best iteration is:\n",
      "[409]\tvalid's l1: 2349.42\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:09:11,307] (INFO): Trial 61 finished with value: -2349.423923044205 and parameters: {'feature_fraction': 0.8459662542225146, 'num_leaves': 122, 'bagging_fraction': 0.7553196964963018, 'min_sum_hessian_in_leaf': 0.036943721504129765, 'reg_alpha': 2.5382936760031076e-06, 'reg_lambda': 0.00015988089585827487}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2413.74\n",
      "[200]\tvalid's l1: 2350.9\n",
      "[300]\tvalid's l1: 2351.19\n",
      "[400]\tvalid's l1: 2351.74\n",
      "Early stopping, best iteration is:\n",
      "[271]\tvalid's l1: 2350.69\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:09:15,159] (INFO): Trial 62 finished with value: -2350.6868602883815 and parameters: {'feature_fraction': 0.7200299813836992, 'num_leaves': 146, 'bagging_fraction': 0.7345134507030237, 'min_sum_hessian_in_leaf': 0.05616116426974458, 'reg_alpha': 0.0003833756514065596, 'reg_lambda': 0.0004005151493561402}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's l1: 2403.38\n",
      "[200]\tvalid's l1: 2359.69\n",
      "[300]\tvalid's l1: 2356.46\n",
      "[400]\tvalid's l1: 2354.39\n",
      "[500]\tvalid's l1: 2355.47\n",
      "[600]\tvalid's l1: 2357.48\n",
      "Early stopping, best iteration is:\n",
      "[454]\tvalid's l1: 2354.16\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "[2021-05-16 20:09:20,957] (INFO): Trial 63 finished with value: -2354.1589238864526 and parameters: {'feature_fraction': 0.8088320120390594, 'num_leaves': 157, 'bagging_fraction': 0.7941683937031322, 'min_sum_hessian_in_leaf': 0.023560511647193836, 'reg_alpha': 2.2075961789734714e-07, 'reg_lambda': 7.556710853722302e-05}. Best is trial 48 with value: -2340.8560846679807.\n",
      "Start fitting Lvl_1_Pipe_1_Mod_1_LightGBM ...\n",
      "\n",
      "===== Start working with fold 0 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 2363.25\n",
      "[200]\tvalid's l1: 2362.96\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid's l1: 2361.58\n",
      "\n",
      "===== Start working with fold 1 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 4173.48\n",
      "[200]\tvalid's l1: 4166.55\n",
      "[300]\tvalid's l1: 4167.26\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid's l1: 4165.82\n",
      "\n",
      "===== Start working with fold 2 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1570.1\n",
      "[200]\tvalid's l1: 1566.32\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid's l1: 1565.35\n",
      "\n",
      "===== Start working with fold 3 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1605.3\n",
      "[200]\tvalid's l1: 1599.63\n",
      "[300]\tvalid's l1: 1601.33\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid's l1: 1599.43\n",
      "\n",
      "===== Start working with fold 4 for Lvl_1_Pipe_1_Mod_1_LightGBM =====\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's l1: 1563.75\n",
      "[200]\tvalid's l1: 1560.78\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid's l1: 1559.85\n",
      "Lvl_1_Pipe_1_Mod_1_LightGBM fitting and predicting completed\n",
      "Time left 638.0590529441833\n",
      "Blending: Optimization starts with equal weights and score -2243.6240390324933\n",
      "Blending, iter 0: score = -2242.3649775939534, weights = [0.42750156 0.07808997 0.4944085 ]\n",
      "Blending, iter 1: score = -2242.308805429077, weights = [0.45229325 0.         0.5477068 ]\n",
      "Blending, iter 2: score = -2242.308805429077, weights = [0.45229322 0.         0.5477067 ]\n",
      "Blending, iter 3: score = -2242.308805429077, weights = [0.45229322 0.         0.5477067 ]\n",
      "No score update. Terminated\n",
      "\n",
      "Automl preset training completed in 1162.13 seconds.\n",
      "[2021-05-16 20:09:29,851] (INFO): oof_pred:\n",
      "array([[ 3964.6028],\n",
      "       [ 6658.7524],\n",
      "       [ 7858.67  ],\n",
      "       ...,\n",
      "       [17988.467 ],\n",
      "       [12057.837 ],\n",
      "       [ 4082.1394]], dtype=float32)\n",
      "Shape = (35000, 1)\n"
     ]
    }
   ],
   "source": [
    "oof_pred = automl.fit_predict(train_data, roles = roles)\n",
    "logging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_fi = automl.get_feature_scores('fast')\n",
    "# fast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (20, 10), grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-05-16 21:09:05,600] (INFO): Prediction for test data:\n",
      "array([[ 2886.2434],\n",
      "       [ 5908.5435],\n",
      "       [ 2444.8494],\n",
      "       ...,\n",
      "       [16929.654 ],\n",
      "       [ 5282.768 ],\n",
      "       [ 6292.7456]], dtype=float32)\n",
      "Shape = (10697, 1)\n",
      "[2021-05-16 21:09:05,601] (INFO): Check scores...\n",
      "[2021-05-16 21:09:05,602] (INFO): OOF score: 2242.3088047814613\n"
     ]
    }
   ],
   "source": [
    "test_pred = automl.predict(test_data)\n",
    "logging.info('Prediction for test data:\\n{}\\nShape = {}'\n",
    "              .format(test_pred, test_pred.shape))\n",
    "\n",
    "logging.info('Check scores...')\n",
    "logging.info('OOF score: {}'.format(mean_absolute_error(train_data[TARGET_NAME].values, oof_pred.data[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   row_ID  final_price\n",
       "0   35000  2886.243408\n",
       "1   35001  5908.543457\n",
       "2   35002  2444.849365\n",
       "3   35003  6914.652832\n",
       "4   35004  3736.633545"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_ID</th>\n      <th>final_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35000</td>\n      <td>2886.243408</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35001</td>\n      <td>5908.543457</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35002</td>\n      <td>2444.849365</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35003</td>\n      <td>6914.652832</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35004</td>\n      <td>3736.633545</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "submission[TARGET_NAME] = test_pred.data[:, 0]\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/submission_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['final_price'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/submission_all_zeros.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission4 = pd.read_csv('submissions/submission_4.csv')\n",
    "np.mean(submission4['final_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission4['final_price'] = submission4['final_price'] - np.mean(submission4['final_price']) + 5454.77075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission4.to_csv('submissions/submission_4_mae_hack.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all zeros gives 5454.77075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}